<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#0078E7"><meta name="author" content="momo"><meta name="copyright" content="momo"><meta name="generator" content="Hexo 5.2.0"><meta name="theme" content="hexo-theme-yun"><title>Redis笔记(尚硅谷黑马整合) | 我的笔记</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/star-markdown-css@0.1.25/dist/yun/yun-markdown.min.css"><script src="//at.alicdn.com/t/font_1140697_dxory92pb0h.js" async></script><script src="https://cdn.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>function initScrollReveal() {
  [".post-card",".post-content img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
}
document.addEventListener("DOMContentLoaded", initScrollReveal);
document.addEventListener("pjax:success", initScrollReveal);
</script><link id="light-prism-css" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@latest/themes/prism.css" media="(prefers-color-scheme: light)"><link id="dark-prism-css" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@latest/themes/prism-tomorrow.css" media="(prefers-color-scheme: dark)"><link rel="icon" type="image/svg+xml" href="/yun.svg"><link rel="mask-icon" href="/yun.svg" color="#0078E7"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><script id="yun-config">
    const Yun = window.Yun || {};
    window.CONFIG = {"hostname":"ppxiaodi.gitee.io","root":"/","title":"momo的小站","version":"1.7.0","mode":"auto","copycode":true,"page":{"isPost":true},"i18n":{"placeholder":"搜索...","empty":"找不到您查询的内容: ${query}","hits":"找到 ${hits} 条结果","hits_time":"找到 ${hits} 条结果（用时 ${time} 毫秒）"},"anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"local_search":{"path":"/search.xml"},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script src="/js/utils.js"></script><script src="/js/hexo-theme-yun.js"></script><meta name="description" content="Redis笔记(尚硅谷黑马整合)  图片未下载到本地   本文由 简悦 SimpRead 转码， 原文地址 blog.csdn.net  &#96; 笔记内容包括两个视频的笔记： Redis—尚硅谷 java 研究院 （推荐）Redis 入门到精通【黑马程序员】https:&#x2F;&#x2F;www.bilibili.com&#x2F;video&#x2F;BV1CJ411m7Gc 第 1 章 NoSQL 简介 REmote Diction">
<meta property="og:type" content="article">
<meta property="og:title" content="Redis笔记(尚硅谷黑马整合)">
<meta property="og:url" content="https://ppxiaodi.gitee.io/2020/03/14/CollectionNote/java/%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E/Redis%E7%AC%94%E8%AE%B0(%E5%B0%9A%E7%A1%85%E8%B0%B7%E9%BB%91%E9%A9%AC%E6%95%B4%E5%90%88)/index.html">
<meta property="og:site_name" content="我的笔记">
<meta property="og:description" content="Redis笔记(尚硅谷黑马整合)  图片未下载到本地   本文由 简悦 SimpRead 转码， 原文地址 blog.csdn.net  &#96; 笔记内容包括两个视频的笔记： Redis—尚硅谷 java 研究院 （推荐）Redis 入门到精通【黑马程序员】https:&#x2F;&#x2F;www.bilibili.com&#x2F;video&#x2F;BV1CJ411m7Gc 第 1 章 NoSQL 简介 REmote Diction">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/3f762f4ca37f1e1fc12b6e740b3702cb.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/2f13cf0a03a4c0fdca1a941de99dfda4.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/2dc21992a69fc02c2e75f7b301e7897a.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/b8701b1273f4fda21438a88f153dc621.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/4302813ffe99025c091ba0b17d46934a.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/7d9fedfe2c35fe6562810857c7d37580.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/1cfe469776490e08960eb6d9b3b105ff.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/d4092a5559ef78c96bc17d1e6c67225e.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/4447bd90ad836f57fd22c26220b94f4c.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/142dc418532cefaf2ac0f9adb06bd8c3.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/b51178bf59d34c0d5bd9a44e8b4ff831.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/1d8b031a190e2dd8706bd5abcc649bc6.png">
<meta property="og:image" content="https://img-blog.csdn.net/2018042316482657">
<meta property="og:image" content="https://images.cnitblog.com/blog/405877/201411/142332187256396.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/b10b0726836cde472bc27abdc23b2a9a.png">
<meta property="og:image" content="https://img-blog.csdn.net/20180423171630284">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/4643a57c24e2c3732e402ff3c95d8d2f.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/6ddc649ddfa077f53a378ee1afd4685e.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/74696ddcc7b8bfd6bf662f509723fc17.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/d2bd5ee75eb4e121b03cf67a3a2026f0.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/6d81cd49d7179505dfb58e6ebb41d84b.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7896890-c6fb10cdbb32f517.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422003323.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7896890-efd5114939a651ed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/9316f10f5edd2367c675c4c30a0d7bd9.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/1c83ccc9b7bf2685e5a59555e846853e.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/cf0dfd3857feb14f75bb26c822a22e73.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/cd70f0f9be21d9ebcd0befc390dc2f77.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/7c1ea079b586e2c453d3b30c1ed4f2b3.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422015831.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/0f467934646780b80335e1d9dae1400f.png">
<meta property="og:image" content="https://images2018.cnblogs.com/blog/1075473/201807/1075473-20180725172641202-1573986143.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422023420.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422024611.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/def1c5bb11ff1a075e5eebead0dbf571.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/2a2b74011307bda37dad2b2be2bf81fd.png">
<meta property="og:image" content="https://images2018.cnblogs.com/blog/1075473/201807/1075473-20180726171841786-525684493.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/e66715f07790a90354d96f77fe064477.png">
<meta property="og:image" content="https://images2018.cnblogs.com/blog/1075473/201807/1075473-20180726181756270-1907770368.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/f3bf2f42c120d30ebe8c1e4a1bb82512.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/5c7c5a3284f9179b95831155658dee84.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200605124921.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200908120235.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/16d55a85a2b764e424a9800189966206.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/17cc08c1e8cc52e8d663621fc7128f12.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/6527560fd25546dba0b3549f134d63ee.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/acc8264643d23e1a6fef6b3d7c52190b.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422160534.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422160736.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422161130.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422161130.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422161507.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422161553.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422161821.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422161652.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422162213.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/35dc7fcf139eee595512c737ba6dc36b.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20190220172520981.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/eccb7f3c010bf908238f62652447fcc2.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422162527.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422162610.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422162630.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/11ac3d82eb2546eeef704de6a710e62f.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422162714.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422162737.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/11ac3d82eb2546eeef704de6a710e62f.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/ab9589e7e14243ab78c6d3d775b69ec3.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/8b5906159669c7674479438af96cc009.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/9fd9e96c23836fb226ca3e97ed1e662e.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/7b4812d3f57c4fc213bdc2cd0961fe41.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/a25dfe621de03eb74b60bb513aa6f197.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/28dac937400b802eefc161634892e7ab.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7896890-516eb4a9465451a6.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200908141231.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7896890-f65c71ca6811c634.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422185737.png">
<meta property="og:image" content="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422185954.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/032dea75c958da075af378b6b9680362.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/d31ddccd938381c23a61a9970e8b20f5.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/1c455870bde86277383fa31c55ce5ff9.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7896890-40e8a2c096c8da92.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B-redis.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/0894c7cbbf05ed70d7cc68546ee66011.png">
<meta property="og:image" content="https://img-blog.csdn.net/20180803155708102">
<meta property="og:image" content="https://img-blog.csdn.net/20180803160634250">
<meta property="og:image" content="https://img-blog.csdn.net/20170707154022077">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/fadbddc6e9e43464bbc841d44334b2d4.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/042526ce752d07f26409d15bd28647a2.png">
<meta property="og:image" content="https://img-blog.csdn.net/20180803161053730">
<meta property="og:image" content="https://img-blog.csdn.net/20180803161427905">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/05e222c654dcfd4856e1eafa99190a1d.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/ffa5637c59ffb4f4b0376fc15d29fcef.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/89ed34304c24266daa788ad41de60066.png">
<meta property="og:image" content="https://img-blog.csdn.net/20170903171144693">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/ddbb9433676fea2ff9f528d493e5312c.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/ba8a9e993128e00238e000032fc54ccf.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/d816539907a311be3cfcd8d43545ef38.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/40c4b12429e049a0cf3357721a9672eb.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/cb9d6944b0011870af3ce96f6b3b2375.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/20f4ab09d79ce8df5f551644d5c88015.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/33cad37cd39d082b649028c8c63f0b65.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/e65d15b933b967d56815950743081a3c.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/055f8934d9258544b71e53da48ae8804.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/df0a5fe83ad2d52805259a39d20e75d2.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/6da8e626c348653125b565d1251afd5b.png">
<meta property="article:published_time" content="2020-03-13T16:00:00.000Z">
<meta property="article:modified_time" content="2021-07-11T08:54:54.210Z">
<meta property="article:author" content="momo">
<meta property="article:tag" content="java">
<meta property="article:tag" content="谷粒商城">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/img_convert/3f762f4ca37f1e1fc12b6e740b3702cb.png"><script src="/js/ui/mode.js"></script></head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="文章目录"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about/" title="momo"><img width="96" loading="lazy" src="/yun.png" alt="momo"></a><div class="site-author-name"><a href="/about/">momo</a></div><a class="site-name" href="/about/site.html">我的笔记</a><sub class="site-subtitle"></sub><div class="site-desciption"></div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="首页"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item"><a href="/archives/" title="归档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">198</span></a></div><div class="site-state-item"><a href="/categories/" title="分类"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">58</span></a></div><div class="site-state-item"><a href="/tags/" title="标签"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">47</span></a></div><a class="site-state-item hty-icon-button" target="_blank" rel="noopener" href="https://yun.yunyoujun.cn" title="文档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-settings-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="/atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://qm.qq.com/cgi-bin/qm/qr?k=kZJzggTTCf4SpvEQ8lXWoi5ZjhAx0ILZ&amp;jump_from=webapi" title="QQ 群 1050458482" target="_blank" style="color:#12B7F5"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-qq-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/YunYouJun" title="GitHub" target="_blank" style="color:#6e5494"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://weibo.com/jizhideyunyoujun" title="微博" target="_blank" style="color:#E6162D"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-weibo-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://www.douban.com/people/yunyoujun/" title="豆瓣" target="_blank" style="color:#007722"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-douban-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://music.163.com/#/user/home?id=247102977" title="网易云音乐" target="_blank" style="color:#C20C0C"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-netease-cloud-music-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://www.zhihu.com/people/yunyoujun/" title="知乎" target="_blank" style="color:#0084FF"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhihu-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://space.bilibili.com/1579790" title="哔哩哔哩" target="_blank" style="color:#FF8EB3"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-bilibili-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/about/white-qrcode-and-search.jpg" title="微信公众号" target="_blank" style="color:#1AAD19"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wechat-2-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://twitter.com/YunYouJun" title="Twitter" target="_blank" style="color:#1da1f2"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-twitter-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://t.me/elpsycn" title="Telegram Channel" target="_blank" style="color:#0088CC"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-telegram-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:me@yunyoujun.cn" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://travellings.link" title="Travelling" target="_blank" style="color:var(--hty-text-color)"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-train-line"></use></svg></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="/links/" title="我的小伙伴们" style="color:dodgerblue"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-genderless-line"></use></svg></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color: #f1cb64"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-contrast-2-line"></use></svg></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">Redis笔记(尚硅谷黑马整合)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">第 1 章 NoSQL 简介</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-5-NoSQL-%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A6%82%E8%BF%B0"><span class="toc-number">2.1.</span> <span class="toc-text">1.5 NoSQL 数据库概述</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">第 2 章 Redis 简介 及 安装</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-Redis-%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">3.1.</span> <span class="toc-text">2.2 Redis 的应用场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-5-%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4"><span class="toc-number">3.2.</span> <span class="toc-text">2.5 安装步骤</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-7-Redis-%E7%9A%84%E5%90%AF%E5%8A%A8"><span class="toc-number">3.3.</span> <span class="toc-text">2.7 Redis 的启动</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E5%A4%9A%E4%B8%AA-redis"><span class="toc-number">3.3.0.1.</span> <span class="toc-text">启动多个 redis</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-9-%E5%85%B3%E9%97%AD-Redis-%E6%9C%8D%E5%8A%A1"><span class="toc-number">3.4.</span> <span class="toc-text">2.9 关闭 Redis 服务</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-10-Redis-%E9%BB%98%E8%AE%A4-16-%E4%B8%AA%E5%BA%93"><span class="toc-number">3.5.</span> <span class="toc-text">2.10 Redis 默认 16 个库</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-11-Redis-%E7%9A%84%E5%8D%95%E7%BA%BF%E7%A8%8B-%E5%A4%9A%E8%B7%AF-IO-%E5%A4%8D%E7%94%A8%E6%8A%80%E6%9C%AF"><span class="toc-number">3.6.</span> <span class="toc-text">2.11 Redis 的单线程 + 多路 IO 复用技术</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-%E6%B5%81%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="toc-number">3.6.0.1.</span> <span class="toc-text">1.1 流的概念</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF-I-O-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8"><span class="toc-number">3.6.1.</span> <span class="toc-text">什么是 I&#x2F;O 多路复用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reactor%EF%BC%88%E5%8F%8D%E5%BA%94%E5%99%A8%E6%A8%A1%E5%BC%8F%EF%BC%89"><span class="toc-number">3.6.2.</span> <span class="toc-text">Reactor（反应器模式）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">3.7.</span> <span class="toc-text">总结</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E4%B8%BA%E4%BB%80%E4%B9%88-Redis-%E6%98%AF%E5%8D%95%E7%BA%BF%E7%A8%8B%E7%9A%84"><span class="toc-number">3.7.1.</span> <span class="toc-text">二、为什么 Redis 是单线程的</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">第 3 章 Redis 的五大数据类型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-0-key-%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4"><span class="toc-number">4.1.</span> <span class="toc-text">3.0 key 基本命令</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-String"><span class="toc-number">4.2.</span> <span class="toc-text">3.1 String</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SDS-%E4%B8%8E-C-%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">4.2.1.</span> <span class="toc-text">SDS 与 C 字符串的区别</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-hash"><span class="toc-number">4.3.</span> <span class="toc-text">3.2 hash</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B8%90%E8%BF%9B%E5%BC%8F-rehash"><span class="toc-number">4.3.1.</span> <span class="toc-text">渐进式 rehash</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%A9%E7%BC%A9%E5%AE%B9%E7%9A%84%E6%9D%A1%E4%BB%B6"><span class="toc-number">4.3.2.</span> <span class="toc-text">扩缩容的条件</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3-List"><span class="toc-number">4.4.</span> <span class="toc-text">3.3 List</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-4-Set"><span class="toc-number">4.5.</span> <span class="toc-text">3.4 Set</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-5-zset-sorted-set"><span class="toc-number">4.6.</span> <span class="toc-text">3.5 zset (sorted set)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">第 4 章 Redis 的相关配置</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">6.</span> <span class="toc-text">第 5 章 Jedis</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">7.</span> <span class="toc-text">第 6 章 Redis 事务</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#6-1-Redis-%E4%B8%AD%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="toc-number">7.1.</span> <span class="toc-text">6.1 Redis 中事务的定义</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8B%E5%8A%A1%E4%B9%8B%E2%80%94%E7%9B%91%E8%A7%86%E9%94%81%EF%BC%88%E8%B6%85%E5%8D%96%E9%97%AE%E9%A2%98%E3%80%81%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%EF%BC%89"><span class="toc-number">7.1.1.</span> <span class="toc-text">事务之—监视锁（超卖问题、分布式锁）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-3-%E4%BA%8B%E5%8A%A1%E4%B8%AD%E7%9A%84%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86"><span class="toc-number">7.2.</span> <span class="toc-text">6.3 事务中的错误处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-4-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%81%9A%E6%88%90%E4%BA%8B%E5%8A%A1"><span class="toc-number">7.3.</span> <span class="toc-text">6.4 为什么要做成事务?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-6-Redis-%E4%BA%8B%E5%8A%A1-%E7%A7%92%E6%9D%80%E6%A1%88%E4%BE%8B"><span class="toc-number">7.4.</span> <span class="toc-text">6.6 Redis 事务 秒杀案例</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">8.</span> <span class="toc-text">第 7 章 Redis 持久化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#7-1-RDB"><span class="toc-number">8.1.</span> <span class="toc-text">7.1 RDB</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#7-1-1-save"><span class="toc-number">8.1.0.1.</span> <span class="toc-text">7.1.1 save</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-1-2-bgsave"><span class="toc-number">8.1.0.2.</span> <span class="toc-text">7.1.2 bgsave</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#bgsave-%E5%8E%9F%E7%90%86%EF%BC%9A"><span class="toc-number">8.1.0.3.</span> <span class="toc-text">bgsave 原理：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-2-AOF"><span class="toc-number">8.2.</span> <span class="toc-text">7.2 AOF</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#AOF-%E5%88%B7%E6%96%B0%E7%BC%93%E5%AD%98%E5%8C%BA"><span class="toc-number">8.2.0.0.1.</span> <span class="toc-text">AOF 刷新缓存区</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AOF-%E6%8C%81%E4%B9%85%E5%8C%96%E7%AD%96%E7%95%A5-%E5%86%99%E6%95%B0%E6%8D%AE"><span class="toc-number">8.2.0.1.</span> <span class="toc-text">AOF 持久化策略 (写数据)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AOF-%E9%87%8D%E5%86%99"><span class="toc-number">8.2.0.2.</span> <span class="toc-text">AOF 重写</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AOF-%E9%87%8D%E5%86%99%E8%BF%87%E7%A8%8B-AOF-%E9%87%8D%E5%86%99%E7%BC%93%E5%86%B2%E5%8C%BA"><span class="toc-number">8.2.0.3.</span> <span class="toc-text">AOF 重写过程 (AOF 重写缓冲区)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-3-RDB-AOF-%E6%B7%B7%E5%90%88%E6%8C%81%E4%B9%85%E5%8C%96"><span class="toc-number">8.3.</span> <span class="toc-text">7.3 RDB+AOF 混合持久化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%80%E5%90%AF%E6%B7%B7%E5%90%88%E6%8C%81%E4%B9%85%E5%8C%96"><span class="toc-number">8.3.0.1.</span> <span class="toc-text">开启混合持久化</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-3-RDB-%E5%92%8C-AOF-%E6%AF%94%E8%BE%83"><span class="toc-number">8.4.</span> <span class="toc-text">7.3 RDB 和 AOF 比较</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%80%E6%9C%BA%E5%8A%A0%E8%BD%BD%E6%8C%81%E4%B9%85%E5%8C%96%E6%AD%A5%E9%AA%A4"><span class="toc-number">8.5.</span> <span class="toc-text">开机加载持久化步骤</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">9.</span> <span class="toc-text">⑧ 过期数据删除策略</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#0-%E6%97%B6%E6%95%88%E6%80%A7%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84"><span class="toc-number">9.0.1.</span> <span class="toc-text">0 时效性数据的存储结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%AE%9A%E6%97%B6%E5%88%A0%E9%99%A4"><span class="toc-number">9.0.2.</span> <span class="toc-text">1 定时删除</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%83%B0%E6%80%A7%E5%88%A0%E9%99%A4"><span class="toc-number">9.0.3.</span> <span class="toc-text">2 惰性删除</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%AE%9A%E6%9C%9F%E5%88%A0%E9%99%A4"><span class="toc-number">9.0.4.</span> <span class="toc-text">3 定期删除</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">10.</span> <span class="toc-text">⑨ 内存不足逐出算法：</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">11.</span> <span class="toc-text">服务器配置</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">12.</span> <span class="toc-text">高级数据模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Pipline"><span class="toc-number">12.0.0.1.</span> <span class="toc-text">Pipline</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Bitmaps"><span class="toc-number">12.0.1.</span> <span class="toc-text">Bitmaps</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B0%B7%E6%AD%8C%E6%8F%90%E4%BE%9B%E7%9A%84%E4%BD%8D%E5%9B%BE%E8%AE%A1%E7%AE%97%E5%99%A8"><span class="toc-number">12.0.1.1.</span> <span class="toc-text">谷歌提供的位图计算器</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HyperLogLog%EF%BC%9A"><span class="toc-number">12.0.2.</span> <span class="toc-text">HyperLogLog：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GEO%EF%BC%9A"><span class="toc-number">12.0.3.</span> <span class="toc-text">GEO：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">13.</span> <span class="toc-text">第 8 章 redis 高可用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#8-1-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6"><span class="toc-number">13.1.</span> <span class="toc-text">8.1 主从复制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#8-2-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E7%9A%84%E7%9B%AE%E7%9A%84"><span class="toc-number">13.1.1.</span> <span class="toc-text">8.2 主从复制的目的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-3-%E4%B8%BB%E4%BB%8E%E9%85%8D%E7%BD%AE%E5%8E%9F%E7%90%86"><span class="toc-number">13.1.2.</span> <span class="toc-text">8.3 主从配置原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E4%B8%80%EF%BC%9A%E5%BB%BA%E7%AB%8B%E8%BF%9E%E6%8E%A5%E9%98%B6%E6%AE%B5"><span class="toc-number">13.1.3.</span> <span class="toc-text">阶段一：建立连接阶段</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E4%BA%8C%EF%BC%9A%E5%90%8C%E6%AD%A5%E9%98%B6%E6%AE%B5"><span class="toc-number">13.1.4.</span> <span class="toc-text">阶段二：同步阶段</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E4%B8%89%EF%BC%9A%E5%91%BD%E4%BB%A4%E4%BC%A0%E6%92%AD%E9%98%B6%E6%AE%B5"><span class="toc-number">13.1.5.</span> <span class="toc-text">阶段三：命令传播阶段</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%8D%E5%88%B6%E7%BC%93%E5%86%B2%E5%8C%BA"><span class="toc-number">13.1.5.1.</span> <span class="toc-text">复制缓冲区</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E6%80%BB%E7%BB%93"><span class="toc-number">13.1.5.2.</span> <span class="toc-text">数据同步总结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BF%83%E8%B7%B3%E6%9C%BA%E5%88%B6"><span class="toc-number">13.1.6.</span> <span class="toc-text">心跳机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98"><span class="toc-number">13.1.7.</span> <span class="toc-text">主从复制常见问题</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A2%91%E7%B9%81%E7%9A%84%E5%85%A8%E9%87%8F%E5%A4%8D%E5%88%B6%EF%BC%88-1%EF%BC%89"><span class="toc-number">13.1.7.1.</span> <span class="toc-text">频繁的全量复制（ 1）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A2%91%E7%B9%81%E7%9A%84%E7%BD%91%E7%BB%9C%E4%B8%AD%E6%96%AD%EF%BC%88-1%EF%BC%89"><span class="toc-number">13.1.7.2.</span> <span class="toc-text">频繁的网络中断（ 1）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%80%E8%87%B4"><span class="toc-number">13.1.7.3.</span> <span class="toc-text">数据不一致</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-2-%E5%93%A8%E5%85%B5%E4%B8%8E%E9%80%89%E4%B8%BE"><span class="toc-number">13.2.</span> <span class="toc-text">8.2 哨兵与选举</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E5%93%A8%E5%85%B5"><span class="toc-number">13.2.1.</span> <span class="toc-text">配置哨兵</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%93%A8%E5%85%B5%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%EF%BC%9A"><span class="toc-number">13.2.2.</span> <span class="toc-text">哨兵工作原理：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2"><span class="toc-number">13.2.2.1.</span> <span class="toc-text">主从切换</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E4%B8%80%EF%BC%9A%E7%9B%91%E6%8E%A7%E9%98%B6%E6%AE%B5"><span class="toc-number">13.2.2.1.1.</span> <span class="toc-text">阶段一：监控阶段</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E4%BA%8C%EF%BC%9A%E9%80%9A%E7%9F%A5%E9%98%B6%E6%AE%B5"><span class="toc-number">13.2.2.1.2.</span> <span class="toc-text">阶段二：通知阶段</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E4%B8%89%EF%BC%9A%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%E9%98%B6%E6%AE%B5"><span class="toc-number">13.2.2.1.3.</span> <span class="toc-text">阶段三：故障转移阶段</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis-Sentinel-%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-number">13.2.3.</span> <span class="toc-text">Redis Sentinel 的工作原理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-3-Redis-%E9%9B%86%E7%BE%A4"><span class="toc-number">13.3.</span> <span class="toc-text">8.3 Redis 集群</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="toc-number">13.3.1.</span> <span class="toc-text">基本原理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%90%AD%E5%BB%BA%E6%96%B9%E5%BC%8F"><span class="toc-number">13.3.1.1.</span> <span class="toc-text">搭建方式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Cluster-%E9%85%8D%E7%BD%AE"><span class="toc-number">13.3.1.2.</span> <span class="toc-text">Cluster 配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-3-4-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA"><span class="toc-number">13.3.1.3.</span> <span class="toc-text">8.3.4 集群搭建</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%A9%E5%AE%B9"><span class="toc-number">13.3.1.4.</span> <span class="toc-text">扩容</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA%E6%96%B9%E6%A1%88%E7%AE%80%E6%9E%90"><span class="toc-number">13.4.</span> <span class="toc-text">数据分区方案简析</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%96%B9%E6%A1%88%E4%B8%80%EF%BC%9A%E5%93%88%E5%B8%8C%E5%80%BC-%E8%8A%82%E7%82%B9%E6%95%B0"><span class="toc-number">13.4.0.0.1.</span> <span class="toc-text">方案一：哈希值 % 节点数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%96%B9%E6%A1%88%E4%BA%8C%EF%BC%9A%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E5%88%86%E5%8C%BA"><span class="toc-number">13.4.0.0.2.</span> <span class="toc-text">方案二：一致性哈希分区</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%96%B9%E6%A1%88%E4%B8%89%EF%BC%9A%E5%B8%A6%E6%9C%89%E8%99%9A%E6%8B%9F%E8%8A%82%E7%82%B9%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E5%88%86%E5%8C%BA"><span class="toc-number">13.4.0.0.3.</span> <span class="toc-text">方案三：带有虚拟节点的一致性哈希分区</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%8A%82%E7%82%B9%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E6%9E%90"><span class="toc-number">13.4.0.1.</span> <span class="toc-text">节点通信机制简析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%A4%E4%B8%AA%E7%AB%AF%E5%8F%A3"><span class="toc-number">13.4.0.2.</span> <span class="toc-text">两个端口</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Gossip-%E5%8D%8F%E8%AE%AE"><span class="toc-number">13.4.0.3.</span> <span class="toc-text">Gossip 协议</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E7%B1%BB%E5%9E%8B"><span class="toc-number">13.4.0.4.</span> <span class="toc-text">消息类型</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AE%80%E6%9E%90"><span class="toc-number">13.5.</span> <span class="toc-text">数据结构简析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#clusterNode-%E7%BB%93%E6%9E%84"><span class="toc-number">13.5.0.1.</span> <span class="toc-text">clusterNode 结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#clusterState-%E7%BB%93%E6%9E%84"><span class="toc-number">13.5.0.2.</span> <span class="toc-text">clusterState 结构</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#redis-%E7%9B%B8%E5%85%B3%E9%98%85%E8%AF%BB"><span class="toc-number">13.5.1.</span> <span class="toc-text">redis 相关阅读</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-6-%E9%9B%86%E7%BE%A4%E6%93%8D%E4%BD%9C"><span class="toc-number">13.6.</span> <span class="toc-text">9.6 集群操作</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">14.</span> <span class="toc-text">redis 客户端</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#9-7-%E9%9B%86%E7%BE%A4%E7%9A%84-Jedis-%E5%BC%80%E5%8F%91"><span class="toc-number">14.1.</span> <span class="toc-text">9.7 集群的 Jedis 开发</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">15.</span> <span class="toc-text">RedisTemplate</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81spring-data-redis-%E5%8A%9F%E8%83%BD%E4%BB%8B%E7%BB%8D"><span class="toc-number">15.0.1.</span> <span class="toc-text">一、spring-data-redis 功能介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#redis-template-%E7%94%A8%E6%B3%95"><span class="toc-number">15.0.2.</span> <span class="toc-text">redis-template 用法</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#String"><span class="toc-number">15.0.2.0.1.</span> <span class="toc-text">String</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#List"><span class="toc-number">15.0.2.0.2.</span> <span class="toc-text">List</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Hash"><span class="toc-number">15.0.2.0.3.</span> <span class="toc-text">Hash</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Set"><span class="toc-number">15.0.2.0.4.</span> <span class="toc-text">Set</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#ZSet"><span class="toc-number">15.0.2.0.5.</span> <span class="toc-text">ZSet</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">16.</span> <span class="toc-text">企业案例</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%AB%98%E5%B9%B6%E5%8F%91%E7%A7%92%E6%9D%80%E8%B6%85%E5%8D%96"><span class="toc-number">16.0.0.0.1.</span> <span class="toc-text">高并发秒杀超卖</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%EF%BC%9A"><span class="toc-number">16.0.0.1.</span> <span class="toc-text">分布式锁：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%83%AD%E7%82%B9%E6%95%B0%E6%8D%AE"><span class="toc-number">16.0.1.</span> <span class="toc-text">热点数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%9A%E8%AF%9D%E7%BB%B4%E6%8C%81-Session"><span class="toc-number">16.0.2.</span> <span class="toc-text">会话维持 Session</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A1%A8%E7%BC%93%E5%AD%98"><span class="toc-number">16.0.3.</span> <span class="toc-text">表缓存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-list"><span class="toc-number">16.0.4.</span> <span class="toc-text">消息队列 list</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">17.</span> <span class="toc-text">企业级解决方案</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9B%B4%E6%96%B0%E4%B8%80%E8%87%B4%E6%80%A7"><span class="toc-number">17.0.1.</span> <span class="toc-text">更新一致性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E9%A2%84%E7%83%AD"><span class="toc-number">17.0.2.</span> <span class="toc-text">缓存预热</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F"><span class="toc-number">17.0.3.</span> <span class="toc-text">缓存穿透</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8"><span class="toc-number">17.0.3.1.</span> <span class="toc-text">布隆过滤器</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%93%88%E5%B8%8C%E5%87%BD%E6%95%B0%E4%B8%AA%E6%95%B0%E5%92%8C%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E9%95%BF%E5%BA%A6"><span class="toc-number">17.0.3.1.1.</span> <span class="toc-text">哈希函数个数和布隆过滤器长度</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Guava"><span class="toc-number">17.0.3.2.</span> <span class="toc-text">Guava</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E8%87%AA%E5%AE%9A%E4%B9%89"><span class="toc-number">17.0.3.2.1.</span> <span class="toc-text">分布式自定义</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#redis-%E5%AE%9E%E7%8E%B0%E7%B1%BB"><span class="toc-number">17.0.3.2.2.</span> <span class="toc-text">redis 实现类</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%BB%BA%E7%AB%8B-hash-%E5%87%BD%E6%95%B0%E6%89%80%E9%9C%80%E8%A6%81%E7%9A%84-seed"><span class="toc-number">17.0.3.2.3.</span> <span class="toc-text">建立 hash 函数所需要的 seed</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95"><span class="toc-number">17.0.3.2.4.</span> <span class="toc-text">测试</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF"><span class="toc-number">17.0.4.</span> <span class="toc-text">缓存击穿</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9"><span class="toc-number">17.0.5.</span> <span class="toc-text">缓存雪崩</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98"><span class="toc-number">17.0.6.</span> <span class="toc-text">数据一致性问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B9%B6%E5%8F%91%E7%AB%9E%E4%BA%89-Key"><span class="toc-number">17.0.7.</span> <span class="toc-text">并发竞争 Key</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87%E7%9B%91%E6%8E%A7"><span class="toc-number">17.0.8.</span> <span class="toc-text">性能指标监控</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">18.</span> <span class="toc-text">常见面试题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E5%95%A5-Redis-%E9%82%A3%E4%B9%88%E5%BF%AB%EF%BC%9F"><span class="toc-number">18.0.1.</span> <span class="toc-text">为啥 Redis 那么快？</span></a></li></ol></li></ol></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="hty-card post-block" itemscope itemtype="https://schema.org/Article"><link itemprop="mainEntityOfPage" href="https://ppxiaodi.gitee.io/2020/03/14/CollectionNote/java/%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E/Redis%E7%AC%94%E8%AE%B0(%E5%B0%9A%E7%A1%85%E8%B0%B7%E9%BB%91%E9%A9%AC%E6%95%B4%E5%90%88)/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="momo"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="我的笔记"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Redis笔记(尚硅谷黑马整合)</h1><div class="post-meta"><div class="post-time" style="display:inline-block"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <time title="创建时间：2020-03-14 00:00:00" itemprop="dateCreated datePublished" datetime="2020-03-14T00:00:00+08:00">2020-03-14</time><span class="post-meta-divider">-</span><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-2-line"></use></svg></span> <time title="修改时间：2021-07-11 16:54:54" itemprop="dateModified" datetime="2021-07-11T16:54:54+08:00">2021-07-11</time></div><div class="post-classify"><span class="post-category"> <span class="post-meta-item-icon" style="margin-right:3px;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span><span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category-item" href="/categories/java/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">java</span></a></span> > <span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category-item" href="/categories/java/%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">谷粒商城</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag-item" href="/tags/java/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">java</span></a><a class="tag-item" href="/tags/%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">谷粒商城</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body" style="--smc-primary:#0078E7;"><h1>Redis笔记(尚硅谷黑马整合)</h1>
<blockquote>
<p>图片未下载到本地</p>
</blockquote>
<blockquote>
<p>本文由 <a target="_blank" rel="noopener" href="http://ksria.com/simpread/">简悦 SimpRead</a> 转码， 原文地址 <a target="_blank" rel="noopener" href="https://blog.csdn.net/hancoder/article/details/105694186">blog.csdn.net</a></p>
</blockquote>
<p>` 笔记内容包括两个视频的笔记：</p>
<p><strong>Redis</strong>—尚硅谷 java 研究院</p>
<p>（推荐）Redis 入门到精通【黑马程序员】<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1CJ411m7Gc">https://www.bilibili.com/video/BV1CJ411m7Gc</a></p>
<h1>第 1 章 NoSQL 简介</h1>
<p>REmote Dictionary Server：是一种用 C 语言开发的开源的高性能键值对数据库。</p>
<p>1.1 技术的分类</p>
<ol>
<li>解决功能性的问题</li>
</ol>
<p>java、Servlet、Jsp、Tomcat、RDBMS、JDBC、Linux、Svn 等</p>
<ol start="2">
<li>解决扩展性的问题</li>
</ol>
<p>Spring、 SpringMVC、SpringBoot、Hibernate、MyBatis 等</p>
<ol start="3">
<li>解决性能的问题</li>
</ol>
<p>NoSQL、java 多线程、Nginx、MQ、ElasticSearch、Hadoop 等</p>
<p>1.2 WEB1.0 及 WEB2.0</p>
<ol>
<li>Web1.0 的时代, 数据访问量很有限，用一夫当关的高性能的单节点服务器可以解决大部分问题.</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/img_convert/3f762f4ca37f1e1fc12b6e740b3702cb.png" alt="" loading="lazy"></p>
<ol start="2">
<li>Web2.0 时代的到来，用户访问量大幅度提升，同时产生了大量的用户数据，加上后来的智能移动设备的普及，所有的互联网平台都面临了巨大的性能挑战.</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/img_convert/2f13cf0a03a4c0fdca1a941de99dfda4.png" alt="" loading="lazy"></p>
<p>1.3 解决服务器 CPU 内存压力</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/2dc21992a69fc02c2e75f7b301e7897a.png" alt="" loading="lazy"></p>
<p>思考: Session 共享问题如何解决?</p>
<ul>
<li>方案一、存在 Cookie 中</li>
</ul>
<p>此种方案需要将 Session 数据以 Cookie 的形式存在客户端, 不安全，网络负担效率低</p>
<ul>
<li>方案二、存在文件服务器或者是数据库里</li>
</ul>
<p>此种方案会导致大量的 IO 操作，效率低.</p>
<ul>
<li>方案三、Session 复制</li>
</ul>
<p>此种方案会导致每个服务器之间必须将 Session 广播到集群内的每个节点，Session 数据会冗余，节点越多浪费越大, 存在广播风暴问题.</p>
<ul>
<li>方案四、存在 Redis 中</li>
</ul>
<p>目前来看，此种方案是最好的。将 Session 数据存在内存中，每台服务器都从内存中读取数据, 速度快，结构还相对简单.</p>
<p>1.4 解决 IO 压力</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/b8701b1273f4fda21438a88f153dc621.png" alt="" loading="lazy"></p>
<p>将活跃的数据缓存到 Redis 中，客户端的请求先打到缓存中来获取对应的数据，如果能获取到，直接返回，不需要从 MySQL 中读取。如果缓存中没有，再从 MySQL 数据库中读取数据，将读取的数据返回并存一份到 Redis 中，方便下次读取.</p>
<p>扩展: 对于持久化的数据库来说，单个库单个表存在性能瓶颈，因此会通过水平切分、垂直切分、读取分离等技术提升性能，此种解决方案会破坏一定的业务逻辑，但是可以换取更高的性能.</p>
<h2 id="1-5-NoSQL-数据库概述"><a class="header-anchor" href="#1-5-NoSQL-数据库概述">¶</a>1.5 NoSQL 数据库概述</h2>
<ol>
<li>NoSQL(NoSQL = Not Only SQL)，意即 ==“不仅仅是 SQL”，泛指非关系型的数据库。==</li>
</ol>
<ul>
<li>NoSQL 不依赖业务逻辑方式存储，而以简单的 key-value 模式存储。因此大大的增加了数据库的扩展能力。</li>
</ul>
<ol start="2">
<li>NoSQL 的特点</li>
</ol>
<ul>
<li>不遵循 SQL 标准</li>
<li>不支持 ACID（原子性，一致性，持久性，隔离性）</li>
<li>远超于 SQL 的性能。</li>
</ul>
<ol start="3">
<li>NoSQL 的适用场景</li>
</ol>
<ul>
<li>
<p>对数据高并发的读写</p>
</li>
<li>
<p>海量数据的读写</p>
</li>
<li>
<p>对数据高可扩展性的</p>
<p>目前 NoSQL 不能完全替代关系型数据库. 使用关系型数据库结合 NoSQl 数据库进行完成项目<br>
2.3.1 当数据比较复杂时不适用于 NoSQL 数据库<br>
2.3.2 关系型数据库依然做为数据存储的主要软件.<br>
2.3.3 NoSQL 数据库当作缓存工具来使用.<br>
2.3.3.1 把某些使用频率较高的内容不仅仅存储到关系型数据库中还存储到 NoSQL 数据中<br>
2.3.3.2 考虑到: NoSQL 和关系型数据库数据同步的问题</p>
<p>Redis 持久化策略<br>
3.1 rdb 持久化策略<br>
3.1.1 默认的持久化策略.<br>
3.1.2 每隔一定时间后把内存中数据持久化到 dump.rdb 文件中</p>
<p>3.1.3 缺点:</p>
<p>3.1.3.1 数据过于集中.（都存储到了一个文件中）<br>
3.1.3.2 可能导致最后的数据没有持久化到 dump.rdb 中（因为是每隔一段时间）<br>
3.1.3.2.1 解决办法: 使用命令: SAVE 或 BGSAVE 手动持久<br>
化.<br>
3.2 aof 持久化策略<br>
3.2.1 监听 Redis 的日志文件, 监听如果发现执行了修改, 删除,<br>
新增命令. 立即根据这条命令把数据持久化.<br>
3.2.2 缺点:<br>
3.2.2.1 效率降低</p>
</li>
</ul>
<ol start="4">
<li>NoSQL 的不适用场景</li>
</ol>
<ul>
<li>需要事务支持</li>
<li>基于 sql 的结构化查询存储，处理复杂的关系, 需要即席查询。</li>
</ul>
<ol start="5">
<li>建议: 用不着 sql 的和用了 sql 也不行的情况，请考虑用 NoSql</li>
</ol>
<p>1.6 常用的缓存数据库</p>
<ol>
<li>Memcached</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/img_convert/4302813ffe99025c091ba0b17d46934a.png" alt="" loading="lazy"></p>
<ol start="2">
<li>Redis</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/img_convert/7d9fedfe2c35fe6562810857c7d37580.png" alt="" loading="lazy"></p>
<ol start="3">
<li>mongoDB</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/img_convert/1cfe469776490e08960eb6d9b3b105ff.png" alt="" loading="lazy"></p>
<ol start="4">
<li>列式数据库</li>
</ol>
<ul>
<li>先看行式数据库</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/img_convert/d4092a5559ef78c96bc17d1e6c67225e.png" alt="" loading="lazy"></p>
<p>思考: 如下两条 SQL 的快慢</p>
<p>​ select * from users where id =3（快）</p>
<p>​ select avg(age) from users（慢）需要先查行年龄，再平均</p>
<ul>
<li>再看列式数据库</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/img_convert/4447bd90ad836f57fd22c26220b94f4c.png" alt="" loading="lazy"></p>
<p>列式数据库对查平均快</p>
<ol start="5">
<li>HBase</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/img_convert/142dc418532cefaf2ac0f9adb06bd8c3.png" alt="" loading="lazy"></p>
<ol start="6">
<li>Cassandra</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/img_convert/b51178bf59d34c0d5bd9a44e8b4ff831.png" alt="" loading="lazy"></p>
<ol start="7">
<li>Neo4j</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/img_convert/1d8b031a190e2dd8706bd5abcc649bc6.png" alt="" loading="lazy"></p>
<p>1.7 数据库排名</p>
<p><a target="_blank" rel="noopener" href="http://db-engines.com/en/ranking">http://db-engines.com/en/ranking</a></p>
<h1>第 2 章 Redis 简介 及 安装</h1>
<p>2.1 Redis 是什么</p>
<p>简单来说 redis 就是一个数据库，不过与传统数据库不同的是 redis 的数据是存在内存中的，所以读写速度非常快，因此 redis 被广泛应用于缓存方向。另外，redis 也经常用来做分布式锁。redis 提供了多种数据类型来支持不同的业务场景。除此之外，redis 支持事务 、持久化、LUA 脚本、LRU 驱动事件、多种集群方案。</p>
<p>Redis 是一个开源的 key-value 存储系统。</p>
<p>是完全开源免费的，用 c 语言编写的，是一个单线程，高性能的（key/value）内存数据库，基于内存运行并支持持久化的 nosql 数据库</p>
<p>和 Memcached 类似，它支持存储的 value 类型相对更多，包括 string(字符串)、list(链表)、set(集合)、zset(sorted set – 有序集合) 和 hash（哈希类型）。这些数据类型都支持 push/pop、add/remove 及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，Redis 支持各种不同方式的排序。</p>
<p>与 memcached 一样，为了保证效率，数据都是缓存在内存中。区别的是 Redis 会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了 master-slave(主从) 同步。</p>
<h2 id="2-2-Redis-的应用场景"><a class="header-anchor" href="#2-2-Redis-的应用场景">¶</a>2.2 Redis 的应用场景</h2>
<ol>
<li>配合关系型数据库做高速缓存</li>
</ol>
<ul>
<li>高频次，热门访问的数据，降低数据库 IO</li>
</ul>
<ol start="2">
<li>由于其拥有持久化能力，利用其多样的数据结构存储特定的数据</li>
</ol>
<ul>
<li>最新 N 个数据→通过 List 实现按自然事件排序的数据</li>
<li>排行榜，TopN→利用 zset(有序集合)</li>
<li>时效性的数据，比如手机验证码→Expire 过期</li>
<li>计数器，秒杀→原子性，自增方法 INCR、DECR</li>
<li>去除大量数据中的重复数据→利用 set 集合</li>
<li>构建队列→利用 list 集合</li>
<li>发布订阅消息系统→pub/sub 模式</li>
</ul>
<p>2.3 Redis 官网</p>
<ol>
<li>
<p>Redis 官方网站 <a target="_blank" rel="noopener" href="http://Redis.io">http://Redis.io</a></p>
</li>
<li>
<p>Redis 中文官方网站 <a target="_blank" rel="noopener" href="http://www.Redis.net.cn">http://www.Redis.net.cn</a></p>
</li>
</ol>
<p>手册网址： <a target="_blank" rel="noopener" href="http://doc.redisfans.com/">http://doc.redisfans.com/</a></p>
<p>2.4 关于 Redis 版本</p>
<ol>
<li>
<p>3.2.5 for Linux</p>
</li>
<li>
<p>不用考虑在 Windows 环境下对 Redis 的支持</p>
</li>
</ol>
<p>Redis 官方没有提供对 Windows 环境的支持，是微软的开源小组开发了对 Redis 对 Windows 的支持.</p>
<h2 id="2-5-安装步骤"><a class="header-anchor" href="#2-5-安装步骤">¶</a>2.5 安装步骤</h2>
<pre class="line-numbers language-none"><code class="language-none">1)    下载获得redis-3.2.5.tar.gz后将它放入我们的Linux目录&#x2F;opt
wget http:&#x2F;&#x2F;......tar.gz
2)    解压命令:&#96;tar -zxvf redis-3.2.5.tar.gz&#96;

3)    解压完成后进入目录:&#96;cd redis-3.2.5&#96;

4)    在redis-3.2.5目录下执行make命令
编译：make
cd src
安装：make install 
或make PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;redis install
# PREFIX&#x3D; 这个关键字的作用是编译的时候用于指定程序存放的路径。比如我们现在就是指定了redis必须存放在&#x2F;usr&#x2F;local&#x2F;redis目录。假设不添加该关键字Linux会将可执行文件存放在&#x2F;usr&#x2F;local&#x2F;bin目录，

5）执行
默认生成的可执行文件在&#x2F;usr&#x2F;local&#x2F;bin中
&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-server &amp; .&#x2F;redis.conf

创建软链接
ln -s 原始目录名 快速访问目录名<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol start="5">
<li>安装 gcc 与 g++</li>
</ol>
<p>运行 Make 命令时出现错误, 提示 gcc：命令未找到 , 原因是因为当前 Linux 环境中并没有安装 gcc 与 g++ 的环境</p>
<ul>
<li>能上网的情况:</li>
</ul>
<p>yum install gcc</p>
<p>yum install gcc-c++</p>
<ol start="6">
<li>重新进入到 Redis 的目录中执行 make distclean 后再执行 make 命令.</li>
</ol>
<pre class="line-numbers language-none"><code class="language-none">Hint: It&#39;s a good idea to run &#39;make test&#39; ;)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<ol start="7">
<li>执行完 make 后，可跳过 Redis test 步骤，直接执行 make install</li>
</ol>
<pre class="line-numbers language-none"><code class="language-none">INSTALL install
    INSTALL install
    INSTALL install
    INSTALL install
    INSTALL install
    make[1]: Leaving directory &#39;&#x2F;home&#x2F;ftp&#x2F;redis&#x2F;redis-3.0.4&#x2F;src&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>2.6 查看默认安装目录 /usr/local/bin</p>
<blockquote>
<p>放到这个目录下之后，可以在任何目录下访问。</p>
</blockquote>
<ol>
<li>
<p>Redis-benchmark: 性能测试工具，可以在自己本子运行，看看自己本子性能如何 (服务启动起来后执行)</p>
</li>
<li>
<p>Redis-check-aof：修复有问题的 AOF 文件，rdb 和 aof 后面讲</p>
</li>
<li>
<p>Redis-check-dump：修复有问题的 dump.rdb 文件</p>
</li>
<li>
<p>Redis-sentinel：Redis 集群使用</p>
</li>
<li>
<p>Redis-server：前台启动 Redis</p>
</li>
</ol>
<pre class="line-numbers language-none"><code class="language-none">_._                                                  
           _.-&#96;&#96;__ &#39;&#39;-._                                             
      _.-&#96;&#96;    &#96;.  &#96;_.  &#39;&#39;-._           Redis 3.0.4 (00000000&#x2F;0) 64 bit
  .-&#96;&#96; .-&#96;&#96;&#96;.  &#96;&#96;&#96;\&#x2F;    _.,_ &#39;&#39;-._                                   
 (    &#39;      ,       .-&#96;  | &#96;,    )     Running in standalone mode
 |&#96;-._&#96;-...-&#96; __...-.&#96;&#96;-._|&#39;&#96; _.-&#39;|     Port: 6379
 |    &#96;-._   &#96;._    &#x2F;     _.-&#39;    |     PID: 26926
  &#96;-._    &#96;-._  &#96;-.&#x2F;  _.-&#39;    _.-&#39;                                   
 |&#96;-._&#96;-._    &#96;-.__.-&#39;    _.-&#39;_.-&#39;|                                  
 |    &#96;-._&#96;-._        _.-&#39;_.-&#39;    |           http:&#x2F;&#x2F;redis.io        
  &#96;-._    &#96;-._&#96;-.__.-&#39;_.-&#39;    _.-&#39;                                   
 |&#96;-._&#96;-._    &#96;-.__.-&#39;    _.-&#39;_.-&#39;|                                  
 |    &#96;-._&#96;-._        _.-&#39;_.-&#39;    |                                  
  &#96;-._    &#96;-._&#96;-.__.-&#39;_.-&#39;    _.-&#39;                                   
      &#96;-._    &#96;-.__.-&#39;    _.-&#39;                                       
          &#96;-._        _.-&#39;                                           
              &#96;-.__.-&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这是前台启动，我们要把他设置为后台启动。</p>
<ol start="6">
<li>redis-cli：客户端，操作入口</li>
</ol>
<h2 id="2-7-Redis-的启动"><a class="header-anchor" href="#2-7-Redis-的启动">¶</a>2.7 Redis 的启动</h2>
<ol>
<li>默认前台方式启动</li>
</ol>
<ul>
<li>直接执行<code>redis-server</code> 即可启动后不能操作当前命令窗口</li>
</ul>
<ol start="2">
<li>推荐后台方式启动</li>
</ol>
<ul>
<li>拷贝一份 redis.conf 配置文件到其他目录，例如根目录下的 myredis 目录 /myredis</li>
<li>修改 redis.conf 文件中的一项配置 daemonize 将 no 改为 yes，代表后台启动</li>
<li>设置自己的端口号</li>
<li>执行配置文件进行启动 执行 <code>redis-server /myredis/redis.conf</code></li>
<li>ps -ef | grep 进程名</li>
<li>kill -s 9 进程号</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none">ouc-13   26926 22709  0 15:30 pts&#x2F;4    00:00:00 redis-server *:6379
ouc-13   29372 28429  0 15:49 pts&#x2F;3    00:00:00 grep --color&#x3D;auto redis
端口号是6379<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-none"><code class="language-none">daemonize yes
#以守护进程方式启动，使用本启动方式， redis将以服务的形式存在，日志将不再打印到命令窗口中
port 6379
#设定当前服务启动端口号
dir &quot;&#x2F;自定义目录&#x2F;redis&#x2F;data&quot;
#设定当前服务文件保存位置，包含日志文件、持久化文件（后面详细讲解）等
logfile &quot;6***.log“
#设定日志文件名，便于查阅<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="启动多个-redis"><a class="header-anchor" href="#启动多个-redis">¶</a>启动多个 redis</h4>
<p>复制 conf 文件</p>
<p>改 port</p>
<p>改 pidfile</p>
<p>改 logfile</p>
<p>改 dir，每个不一样</p>
<p>集群配置：</p>
<p>cluster-enabled yes 打开注释</p>
<p>cluster-config-file nodes-6379.conf 打开注释并修改（可不改）</p>
<p>当你安装完成之后，你可以先执行 <code>redis-server</code> 让 Redis 启动起来，然后运行命令 <code>redis-benchmark -n 100000 -q</code> 来检测本地同时执行 10 万个请求时的性能：</p>
<pre class="line-numbers language-none"><code class="language-none">redis-cli -h localhost -p 6379<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h2 id="2-9-关闭-Redis-服务"><a class="header-anchor" href="#2-9-关闭-Redis-服务">¶</a>2.9 关闭 Redis 服务</h2>
<ol>
<li>单实例关闭</li>
</ol>
<ul>
<li>如果还未通过客户端访问，可直接 <code>redis-cli shutdown</code></li>
<li>如果已经进入客户端, 直接 shutdown 即可.</li>
</ul>
<ol start="2">
<li>多实例关闭</li>
</ol>
<p>l 指定端口关闭 redis-cli -p 端口号 shutdown</p>
<p>如何启动多个 redis：</p>
<pre class="line-numbers language-none"><code class="language-none">#默认配置启动
redis-server
redis-server –-port 6379
redis-server –-port 6380 ……
# 指定配置文件启动
redis-server redis.conf
redis-server redis-6379.conf
redis-server redis-6380.conf ……
redis-server conf&#x2F;redis-6379.conf
redis-server config&#x2F;redis-6380.conf ……
#默认连接
redis-cli
#连接指定服务器
redis-cli -h 127.0.0.1
redis-cli –port 6379
redis-cli -h 127.0.0.1 –port 6379<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="2-10-Redis-默认-16-个库"><a class="header-anchor" href="#2-10-Redis-默认-16-个库">¶</a>2.10 Redis 默认 16 个库</h2>
<ol>
<li>
<p>Redis 默认创建 16 个库, 每个库对应一个下标, 从 0 开始。通过客户端连接后默认进入到 0 号库，推荐只使用 0 号库.</p>
</li>
<li>
<p>使用命令 <code>select 库的下标</code> 来切换数据库，例如 <code>select 8</code></p>
</li>
</ol>
<p>统一的密码管理：所有库都是同样密码，要么都 OK，要么一个都连不上</p>
<h2 id="2-11-Redis-的单线程-多路-IO-复用技术"><a class="header-anchor" href="#2-11-Redis-的单线程-多路-IO-复用技术">¶</a>2.11 Redis 的单线程 + 多路 IO 复用技术</h2>
<h4 id="1-1-流的概念"><a class="header-anchor" href="#1-1-流的概念">¶</a>1.1 流的概念</h4>
<p>一个流可以文件、socket、pipe 等可以进行 IO 操作的内核对象。不管是文件，还是套接字，还是管道，我们都可以把他们看作流。</p>
<p>从<strong>流</strong>中读取数据或者写入数据到流中，可能存在这样的情况：①读取数据时，流中还没有数据；②写入数据时，流中数据已经满了，没有空间写入了。典型的例子为客户端要从 socket 流中读入数据，但是服务器还没有把数据准备好。此时有两种处理办法：</p>
<ul>
<li>阻塞，等待数据准备好了，再读取出来返回；</li>
<li>非阻塞，通过轮询的方式，查询是否有数据可以读取，直到把数据读取返回。</li>
</ul>
<p>接下来再来了解以下 I/O 同步、异步、阻塞、非阻塞的概念。</p>
<ul>
<li>1.redis 是基于内存的，内存的读写速度非常快（纯内存）。</li>
<li>2.redis 是单线程的，省去了很多上下文切换线程的时间（避免线程切换和竞态消耗）。</li>
<li>3.redis 使用多路复用技术，可以处理并发的连接（非阻塞 IO 即 NIO）。</li>
</ul>
<p>非阻塞 IO 内部实现采用<code>epoll</code>，采用了 epoll + 自己实现的简单的事件框架。epoll 中的读、写、关闭、连接都转化成了事件，然后利用 epoll 的多路复用特性，绝不在 io 上浪费一点时间。</p>
<ol>
<li>
<p>多路复用是指使用一个线程来检查多个文件描述符（Socket）的就绪状态，比如调用 select 和 poll 函数，传入多个文件描述符，如果有一个文件描述符就绪，则返回，否则阻塞直到超时。得到就绪状态后进行真正的操作可以在同一个线程里执行，也可以启动线程执行（比如使用线程池）。</p>
</li>
<li>
<p>Memcached 是 多线程 + 锁 ；Redis 是 单线程 + 多路 IO 复用.</p>
</li>
</ol>
<blockquote>
<p><strong>1. 阻塞 IO</strong>, 给女神发一条短信, 说我来找你了, 然后就默默的一直等着女神下楼, 这个期间除了等待你不会做其他事情, 属于备胎做法.</p>
</blockquote>
<blockquote>
<p><strong>2 非阻塞 IO</strong>, 给女神发短信, 如果不回, 接着再发, 一直发到女神下楼, 这个期间你除了发短信等待不会做其他事情, 属于专一做法.</p>
</blockquote>
<blockquote>
<p><strong>3 IO 多路复用</strong>, 是找一个宿管大妈来帮你监视下楼的女生, 这个期间你可以些其他的事情. 例如可以顺便看看其他妹子, 玩玩王者荣耀, 上个厕所等等. IO 复用又包括 select, poll, epoll 模式. 那么它们的区别是什么?<br>
3.1 <strong>select 大妈</strong> 每一个女生下楼, select 大妈都不知道这个是不是你的女神, 她需要一个一个询问, 并且 select 大妈能力还有限, 最多一次帮你监视 1024 个妹子。对应的编程模型就是：一个连接来了，就必须<strong>遍历所有已经注册的文件描述符</strong>，来找到那个需要处理信息的文件描述符，如果已经注册了几万个文件描述符，那会因为遍历这些已经注册的文件描述符，导致 cpu 爆炸。</p>
<p>3.2 <strong>poll 大妈</strong>不限制盯着女生的数量, 只要是经过宿舍楼门口的女生, 都会帮你去问是不是你女神<br>
3.3 <strong>epoll 大妈</strong>不限制盯着女生的数量, 并且也不需要一个一个去问. 那么如何做呢? epoll 大妈会为每个 == 进宿舍楼的女生脸上贴上一个大字条,== 上面写上女生自己的名字, 只要女生下楼了, epoll 大妈就知道这个是不是你女神了, 然后大妈再通知你.</p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/28594409">https://www.zhihu.com/question/28594409</a></p>
<p>上面这些同步 IO 有一个共同点就是, 当女神走出宿舍门口的时候, 你已经站在宿舍门口等着女神的, 此时你属于<strong>阻塞状态</strong></p>
<p>一个 epoll 场景：一个酒吧服务员（一个线程），前面趴了一群醉汉，突然一个吼一声 “倒酒”（事件），你小跑过去给他倒一杯，然后随他去吧，突然又一个要倒酒，你又过去倒上，就这样一个服务员服务好多人，有时没人喝酒，服务员处于空闲状态，可以干点别的玩玩手机。至于 epoll 与 select，poll 的区别在于后两者的场景中醉汉不说话，你要挨个问要不要酒，没时间玩手机了。io 多路复用大概就是指这几个醉汉共用一个服务员。</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/happy_wu/article/details/80052617">https://blog.csdn.net/happy_wu/article/details/80052617</a></p>
</blockquote>
<blockquote>
<p>接下来是<strong>异步 IO</strong> 的情况<br>
你告诉女神我来了, 然后你就去王者荣耀了, 一直到女神下楼了, 发现找不见你了, 女神再给你打电话通知你, 说我下楼了, 你在哪呢? 这时候你才来到宿舍门口. 此时属于逆袭做法</p>
</blockquote>
<p><strong>为什么 Redis 中要使用 I/O 多路复用这种技术呢？</strong></p>
<p>首先，Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而 <strong>I/O 多路复用</strong>就是为了解决这个问题而出现的。</p>
<p><strong>要弄清问题先要知道问题的出现原因</strong></p>
<p>由于进程的执行过程是线性的 (也就是顺序执行)，当我们调用低速系统 I/O(read，write，accept 等等)，进程可能阻塞，此时进程就阻塞在这个调用上，不能执行其他操作。阻塞很正常， 接下来考虑这么一个问题：一个服务器进程和一个客户端进程通信，服务器端 read(sockfd1,bud,bufsize)，此时客户端进程没有发送数据，那么 read(阻塞调用) 将阻塞直到客户端 write(sockfd,but,size)发来数据。在一个客户和服务器通信时这没什么问题，当多个客户与服务器通信时，若服务器阻塞于其中一个客户 sockfd1，当另一个客户的数据到达套接字 sockfd2 时，服务器仍不能处理，仍然阻塞在 read(sockfd1,…) 上。此时问题就出现了，不能及时处理另一个客户的服务，肿么办？I/O 多路复用来解决！</p>
<p>继续上面的问题，有多个客户连接，sockfd1、sockfd2、sockfd3…sockfdn 同时监听这 n 个客户，当其中有一个发来消息时就从 select 的阻塞中返回，然后就调用 read 读取收到消息的 sockfd，然后又循环回 select 阻塞；这样就不会因为阻塞在其中一个上而不能处理另一个客户的消息。</p>
<p>Q：<br>
那这样子，在读取 socket1 的数据时，如果其它 socket 有数据来，那么也要等到 socket1 读取完了才能继续读取其它 socket 的数据吧。那不是也阻塞住了吗？而且读取到的数据也要开启线程处理吧，那这和多线程 I/O 有什么区别呢？</p>
<p>A：<br>
1.CPU 本来就是线性的，不论什么都需要顺序处理，并行只能是多核 CPU。</p>
<p>2.I/O 多路复用本来就是用来解决对多个 I/O 监听时，一个 I/O 阻塞影响其他 I/O 的问题，跟多线程没关系。</p>
<ol start="3">
<li>跟多线程相比较，线程切换需要切换到内核进行线程切换，需要消耗时间和资源。而 I/O 多路复用不需要切换线 / 进程，效率相对较高，特别是对高并发的应用 nginx 就是用 I/O 多路复用，故而性能极佳。但多线程编程逻辑和处理上比 I/O 多路复用简单，而 I/O 多路复用处理起来较为复杂。</li>
</ol>
<p>理解 IO 多路复用</p>
<h3 id="什么是-I-O-多路复用"><a class="header-anchor" href="#什么是-I-O-多路复用">¶</a>什么是 I/O 多路复用</h3>
<p>关于 I/O 多路复用 (又被称为 “事件驱动”)，首先要理解的是，操作系统为你提供了一个功能，当你的某个 socket 可读或者可写的时候，它可以给你一个通知。这样当配合非阻塞的 socket 使用时，只有当系统通知我哪个描述符可读了，我才去执行 read 操作，可以保证每次 read 都能读到有效数据而不做纯返回 - 1 和 EAGAIN 的无用功。写操作类似。操作系统的这个功能通过<code>select/poll/epoll/kqueue</code>之类的系统调用函数来使用，这些函数都可以同时监视多个描述符的读写就绪状况，这样，多个描述符的 I/O 操作都能在一个线程内并发交替地顺序完成，这就叫 I/O 多路复用，这里的 “复用” 指的是复用同一个线程。</p>
<p>I/O 多路复用其实是在单个线程中通过记录跟踪每一个 sock（I/O 流） 的状态来管理多个 I/O 流。结合下图可以清晰地理解 I/O 多路复用。</p>
<p><img src="https://img-blog.csdn.net/2018042316482657" alt="" loading="lazy"></p>
<p>select, poll, epoll 都是 I/O 多路复用的具体的实现。epoll 性能比其他几者要好。redis 中的 I/O 多路复用的所有功能通过包装常见的 select、epoll、evport 和 kqueue 这些 I/O 多路复用函数库来实现的。</p>
<h3 id="Reactor（反应器模式）"><a class="header-anchor" href="#Reactor（反应器模式）">¶</a>Reactor（反应器模式）</h3>
<p>IO 多路复用模型是建立在内核提供的多路分离函数 select 基础之上的，使用 select 函数可以避免同步非阻塞 IO 模型中轮询等待的问题。</p>
<ul>
<li>用户线程监视一个 socket，socket 把监视信息注册到内核缓存 recvBuf，等待数据到达，（用户线程不阻塞）</li>
<li>数据到达之后，内核发送 socket 刻度信息，用户线程发送 read 请求去从 recvBuf 中读数据</li>
<li>read 完成</li>
</ul>
<p><img src="https://images.cnitblog.com/blog/405877/201411/142332187256396.png" alt="" loading="lazy"></p>
<p>多路分离函数 select</p>
<p>如上图所示，用户线程发起请求的时候，首先会将需要进行 IO 操作的 socket 添加到 select 中，这时阻塞等待 select 函数返回。当数据到达时，select 被激活，select 函数返回，此时用户线程才正式发起 read 请求，读取数据并继续执行。</p>
<p>从流程上来看，使用 select 函数进行 I/O 请求和同步阻塞模型没有太大的区别，甚至还多了添加监视 socket，以及调用 select 函数的额外操作，效率更差。但是，使用 select 以后最大的优势是用户可以在一个线程内同时处理多个 socket 的 I/O 请求。用户可以注册多个 socket，然后不断地调用 select 读取被激活的 socket，即可达到在同一个线程内同时处理多个 I/O 请求的目的。而在同步阻塞模型中，必须通过多线程的方式才能达到这个目的。</p>
<pre class="line-numbers language-none"><code class="language-none">用户线程使用select函数的伪代码描述为：

&#123;
   select(socket);&#x2F;&#x2F;将需要进行IO操作的socket加入到select中

   while(1) &#123;
       sockets &#x3D; select();&#x2F;&#x2F;获取被激活的socket
       for(socket in sockets) &#123;
           if(can_read(socket)) &#123;&#x2F;&#x2F;拿被激活的socket去读
               read(socket, buffer);&#x2F;&#x2F;从socket中把数据库读到buffer中
               process(buffer);&#x2F;&#x2F;处理缓存中的数据
           &#125;
       &#125;
   &#125;
&#125;

其中while循环前将socket添加到select监视中，然后在while内一直调用select获取被激活的socket，一旦socket可读，便调用read函数将socket中的数据读取出来。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>然而，使用 select 函数的优点并不仅限于此。虽然上述方式允许单线程内处理多个 IO 请求，但是每个 IO 请求的过程还是阻塞的（在 select 函数上阻塞），平均时间甚至比同步阻塞 IO 模型还要长。如果用户线程只注册自己感兴趣的 socket 或者 IO 请求，然后去做自己的事情，等到数据到来时再进行处理，则可以提高 CPU 的利用率。</p>
<p>IO 多路复用模型使用了 Reactor 设计模式实现了这一机制。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/b10b0726836cde472bc27abdc23b2a9a.png" alt="" loading="lazy"></p>
<p>EventHandler 抽象类表示 IO 事件处理器，它拥有 IO 文件句柄 Handle（通过 get_handle 获取），以及对 Handle 的操作 handle_event（读 / 写等）。继承于 EventHandler 的子类可以对事件处理器的行为进行定制。Reactor 类用于管理 EventHandler（注册、删除等），并使用 handle_events 实现事件循环，不断调用同步事件多路分离器（一般是内核）的多路分离函数 select，只要某个文件句柄被激活（可读 / 写等），select 就返回（阻塞），handle_events 就会调用与文件句柄关联的事件处理器的 handle_event 进行相关操作。</p>
<p><img src="https://img-blog.csdn.net/20180423171630284" alt="" loading="lazy"></p>
<p>如上图，I/O 多路复用模型使用了 Reactor 设计模式实现了这一机制。通过 Reactor 的方式，可以将用户线程轮询 I/O 操作状态的工作统一交给 handle_events 事件循环进行处理。用户线程注册事件处理器之后可以继续执行做其他的工作（异步），而 Reactor 线程负责调用内核的 select 函数检查 socket 状态。当有 socket 被激活时，则通知相应的用户线程（或执行用户线程的回调函数），执行 handle_event 进行数据读取、处理的工作。由于 select 函数是阻塞的，因此多路 I/O 复用模型也被称为<strong>异步阻塞 I/O 模型</strong>。注意，这里的所说的阻塞是指 select 函数执行时线程被阻塞，而不是指 socket。一般在使用 I/O 多路复用模型时，socket 都是设置为 NONBLOCK 的，不过这并不会产生影响，因为用户发起 I/O 请求时，数据已经到达了，用户线程一定不会被阻塞。</p>
<pre class="line-numbers language-none"><code class="language-none">void UserEventHandler::handle_event() &#123;

    if(can_read(socket)) &#123;
        read(socket, buffer);
        process(buffer);
    &#125;
&#125;



&#123;
    Reactor.register(new UserEventHandler(socket));
&#125;

&#x2F;&#x2F;用户需要重写EventHandler的handle_event函数进行读取数据、处理数据的工作，用户线程只需要将自己的EventHandler注册到Reactor即可。Reactor中handle_events事件循环的伪代码大致如下。

Reactor::handle_events() &#123;
    while(1) &#123;
        sockets &#x3D; select();
        for(socket in sockets) &#123;
            get_event_handler(socket).handle_event();
        &#125;
    &#125;
&#125;

&#x2F;&#x2F;事件循环不断地调用select获取被激活的socket，然后根据获取socket对应的EventHandler，执行器handle_event函数即可。

IO多路复用是最常使用的IO模型，但是其异步程度还不够“彻底”，因为它使用了会阻塞线程的select系统调用。因此IO多路复用只能称为异步阻塞IO，而非真正的异步IO。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/happy_wu/article/details/80052617">https://blog.csdn.net/happy_wu/article/details/80052617</a></p>
<h2 id="总结"><a class="header-anchor" href="#总结">¶</a>总结</h2>
<p>I/O 多路复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。这里 “多路” 指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快（内存内的操作不会成为这里的性能瓶颈），主要以上两点造就了 Redis 具有很高的吞吐量。</p>
<p>IO 多路复用总结：</p>
<p>redis 采用网络 IO 多路复用技术，来保证在多连接的时候系统的高吞吐量。</p>
<p>多路 - 指的是多个 socket 网络连接，复用 - 指的是复用一个线程。</p>
<p>多路复用主要有三种技术：<code>select，poll，epoll</code>。epoll 是最新的、也是目前最好的多路复用技术。</p>
<p>采用多路 I/O 复用技术：其一，可以让单个线程高效处理多个连接请求（尽量减少网络 IO 的时间消耗）。其二，Redis 在内存中操作数据的速度非常快（内存里的操作不会成为这里的性能瓶颈）。主要以上两点造就了 Redis 具有很高的吞吐量。</p>
<h3 id="二、为什么-Redis-是单线程的"><a class="header-anchor" href="#二、为什么-Redis-是单线程的">¶</a><strong>二、为什么 Redis 是单线程的</strong></h3>
<p><strong>2.1. 官方答案</strong></p>
<p>因为 Redis 是基于内存的操作，CPU 不是 Redis 的瓶颈，Redis 的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且 CPU 不会成为瓶颈，那就顺理成章地采用单线程的方案了。</p>
<p><strong>2.2. 性能指标</strong></p>
<p>关于 redis 的性能，官方网站也有，普通笔记本轻松处理每秒几十万的请求。</p>
<p><strong>2.3. 详细原因</strong></p>
<p><strong>1）不需要各种锁的性能消耗</strong></p>
<p>Redis 的数据结构并不全是简单的 Key-Value，还有 list，hash 等复杂的结构，这些结构有可能会进行很细粒度的操作，比如在很长的列表后面添加一个元素，在 hash 当中添加或者删除一个对象。这些操作可能就需要加非常多的锁，导致的结果是同步开销大大增加。</p>
<p>总之，在单线程的情况下，就不用去考虑各种锁的问题，不存在加锁、释放锁操作，没有因为可能出现死锁而导致的性能消耗。</p>
<p><strong>2）单线程多进程集群方案</strong></p>
<p>单线程的威力实际上非常强大，单核 cpu 效率也非常高，多线程自然是可以比单线程有更高的性能上限，但是在今天的计算环境中，即使是单机多线程的上限也往往不能满足需要了，需要进一步摸索的是多服务器集群化的方案，这些方案中多线程的技术照样是用不上的。</p>
<p>** 所以 “单线程、多进程的集群” 不失为一个时髦的解决方案。** 我们需要的是机器内存</p>
<p><strong>3）CPU 消耗</strong></p>
<p>采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU。</p>
<p>但是如果 CPU 成为 Redis 瓶颈，或者不想让服务器其他 CUP 核闲置，那怎么办？</p>
<p>可以考虑多起几个 Redis 进程，Redis 是 key-value 数据库，不是关系数据库，数据之间没有约束。只要客户端分清哪些 key 放在哪个 Redis</p>
<h1>第 3 章 Redis 的五大数据类型</h1>
<p>string String</p>
<p>hash HashMap</p>
<p>list LinkedList</p>
<p>set HashSet</p>
<p>sorted set TreeSet</p>
<h2 id="3-0-key-基本命令"><a class="header-anchor" href="#3-0-key-基本命令">¶</a>3.0 key 基本命令</h2>
<p><a target="_blank" rel="noopener" href="http://www.redis.cn/commands.html">http://www.redis.cn/commands.html</a></p>
<table><thead><tr><th>命令</th><th>说明</th></tr></thead><tbody><tr><td><code>keys *</code></td><td>查看当前库的所有键，支持正则</td></tr><tr><td><code>exists &lt;key&gt;</code></td><td>判断某个键是否存在</td></tr><tr><td><code>type &lt;key&gt;</code></td><td>查看键的类型</td></tr><tr><td><code>del &lt;key&gt;</code></td><td>删除某个键</td></tr><tr><td><code>expire &lt;key&gt; &lt;seconds&gt;</code></td><td>为键值设置过期时间，单位秒</td></tr><tr><td><code>ttl &lt;key&gt;</code></td><td>查看还有多久过期，返回 - 1 表示永不过期，-2 表示已过期</td></tr><tr><td>dbsize</td><td>查看当前数据库中 key 的数量</td></tr><tr><td>flushdb</td><td>清空当前库</td></tr><tr><td>Flushall</td><td>通杀全部库</td></tr><tr><td>move key db</td><td>移动 key，从当前库移动到 db 库</td></tr></tbody></table>
<pre class="line-numbers language-none"><code class="language-none"># 设置key有效期
expire key seconds
pexpire key milliseconds
expireat key timestamp
pexpireat key milliseconds-timestamp

# 查询key有效时间 [time to live]
ttl key # 如果key不存在或者已过期，返回 -2。如果key存在并且没有设置过期时间（永久有效），返回 -1 。整数代表有效秒数
pttl key # 毫秒数

# 切换key从时效性转换为永久性
persist key

查询匹配的key值
keys pattern正则

其他操作
rename key newkey
renamenx key newkey

排序key
sort
sort list1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>key 的重复问题：</p>
<p>key 是由程序员定义的</p>
<ul>
<li>redis 在使用过程中，伴随着操作数据量的增加，会出现大量的数据以及对应的 key</li>
<li>数据不区分种类、类别混杂在一起，极易出现重复或冲突</li>
</ul>
<p>解决方案：</p>
<p>redis 为每个服务提供有 16 个数据库，编号从 0 到 15</p>
<ul>
<li>每个数据库之间的数据相互独立</li>
<li>这些数据库共用一块空间，没有空间大小之分</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none">select index #切换数据库
quit
ping #返回PONG代表连通
echo

move key db #移动到另外一个库
dbsize
flushdb # 删除掉当前库数据
flushall # 删除掉所有库<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="3-1-String"><a class="header-anchor" href="#3-1-String">¶</a>3.1 String</h2>
<ol>
<li>
<p>String 是 Redis 最基本的类型，你可以理解成与 Memcached 一模一样的类型，一个 key 对应一个 value</p>
</li>
<li>
<p>String 类型是二进制安全的。意味着 Redis 的 string 可以包含任何数据。比如 jpg 图片或者序列化的对象 。</p>
</li>
<li>
<p>String 类型是 Redis 最基本的数据类型，一个 Redis 中字符串 value 最多可以是 512M</p>
</li>
<li>
<p>常用操作</p>
</li>
</ol>
<p>m：multiple</p>
<p>为什么有 m 的操作：发送命令还需要时长</p>
<table><thead><tr><th>命令</th><th>说明</th></tr></thead><tbody><tr><td><code>get &lt;key&gt;</code></td><td>查询对应键值</td></tr><tr><td><code>set &lt;key&gt; &lt;value&gt;</code></td><td>添加键值对</td></tr><tr><td><code>append &lt;key&gt; &lt;value&gt;</code></td><td>将给定的<code>&lt;value&gt;</code>追加到原值的末尾 ，返回的长度</td></tr><tr><td><code>strlen &lt;key&gt;</code></td><td>获取值的长度，不包括 \ 0</td></tr><tr><td><code>setnx &lt;key&gt; &lt;value&gt;</code></td><td>只有在 key 不存在时设置 key 的值</td></tr><tr><td><mark><code>incr &lt;key&gt;</code></mark></td><td>将 key 中存储的数字值增 1 只能对数字值操作，如果为空，新增值为 1</td></tr><tr><td><mark><code>decr &lt;key&gt;</code></mark></td><td>将 key 中存储的数字值减 1 只能对数字之操作，如果为空, 新增值为 - 1</td></tr><tr><td><mark><code>incrby/decrby &lt;key&gt; 步长</code></mark>、<br><mark><code>incrbyfloat key 值</code></mark></td><td>将 key 中存储的数字值增减，自定义步长。值可正可负，但小数得用 float。操作具有原子性，命令都是一个一个执行的，所以<mark>安全</mark>。超过上限或原来不是数会报错。</td></tr><tr><td><mark><code>mset &lt;key1&gt; &lt;value1&gt; &lt;key2&gt; &lt;value2&gt;</code></mark></td><td>同时设置一个或多个 key-value 对</td></tr><tr><td><code>mget &lt;key1&gt; &lt;key2&gt; &lt;key3&gt;</code></td><td>同时获取一个或多个 value</td></tr><tr><td><code>msetnx &lt;key1&gt; &lt;value1&gt; &lt;key2&gt; &lt;value2&gt;</code></td><td>同时设置一个或多个 key-value 对，当且仅当所有给定的 key 都不存在</td></tr><tr><td><code>getrange &lt;key&gt; &lt;起始位置&gt; &lt;结束位置&gt;</code></td><td>获得值的范围，双闭区间，类似 java 中的 substring</td></tr><tr><td><code>setrange &lt;key&gt; &lt;起始位置&gt; &lt;value&gt;</code></td><td>用<code>&lt;value&gt;</code>覆盖<code>&lt;key&gt;</code>所存储的字符串值，从 &lt;起始位置&gt; 开始</td></tr><tr><td><code>setex &lt;key&gt; &lt;过期时间&gt; &lt;value&gt;</code></td><td>设置键值的同时，设置过去时间，单位秒。ex 是 expire。对投票系统等很有效。但重新设置 set 的值后，时间就失效了</td></tr><tr><td>psetex key milliseconds value</td><td></td></tr><tr><td><code>getset &lt;key&gt; &lt;value&gt;</code></td><td>以新换旧，设置了新值的同时获取旧值</td></tr></tbody></table>
<p>数据操作不成功的反馈与数据正常操作之间的差异</p>
<p>值可以是任何种类的字符串（包括二进制数据），例如你可以在一个键下保存一张 <code>.jpeg</code> 图片，只需要注意不要超过 512 MB 的最大限度就好了。</p>
<p>当 key 存在时，<code>SET</code> 命令会覆盖掉你上一次设置的值：</p>
<p>string 类型数据操作的注意事项</p>
<p>① 表示运行结果是否成功<br>
 (integer) 0 → false 失败<br>
 (integer) 1 → true 成功<br>
② 表示运行结果值<br>
 (integer) 3 → 3 3 个<br>
 (integer) 1 → 1 1 个</p>
<p> 数据未获取到<br>
（ nil）等同于 null</p>
<p> 数据最大存储量<br>
512MB<br>
 数值计算最大范围（ java 中的 long 的最大值）<br>
9223372036854775807</p>
<p>key 的命名规范：</p>
<p><code>表名:主键名:主键值:字段名</code></p>
<p>如<code>stu:id:1:class</code></p>
<ol start="5">
<li>详说 incr key 操作的原子性</li>
</ol>
<ul>
<li>所谓原子操作是指不会被线程调度机制打断的操作；这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch （切换到另一个线程）。</li>
<li>在单线程中， 能够在单条指令中完成的操作都可以认为是 “原子操作”，因为中断只能发生于指令之间。</li>
<li>在多线程中，不能被其它进程（线程）打断的操作就叫原子操作。</li>
<li>Redis 单命令的原子性主要得益于 Redis 的单线程</li>
</ul>
<p>Redis 中的字符串是一种 <strong>动态字符串 sds</strong>，这意味着使用者可以修改，它的底层实现有点类似于 Java 中的 <strong>ArrayList</strong>，有一个字符数组，从源码的 <strong>sds.h/sdshdr 文件</strong> 中可以看到 Redis 底层对于字符串的定义 <strong>SDS</strong>，即 <em>Simple Dynamic String</em> 结构：</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;* Note: sdshdr5 is never used, we just access the flags byte directly.
 * However is here to document the layout of type 5 SDS strings. *&#x2F;
struct __attribute__ ((__packed__)) sdshdr5 &#123;
    unsigned char flags; &#x2F;* 3 lsb of type, and 5 msb of string length *&#x2F;
    char buf[];
&#125;;
struct __attribute__ ((__packed__)) sdshdr8 &#123;
    uint8_t len; &#x2F;* used *&#x2F;
    uint8_t alloc; &#x2F;* excluding the header and null terminator *&#x2F;
    unsigned char flags; &#x2F;* 3 lsb of type, 5 unused bits *&#x2F;
    char buf[];
&#125;;
struct __attribute__ ((__packed__)) sdshdr16 &#123;
    uint16_t len; &#x2F;* used *&#x2F;
    uint16_t alloc; &#x2F;* excluding the header and null terminator *&#x2F;
    unsigned char flags; &#x2F;* 3 lsb of type, 5 unused bits *&#x2F;
    char buf[];
&#125;;
struct __attribute__ ((__packed__)) sdshdr32 &#123;
    uint32_t len; &#x2F;* used *&#x2F;
    uint32_t alloc; &#x2F;* excluding the header and null terminator *&#x2F;
    unsigned char flags; &#x2F;* 3 lsb of type, 5 unused bits *&#x2F;
    char buf[];
&#125;;
struct __attribute__ ((__packed__)) sdshdr64 &#123;
    uint64_t len; &#x2F;* used *&#x2F;
    uint64_t alloc; &#x2F;* excluding the header and null terminator *&#x2F;
    unsigned char flags; &#x2F;* 3 lsb of type, 5 unused bits *&#x2F;
    char buf[];
&#125;;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>你会发现同样一组结构 Redis 使用泛型定义了好多次，<strong>为什么不直接使用 int 类型呢？</strong></p>
<p>因为当字符串比较短的时候，len 和 alloc 可以使用 byte 和 short 来表示，<strong>Redis 为了对内存做极致的优化，不同长度的字符串使用不同的结构体来表示。</strong></p>
<h3 id="SDS-与-C-字符串的区别"><a class="header-anchor" href="#SDS-与-C-字符串的区别">¶</a>SDS 与 C 字符串的区别</h3>
<p>为什么不考虑直接使用 C 语言的字符串呢？因为 C 语言这种简单的字符串表示方式 <strong>不符合 Redis 对字符串在安全性、效率以及功能方面的要求</strong>。我们知道，C 语言使用了一个长度为 N+1 的字符数组来表示长度为 N 的字符串，并且字符数组最后一个元素总是 <code>'\0'</code>。<em>(下图就展示了 C 语言中值为 “Redis” 的一个字符数组)</em></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/4643a57c24e2c3732e402ff3c95d8d2f.png" alt="" loading="lazy"></p>
<p>C 语言这样简单的数据结构可能会造成以下一些问题：</p>
<ul>
<li><strong>获取字符串长度为 O(N) 级别的操作</strong> → 因为 C 不保存数组的长度，每次都需要遍历一遍整个数组；</li>
<li>不能很好的杜绝 <strong>缓冲区溢出 / 内存泄漏</strong> 的问题 → 跟上述问题原因一样，如果执行拼接 or 缩短字符串的操作，如果操作不当就很容易造成上述问题；</li>
<li>C 字符串 <strong>只能保存文本数据</strong> → 因为 C 语言中的字符串必须符合某种编码（比如 ASCII），例如中间出现的 <code>'\0'</code> 可能会被判定为提前结束的字符串而识别不了；</li>
</ul>
<p>我们以追加字符串的操作举例，Redis 源码如下：</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;* Append the specified binary-safe string pointed by &#39;t&#39; of &#39;len&#39; bytes to the
 * end of the specified sds string &#39;s&#39;.
 *
 * After the call, the passed sds string is no longer valid and all the
 * references must be substituted with the new pointer returned by the call. *&#x2F;
sds sdscatlen(sds s, const void *t, size_t len) &#123;
    &#x2F;&#x2F; 获取原字符串的长度
    size_t curlen &#x3D; sdslen(s);
  
    &#x2F;&#x2F; 按需调整空间，如果容量不够容纳追加的内容，就会重新分配字节数组并复制原字符串的内容到新数组中
    s &#x3D; sdsMakeRoomFor(s,len); 
    if (s &#x3D;&#x3D; NULL) return NULL;   &#x2F;&#x2F; 内存不足
    memcpy(s+curlen, t, len);     &#x2F;&#x2F; 追加目标字符串到字节数组中
    sdssetlen(s, curlen+len);     &#x2F;&#x2F; 设置追加后的长度
    s[curlen+len] &#x3D; &#39;\0&#39;;         &#x2F;&#x2F; 让字符串以 \0 结尾，便于调试打印
    return s;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="3-2-hash"><a class="header-anchor" href="#3-2-hash">¶</a>3.2 hash</h2>
<p>hash 相当于一个 hashMap，他是一整个 hashMap，而不只是一个键值对。</p>
<p>场景：学生有姓名，学号，班级等信息，想让学生为 key，剩下的为值。那么此时值想让称为一个 hashmap，这样更方便更改。</p>
<p>新的存储需求：对一系列存储的数据进行编组，方便管理，典型应用存储对象信息</p>
<p>需要的存储结构：一个存储空间保存多个键值对数据</p>
<p>hash 类型：底层使用哈希表结构实现数据存储</p>
<p>hash 存储结构优化<br>
 如果 field 数量较少，存储结构优化为类数组结构<br>
 如果 field 数量较多，存储结构使用 HashMap 结构</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/6ddc649ddfa077f53a378ee1afd4685e.png" alt="" loading="lazy"></p>
<pre class="line-numbers language-none"><code class="language-none">hdel key field1 [field2]

hmset key field1 value1 field2 value2...#设置多个
hmget key field1 field2...#获取多个
hlen key #字段数量
hexists key field #查是否存在指定字段

hkeys key
hvals key

hincrby key field increment
hincrbyfloat key field increment<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<table><thead><tr><th>命令</th><th>说明</th></tr></thead><tbody><tr><td><code>hset &lt;key&gt; &lt;field&gt; &lt;value&gt;</code></td><td>给集合中的 键赋值</td></tr><tr><td><code>hget &lt;key1&gt; &lt;field&gt;</code></td><td>从集合 取出 value</td></tr><tr><td><code>hmset &lt;key1&gt; &lt;field1&gt; &lt;value1&gt; &lt;field2&gt; &lt;value2&gt;...</code></td><td>批量设置 hash 的值</td></tr><tr><td><code>hexists key &lt;field&gt;</code></td><td>查看哈希表 key 中，给定域 field 是否存在。</td></tr><tr><td>hkeys</td><td>列出该 hash 集合的所有 field</td></tr><tr><td>hvals</td><td>列出该 hash 集合的所有 value</td></tr><tr><td>hincrby</td><td>为哈希表 key 中的域 field 的值加上增量 increment</td></tr><tr><td>hsetnx</td><td>将哈希表 key 中的域 field 的值设置为 value ，当且仅当域 field 不存在</td></tr></tbody></table>
<pre class="line-numbers language-none"><code class="language-none">例子：
127.0.0.1:6379&gt; hset user id 01
(integer) 0
127.0.0.1:6379&gt; hset user name lisi
(integer) 0
127.0.0.1:6379&gt; hset user class 1
(integer) 1
# 即hset可以多句分开设置，不会覆盖、

127.0.0.1:6379&gt; hgetall user
1) &quot;id&quot;
2) &quot;01&quot;
3) &quot;name&quot;
4) &quot;lisi&quot;
5) &quot;class&quot;
6) &quot;1&quot;

127.0.0.1:6379&gt; hget user name
&quot;lisi&quot;
127.0.0.1:6379&gt; hdel user class
(integer) 1
127.0.0.1:6379&gt; hgetall user
1) &quot;id&quot;
2) &quot;01&quot;
3) &quot;name&quot;
4) &quot;lisi&quot;

127.0.0.1:6379&gt; hmget user id name
1) &quot;01&quot;
2) &quot;lisi&quot;
127.0.0.1:6379&gt; hexists user id
(integer) 1
127.0.0.1:6379&gt; hexists user age
(integer) 0
127.0.0.1:6379&gt; hkeys user
1) &quot;id&quot;
2) &quot;name&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>hash 类型数据操作的注意事项</p>
<ul>
<li>hash 类型下的 value 只能存储字符串，不允许存储其他数据类型，不存在嵌套现象。如果数据未获取到，对应的值为（ nil）</li>
<li>每个 hash 可以存储 232 - 1 个键值对</li>
<li>hash 类型十分贴近对象的数据存储形式，并且可以灵活添加删除对象属性。但 hash 设计初衷不是为了存储大量对象而设计的，切记不可滥用，更不可以将 hash 作为对象列表使用</li>
<li>hgetall 操作可以获取全部属性，如果内部 field 过多，遍历整体数据效率就很会低，有可能成为数据访问瓶颈</li>
</ul>
<p>hash 类型应用场景：</p>
<p>淘宝购物车涉及与实现</p>
<p>业务分析：</p>
<ul>
<li>仅分析购物车的 redis 存储模型。添加、浏览、更改数量、删除、清空</li>
<li>购物车于数据库间持久化同步（不讨论）</li>
<li>购物车于订单间关系（不讨论）<br>
提交购物车：读取数据生成订单<br>
商家临时价格调整：隶属于订单级别</li>
<li>未登录用户购物车信息存储（不讨论）<br>
cookie 存储</li>
</ul>
<p>解决方案</p>
<ul>
<li>以客户 id 作为 key，每位客户创建一个 hash 存储结构存储对应的购物车信息</li>
<li>将商品编号作为 field，购买数量作为 value 进行存储</li>
<li>添加商品：追加全新的 field 与 value</li>
<li>浏览：遍历 hash</li>
<li>更改数量：自增 / 自减，设置 value 值</li>
<li>删除商品：删除 field</li>
<li>清空：删除 key</li>
<li>此处仅讨论购物车中的模型设计</li>
<li>购物车与数据库间持久化同步、购物车与订单间关系、未登录用户购物车信息存储不进行讨论</li>
</ul>
<p>场景 2：双 11 活动日，销售手机充值卡的商家对移动、联通、电信的 30 元、 50 元、 100 元商品推出抢购活动，每种商品抢购上限 1000 张</p>
<p>解决方案</p>
<ul>
<li>以商家 id 作为 key，3 个 key</li>
<li>将参与抢购的商品 id 作为 field</li>
<li>将参与抢购的商品数量作为对应的 value</li>
<li>抢购时使用降值的方式控制产品数量</li>
<li>实际业务中还有超卖等实际问题，这里不做讨论</li>
</ul>
<p>业务场景<br>
string 存储对象（ json）与 hash 存储对象</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; 源码定义如 &#96;dict.h&#x2F;dictht&#96; 定义：
typedef struct dictht &#123;
    &#x2F;&#x2F; 哈希表数组
    dictEntry **table;
    &#x2F;&#x2F; 哈希表大小
    unsigned long size;
    &#x2F;&#x2F; 哈希表大小掩码，用于计算索引值，总是等于 size - 1
    unsigned long sizemask;
    &#x2F;&#x2F; 该哈希表已有节点的数量
    unsigned long used;
&#125; dictht;

typedef struct dict &#123;
    dictType *type;
    void *privdata;
    &#x2F;&#x2F; 内部有两个 dictht 结构
    dictht ht[2];
    long rehashidx; &#x2F;* rehashing not in progress if rehashidx &#x3D;&#x3D; -1 *&#x2F;
    unsigned long iterators; &#x2F;* number of iterators currently running *&#x2F;
&#125; dict;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><code>table</code> 属性是一个数组，数组中的每个元素都是一个指向 <code>dict.h/dictEntry</code> 结构的指针，而每个 <code>dictEntry</code> 结构保存着一个键值对：</p>
<pre class="line-numbers language-none"><code class="language-none">typedef struct dictEntry &#123;
    &#x2F;&#x2F; 键
    void *key;
    &#x2F;&#x2F; 值
    union &#123;
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    &#125; v;
    &#x2F;&#x2F; 指向下个哈希表节点，形成链表
    struct dictEntry *next;
&#125; dictEntry;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以从上面的源码中看到，<strong>实际上字典结构的内部包含两个 hashtable</strong>，通常情况下只有一个 hashtable 是有值的，但是在字典扩容缩容时，需要分配新的 hashtable，然后进行 <strong>渐进式搬迁</strong> <em>(下面说原因)</em>。</p>
<h3 id="渐进式-rehash"><a class="header-anchor" href="#渐进式-rehash">¶</a>渐进式 rehash</h3>
<p>大字典的扩容是比较耗时间的，需要重新申请新的数组，然后将旧字典所有链表中的元素重新挂接到新的数组下面，这是一个 O(n) 级别的操作，作为单线程的 Redis 很难承受这样耗时的过程，所以 Redis 使用 <strong>渐进式 rehash</strong> 小步搬迁：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/74696ddcc7b8bfd6bf662f509723fc17.png" alt="" loading="lazy"></p>
<p>渐进式 rehash 会在 rehash 的同时，保留新旧两个 hash 结构，如上图所示，查询时会同时查询两个 hash 结构，然后在后续的定时任务以及 hash 操作指令中，循序渐进的把旧字典的内容迁移到新字典中。当搬迁完成了，就会使用新的 hash 结构取而代之。</p>
<h3 id="扩缩容的条件"><a class="header-anchor" href="#扩缩容的条件">¶</a>扩缩容的条件</h3>
<p>正常情况下，当 hash 表中 <strong>元素的个数等于第一维数组的长度时</strong>，就会开始扩容，扩容的新数组是 <strong>原数组大小的 2 倍</strong>。不过如果 Redis 正在做 <code>bgsave(持久化命令)</code>，为了减少内存也得过多分离，Redis 尽量不去扩容，但是如果 hash 表非常满了，<strong>达到了第一维数组长度的 5 倍了</strong>，这个时候就会 <strong>强制扩容</strong>。</p>
<p>当 hash 表因为元素逐渐被删除变得越来越稀疏时，Redis 会对 hash 表进行缩容来减少 hash 表的第一维数组空间占用。所用的条件是 <strong>元素个数低于数组长度的 10%</strong>，缩容不会考虑 Redis 是否在做 <code>bgsave</code>。</p>
<h2 id="3-3-List"><a class="header-anchor" href="#3-3-List">¶</a>3.3 List</h2>
<p>LinkedList</p>
<ol>
<li>
<p>单键多值</p>
</li>
<li>
<p>Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素导列表的头部（左边）或者尾部（右边）。</p>
</li>
<li>
<p>它的底层实际是个 ** 双向链表，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差 **</p>
</li>
</ol>
<p>不可以操作中间的</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/d2bd5ee75eb4e121b03cf67a3a2026f0.png" alt="" loading="lazy"></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/6d81cd49d7179505dfb58e6ebb41d84b.png" alt="" loading="lazy"></p>
<ol start="4">
<li>常用操作</li>
</ol>
<table><thead><tr><th>命令</th><th>说明</th></tr></thead><tbody><tr><td><code>lpush/rpush &lt;key&gt; &lt;value1&gt; &lt;value2&gt;</code></td><td>从左边 / 右边插入一个或多个值。</td></tr><tr><td><code>lpop/rpop &lt;key&gt;</code></td><td>从左边 / 右边吐出一个值。 值在键在，值光键亡。</td></tr><tr><td><code>rpoplpush &lt;key1&gt; &lt;key2&gt;</code></td><td>从<code>&lt;key1&gt;</code>列表右边吐出一个值，插到<code>&lt;key2&gt;</code>列表左边</td></tr><tr><td><code>lrange &lt;key&gt; &lt;start&gt; &lt;stop&gt;</code></td><td>按照索引下标获得元素 (从左到右)，可以用 - 1 表示最后一个</td></tr><tr><td><code>lindex &lt;key&gt; &lt;index&gt;</code></td><td>按照索引下标获得元素 (从左到右)</td></tr><tr><td><code>llen &lt;key&gt;</code></td><td>获得列表长度</td></tr><tr><td><code>linsert &lt;key&gt; before &lt;value&gt; &lt;newvalue&gt;</code></td><td>在<code>&lt;value&gt;</code>的后面插入<code>&lt;newvalue&gt;</code> 插入值</td></tr><tr><td><code>lrem &lt;key&gt; &lt;n&gt; &lt;value&gt;</code></td><td>从左边删除 n 个 value(从左到右)</td></tr></tbody></table>
<pre class="line-numbers language-none"><code class="language-none"># 规定时间内获取并移除数据，现在没有没关系，可以等一会
blpop key1 [key2] timeout
brpop key1 [key2] timeout
brpoplpush source destination timeout<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>业务场景：</p>
<p>微信朋友圈点赞，要求按照点赞顺序显示点赞好友信息<br>
如果取消点赞，移除对应好友信息</p>
<pre class="line-numbers language-none"><code class="language-none"># 移除指定数据，中间拿数据,但其实是从左面拿指定value，拿完count个value后结束
lrem key count value<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>list 操作注意事项：</p>
<ul>
<li>list 中保存的数据都是 string 类型的，数据总容量是有限的，最多 2^32 - 1 个元素 (4294967295)。</li>
<li>list 具有索引的概念，但是操作数据时通常以队列的形式进行入队出队操作，或以栈的形式进行入栈出栈操作</li>
<li>获取全部数据操作结束索引设置为 - 1</li>
<li>list 可以对数据进行分页操作，通常第一页的信息来自于 list，第 2 页及更多的信息通过数据库的形式加载</li>
</ul>
<p>场景 2：</p>
<p>twitter、新浪微博、腾讯微博中个人用户的关注列表需要按照用户的关注顺序进行展示，粉丝列表需要将最近关注的粉丝列在前面</p>
<p>新闻、资讯类网站如何将最新的新闻或资讯按照发生的时间顺序展示？<br>
企业运营过程中，系统将产生出大量的运营数据，如何保障多台服务器操作日志的统一顺序输出？</p>
<p>解决方案</p>
<ul>
<li>依赖 list 的数据具有顺序的特征对信息进行管理</li>
<li>使用队列模型解决多路信息汇总合并的问题</li>
<li>使用栈模型解决最新消息的问题</li>
</ul>
<p>tips：redis 应用于最新消息展示</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F; &#96;adlist.h&#x2F;listNode&#96; 源码

&#x2F;* Node, List, and Iterator are the only data structures used currently. *&#x2F;

typedef struct listNode &#123;
    struct listNode *prev;
    struct listNode *next;
    void *value;
&#125; listNode;

typedef struct listIter &#123;
    listNode *next;
    int direction;
&#125; listIter;

typedef struct list &#123;
    listNode *head;
    listNode *tail;
    void *(*dup)(void *ptr);
    void (*free)(void *ptr);
    int (*match)(void *ptr, void *key);
    unsigned long len;
&#125; list;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>虽然仅仅使用多个 listNode 结构就可以组成链表，但是使用 <code>adlist.h/list</code> 结构来持有链表的话，操作起来会更加方便：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7896890-c6fb10cdbb32f517.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" loading="lazy"></p>
<h2 id="3-4-Set"><a class="header-anchor" href="#3-4-Set">¶</a>3.4 Set</h2>
<ol>
<li>
<p>Redis set 对外提供的功能与 list 类似是一个列表的功能，特殊之处在于 set 是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择，并且 set 提供了判断某个成员是否在一个 set 集合内的重要接口，这个也是 list 所不能提供的</p>
</li>
<li>
<p>Redis 的 Set 是 string 类型的无序集合。它底层其实是一个 value 为 null 的 hash 表, 所以添加，删除，查找的复杂度都是 O(1)。</p>
</li>
</ol>
<p>当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择，并且 set 提供了判断某个成员是否在一个 set 集合内的重要接口，这个也是 list 所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。</p>
<ol start="3">
<li>常用操作</li>
</ol>
<p>list 内部是链表结构，读取比较慢，所以想起 set，高效查询。</p>
<p>把前面的 hash 表的 field 保留，value 去除，即得到了 set。</p>
<p>新的存储需求：存储大量的数据，在查询方面提供更高的效率<br>
 需要的存储结构：能够保存大量的数据，高效的内部存储机制，便于查询<br>
 set 类型：与 hash 存储结构完全相同，仅存储键，不存储值（ nil），并且值是不允许重复的</p>
<table><thead><tr><th>命令</th><th>说明</th></tr></thead><tbody><tr><td><code>sadd &lt;key&gt; &lt;value1&gt; &lt;value2&gt; ....</code></td><td>将一个或多个 member 元素加入到集合 key 当中，已经存在于集合的 value 元素将被忽略。</td></tr><tr><td><code>smembers &lt;key&gt;</code></td><td>取出该集合的所有值。</td></tr><tr><td><code>sismember &lt;key&gt; &lt;value&gt;</code></td><td>判断集合是否为含有该值，有返回 1，没有返回 0</td></tr><tr><td><code>scard &lt;key&gt;</code></td><td>返回该集合的元素个数。</td></tr><tr><td><code>srem &lt;key&gt; &lt;value1&gt; &lt;value2&gt; ....</code></td><td>删除集合中的某个元素。</td></tr><tr><td><code>spop &lt;key&gt;</code></td><td>随机从该集合中吐出一个值。</td></tr><tr><td><code>srandmember &lt;key&gt; &lt;n&gt;</code></td><td>随机从该集合中取出 n 个值。 不会从集合中删除</td></tr><tr><td><code>sinter &lt;key1&gt; &lt;key2&gt;</code></td><td>返回两个集合的交集元素。</td></tr><tr><td><code>sunion &lt;key1&gt; &lt;key2&gt;</code></td><td>返回两个集合的并集元素。</td></tr><tr><td><code>sdiff &lt;key1&gt; &lt;key2&gt;</code></td><td>返回两个集合的差集元素。在</td></tr><tr><td><code>sinterstore key1 key2 key3</code></td><td>将交集存在 key1 内</td></tr></tbody></table>
<p>缺点: 用户 ID 数据冗余</p>
<ul>
<li>第三种方案: 通过 key(用户 ID) + field(属性标签) 就可以操作对应属性数据了，既不需要重复存储数据，也不会带来序列化和并发修改控制的问题</li>
</ul>
<p>扩展：</p>
<pre class="line-numbers language-none"><code class="language-none">srandmember key [count] #随机获取集合中指定数量的数据
spop key [count] #随机获取集合中的某个数据并将该数据移除集合<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<pre class="line-numbers language-none"><code class="language-none"># 求两个集合的交、并、差集
sinter key1 [key2]
sunion key1 [key2]
sdiff key1 [key2]

# 求两个集合的交、并、差集并存储到指定集合中
sinterstore destination key1 [key2]
sunionstore destination key1 [key2]
sdiffstore destination key1 [key2]

# 将指定数据从原始集合中移动到目标集合中
smove source destination member<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>场景：</p>
<p>每位用户首次使用今日头条时会设置 3 项爱好的内容，但是后期为了增加用户的活跃度、兴趣点，必须让用户对其他信息类别逐渐产生兴趣，增加客户留存度，如何实现？</p>
<p>业务分析</p>
<ul>
<li>系统分析出各个分类的最新或最热点信息条目并组织成 set 集合</li>
<li>随机挑选其中部分信息</li>
<li>配合用户关注信息分类中的热点信息组织成展示的全信息集合</li>
</ul>
<p>redis 应用于随机推荐类信息检索，例如热点歌单推荐，热点新闻推荐，热卖旅游线路，应用 APP 推荐，大 V 推荐等</p>
<p>场景 2：</p>
<p>脉脉为了促进用户间的交流，保障业务成单率的提升，需要让每位用户拥有大量的好友，事实上职场新人不具有更多的职场好友，如何快速为用户积累更多的好友？<br>
新浪微博为了增加用户热度，提高用户留存性，需要微博用户在关注更多的人，以此获得更多的信息或热门话题，如何提高用户关注他人的总量？<br>
QQ 新用户入网年龄越来越低，这些用户的朋友圈交际圈非常小，往往集中在一所学校甚至一个班级中，如何帮助用户快速积累好友用户带来更多的活跃度？<br>
微信公众号是微信信息流通的渠道之一，增加用户关注的公众号成为提高用户活跃度的一种方式，如何帮助用户积累更多关注的公众号？<br>
美团外卖为了提升成单量，必须帮助用户挖掘美食需求，如何推荐给用户最适合自己的美食？</p>
<p>Tips 9：<br>
 redis 应用于同类信息的关联搜索，二度关联搜索，深度关联搜索<br>
 显示共同关注（一度）<br>
 显示共同好友（一度）<br>
 由用户 A 出发，获取到好友用户 B 的好友信息列表（一度）<br>
 由用户 A 出发，获取到好友用户 B 的购物清单列表（二度）<br>
 由用户 A 出发，获取到好友用户 B 的游戏充值列表（二度）</p>
<p>set 类型数据操作的注意事项</p>
<ul>
<li>set 类型不允许数据重复，如果添加的数据在 set 中已经存在，将只保留一份</li>
<li>set 虽然与 hash 的存储结构相同，但是无法启用 hash 中存储值的空间</li>
</ul>
<p>场景 3：</p>
<p>集团公司共具有 12000 名员工，内部 OA 系统中具有 700 多个角色， 3000 多个业务操作， 23000 多种数据，每位员工具有一个或多个角色，如何快速进行业务操作的权限校验？</p>
<p>场景 4：</p>
<p>公司对旗下新的网站做推广，统计网站的 PV（访问量） ,UV（独立访客） ,IP（独立 IP）。<br>
PV：网站被访问次数，可通过刷新页面提高访问量<br>
UV：网站被不同用户访问的次数，可通过 cookie 统计访问量，相同用户切换 IP 地址， UV 不变<br>
IP：网站被不同 IP 地址访问的总次数，可通过 IP 地址统计访问量，相同 IP 不同用户访问， IP 不变</p>
<p>解决方案<br>
 利用 set 集合的数据去重特征，记录各种访问数据<br>
 建立 string 类型数据，利用 incr 统计日访问量（ PV）<br>
 建立 set 模型，记录不同 cookie 数量（ UV）<br>
 建立 set 模型，记录不同 IP 数量（ IP）</p>
<p>tips：redis 应用于同类型数据的快速去重</p>
<p>场景 5：</p>
<p>黑名单<br>
资讯类信息类网站追求高访问量，但是由于其信息的价值，往往容易被不法分子利用，通过爬虫技术，快速获取信息，个别特种行业网站信息通过爬虫获取分析后，可以转换成商业机密进行出售。例如第三方火车票、机票、酒店刷票代购软件，电商刷评论、刷好评。<br>
同时爬虫带来的伪流量也会给经营者带来错觉，产生错误的决策，有效避免网站被爬虫反复爬取成为每个网站都要考虑的基本问题。在基于技术层面区分出爬虫用户后，需要将此类用户进行有效的屏蔽，这就是黑名单的典型应用。<br>
ps: 不是说爬虫一定做摧毁性的工作，有些小型网站需要爬虫为其带来一些流量。</p>
<p>白名单<br>
对于安全性更高的应用访问，仅仅靠黑名单是不能解决安全问题的，此时需要设定可访问的用户群体，<br>
依赖白名单做更为苛刻的访问验证。</p>
<p>解决方案<br>
 基于经营战略设定问题用户发现、鉴别规则<br>
 周期性更新满足规则的用户黑名单，加入 set 集合<br>
 用户行为信息达到后与黑名单进行比对，确认行为去向<br>
 黑名单过滤 IP 地址：应用于开放游客访问权限的信息源<br>
 黑名单过滤设备信息：应用于限定访问设备的信息源<br>
 黑名单过滤用户：应用于基于访问权限的信息源</p>
<p>tips：redis 应用于基于黑名单与白名单设定的服务控制</p>
<h2 id="3-5-zset-sorted-set"><a class="header-anchor" href="#3-5-zset-sorted-set">¶</a>3.5 zset (sorted set)</h2>
<p>zset 和 set 相比，sorted set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列。</p>
<p><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422003323.png" alt="" loading="lazy"></p>
<p>它的内部实现用的是一种叫做 <strong>「跳跃表」</strong> 的数据结构，由于比较复杂，所以在这里简单提一下原理就好了：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7896890-efd5114939a651ed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" loading="lazy"></p>
<p>score 不是数据。</p>
<ol>
<li>
<p>Redis 有序集合 zset 与普通集合 set 非常相似，是一个没有重复元素的字符串集合。不同之处是有序集合的每个成员都关联了一个评分（score） ，这个评分（score）被用来按照从最低分到最高分的方式排序集合中的成员。集合的成员是唯一的，但是评分可以是重复了 。</p>
</li>
<li>
<p>因为元素是有序的, 所以你也可以很快的根据评分（score）或者次序（position）来获取一个范围的元素。访问有序集合的中间元素也是非常快的, 因此你能够使用有序集合作为一个没有重复成员的智能列表。</p>
</li>
<li>
<p>常用操作</p>
</li>
</ol>
<table><thead><tr><th>命令</th><th>说明</th></tr></thead><tbody><tr><td><code>zadd &lt;key&gt; &lt;score1&gt; &lt;value1&gt; &lt;score2&gt; &lt;value2&gt;...</code></td><td>将一个或多个 member 元素及其 score 值加入到有序集 key 当中。注意分在前，值在后。</td></tr><tr><td><code>zrange &lt;key&gt; &lt;start&gt; &lt;stop&gt; [WITHSCORES]</code></td><td>返回有序集 key 中，下标在 <stop>之间的元素 带 WITHSCORES，可以让分数一起和值返回到结果集。</stop></td></tr><tr><td>zrangebyscore key min max [withscores] [limit offset count]</td><td>返回有序集 key 中，所有 score 值介于 min 和 max 之间 (包括等于 min 或 max) 的成员。有序集成员按 score 值递增 (从小到大) 次序排列。</td></tr><tr><td>zrevrangebyscore key max min [withscores] [limit offset count]</td><td>同上，改为从大到小排列。</td></tr><tr><td><code>zincrby &lt;key&gt; &lt;increment&gt; &lt;value&gt;</code></td><td>为元素的 score 加上增量</td></tr><tr><td><code>zrem &lt;key&gt; &lt;value&gt;</code></td><td>删除该集合下，指定值的元素</td></tr><tr><td>zremrangebyrank/zremrangebyscore key start stop【或 min max】</td><td>条件删除</td></tr><tr><td><code>zcount &lt;key&gt; &lt;min&gt; &lt;max&gt;</code></td><td>统计该集合，分数区间内的元素个数</td></tr><tr><td><code>zrank &lt;key&gt; &lt;value&gt;</code></td><td>返回该值在集合中的排名，从 0 开始。</td></tr></tbody></table>
<pre class="line-numbers language-none"><code class="language-none"> 获取集合数据总量
zcard key
zcount key min max

 集合交、并操作
zinterstore destination numkeys key [key ...]
zunionstore destination numkeys key [key ...]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>主要应用：排行榜</p>
<ol start="4">
<li>思考: 如何利用 zset 实现一个文章访问量的排行榜?</li>
</ol>
<pre class="line-numbers language-none"><code class="language-none">语法：zadd &lt;key&gt;  &lt;score1&gt; &lt;value1&gt;
127.0.0.1:6379&gt; zadd test 94 zs
(integer) 1
127.0.0.1:6379&gt; zadd test 100 ls
(integer) 1
127.0.0.1:6379&gt; zadd test 60 ww
(integer) 1
127.0.0.1:6379&gt; zadd test 47 zl
(integer) 1
127.0.0.1:6379&gt; zrange test 0 -1
1) &quot;zl&quot;
2) &quot;ww&quot;
3) &quot;zs&quot;
4) &quot;ls&quot;
127.0.0.1:6379&gt; zrange test 0 -1 withscores
1) &quot;zl&quot;
2) &quot;47&quot;
3) &quot;ww&quot;
4) &quot;60&quot;
5) &quot;zs&quot;
6) &quot;94&quot;
7) &quot;ls&quot;
8) &quot;100&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>min 与 max 用于限定搜索查询的条件</li>
<li>start 与 stop 用于限定查询范围，作用于索引，表示开始和结束索引</li>
<li>offset 与 count 用于限定查询范围，作用于查询结果，表示开始位置和数据总量</li>
</ul>
<p>场景 1：</p>
<p>票选广东十大杰出青年，各类综艺选秀海选投票<br>
各类资源网站 TOP10（电影，歌曲，文档，电商，游戏等）<br>
聊天室活跃度统计<br>
游戏好友亲密度<br>
业务分析<br>
 为所有参与排名的资源建立排序依据</p>
<pre class="line-numbers language-none"><code class="language-none"> 获取数据对应的索引（排名）
zrank key member
zrevrank key member
 score值获取与修改
zscore key member
zincrby key increment member<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> redis 应用于计数器组合排序功能对应的排名</p>
<p>注意事项：</p>
<p>score 保存的数据存储空间是 64 位，如果是整数范围是 - 9007199254740992~9007199254740992<br>
 score 保存的数据也可以是一个双精度的 double 值，基于双精度浮点数的特征，可能会丢失精度，使用时候要慎重<br>
 sorted_set 底层存储还是基于 set 结构的，因此数据不能重复，如果重复添加相同的数据， score 值将被反复覆盖，保留最后一次修改的结果</p>
<p>场景 2：</p>
<p>基础服务 + 增值服务类网站会设定各位会员的试用，让用户充分体验会员优势。例如观影试用 VIP、游戏 VIP 体验、云盘下载体验 VIP、数据查看体验 VIP。当 VIP 体验到期后，如果有效管理此类信息。即便对于正式 VIP 用户也存在对应的管理方式。<br>
网站会定期开启投票、讨论，限时进行，逾期作废。如何有效管理此类过期信息。</p>
<p>解决方案：</p>
<p>对于基于时间线限定的任务处理，将处理时间记录为 score 值，利用排序功能区分处理的先后顺序<br>
 记录下一个要处理的时间，当到期后处理对应任务，移除 redis 中的记录，并记录下一个要处理的时间<br>
 当新任务加入时，判定并更新当前下一个要处理的任务时间<br>
 为提升 sorted_set 的性能，通常将任务根据特征存储成若干个 sorted_set。例如 1 小时内， 1 天内，周内，月内，季内，年度等，操作时逐级提升，将即将操作的若干个任务纳入到 1 小时内处理的队列中</p>
<pre class="line-numbers language-none"><code class="language-none">time # 获取当前系统时间<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>tips： redis 应用于定时任务执行顺序管理或任务过期管理</p>
<p>场景 3：</p>
<p>任务 / 消息权重设定应用<br>
当任务或者消息待处理，形成了任务队列或消息队列时，对于高优先级的任务要保障对其优先处理，如何实现任务权重管理。</p>
<p>解决方案：</p>
<p>对于带有权重的任务，优先处理权重高的任务，采用 score 记录权重即可多条件任务权重设定<br>
如果权重条件过多时，需要对排序 score 值进行处理，保障 score 值能够兼容 2 条件或者多条件，例如外贸订单优先于国内订单，总裁订单优先于员工订单，经理订单优先于员工订单<br>
 因 score 长度受限，需要对数据进行截断处理，尤其是时间设置为小时或分钟级即可（折算后）<br>
 先设定订单类别，后设定订单发起角色类别，整体 score 长度必须是统一的，不足位补 0。第一排序规则首位不得是 0<br>
 例如外贸 101，国内 102，经理 004，员工 008。<br>
 员工下的外贸单 score 值为 101008（优先）<br>
 经理下的国内单 score 值为 102004</p>
<h1>第 4 章 Redis 的相关配置</h1>
<ol>
<li>
<p>计量单位说明, 大小写不敏感</p>
</li>
<li>
<p>include</p>
</li>
</ol>
<p>类似 jsp 中的 include，多实例的情况可以把公用的配置文件提取出来</p>
<ol start="3">
<li>ip 地址的绑定 bind</li>
</ol>
<ul>
<li>默认情况 bind=127.0.0.1，只能接受本机的访问请求</li>
<li>不写的情况下，无限制接受任何 ip 地址的访问</li>
<li>生产环境肯定要写你应用服务器的地址</li>
<li>如果开启了 protected-mode，那么在没有设定 bind ip 且没有设密码的情况下，Redis 只允许接受本机的相应</li>
</ul>
<ol start="4">
<li>tcp-backlog</li>
</ol>
<ul>
<li>可以理解是一个请求到达后至到接受进程处理前的队列.</li>
<li>backlog 队列总和 = 未完成三次握手队列 + 已经完成三次握手队列</li>
<li>高并发环境 tcp-backlog 设置值跟超时时限内的 Redis 吞吐量决定</li>
</ul>
<ol start="5">
<li>timeout</li>
</ol>
<p>一个空闲的客户端维持多少秒会关闭，0 为永不关闭。</p>
<ol start="6">
<li>tcp keepalive</li>
</ol>
<p>对访问客户端的一种心跳检测，每个 n 秒检测一次，官方推荐设置为 60 秒</p>
<ol start="7">
<li>daemonize</li>
</ol>
<p>是否为后台进程</p>
<ol start="8">
<li>pidfile</li>
</ol>
<p>存放 pid 文件的位置，每个实例会产生一个不同的 pid 文件</p>
<ol start="9">
<li>log level</li>
</ol>
<p>四个级别根据使用阶段来选择，生产环境选择 notice 或者 warning</p>
<ol start="10">
<li>log level</li>
</ol>
<p>日志文件名称</p>
<ol start="11">
<li>syslog</li>
</ol>
<p>是否将 Redis 日志输送到 linux 系统日志服务中</p>
<ol start="12">
<li>syslog-ident</li>
</ol>
<p>日志的标志</p>
<ol start="13">
<li>syslog-facility</li>
</ol>
<p>输出日志的设备</p>
<ol start="14">
<li>database</li>
</ol>
<p>设定库的数量 默认 16</p>
<ol start="15">
<li>security</li>
</ol>
<p>在命令行中设置密码</p>
<pre class="line-numbers language-none"><code class="language-none">config get requirepass
config set requirepass &quot;123456&quot;
config get requirepass
auth 123456
get kl<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol start="16">
<li>maxclient</li>
</ol>
<p>最大客户端连接数</p>
<ol start="17">
<li>maxmemory</li>
</ol>
<p>设置 Redis 可以使用的内存量。一旦到达内存使用上限，Redis 将会试图移除内部数据，移除规则可以通过 maxmemory-policy 来指定。如果 Redis 无法根据移除规则来移除内存中的数据，或者设置了 “不允许移除”，</p>
<p>那么 Redis 则会针对那些需要申请内存的指令返回错误信息，比如 SET、LPUSH 等。</p>
<ol start="18">
<li>Maxmemory-policy</li>
</ol>
<ul>
<li>volatile-lru：使用 LRU 算法移除 key，只对设置了过期时间的键</li>
<li>allkeys-lru：使用 LRU 算法移除 key</li>
<li>volatile-random：在过期集合中移除随机的 key，只对设置了过期时间的键</li>
<li>allkeys-random：移除随机的 key</li>
<li>volatile-ttl：移除那些 TTL 值最小的 key，即那些最近要过期的 key</li>
<li>noeviction：不进行移除。针对写操作，只是返回错误信息</li>
</ul>
<ol start="19">
<li>Maxmemory-samples</li>
</ol>
<p>设置样本数量，LRU 算法和最小 TTL 算法都并非是精确的算法，而是估算值，所以你可以设置样本的大小。</p>
<p>一般设置 3 到 7 的数字，数值越小样本越不准确，但是性能消耗也越小。</p>
<h1>第 5 章 Jedis</h1>
<p>可视化客户端：Redis Desktop Manager</p>
<pre class="line-numbers language-none"><code class="language-none">Jedis jedis &#x3D; new Jedis(&quot;localhost&quot;,6379);
jedis.set(&quot;name&quot;,&quot;lisi&quot;);&#x2F;&#x2F;方法名和原来的命令一致
jedis.get(&quot;name&quot;);
jedis.close();
&#x2F;&#x2F;http:&#x2F;&#x2F;xetorthio.github.io&#x2F;jedis&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol>
<li>Jedis 所需要的 jar 包 , 可通过 Maven 的依赖引入</li>
</ol>
<pre class="line-numbers language-none"><code class="language-none">Commons-pool-1.6.jar
Jedis-2.1.0.jar

maven为jedis，可选junit<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<ol start="2">
<li>使用 Windows 环境下 Eclipse 连接虚拟机中的 Redis 注意事项</li>
</ol>
<ul>
<li>禁用 Linux 的防火墙：Linux(CentOS7) 里执行命令 ： systemctl stop firewalld.service</li>
<li>redis.conf 中注释掉 bind 127.0.0.1，然后 protect-mode no。</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none">package com.itheima;

import org.junit.Test;
import redis.clients.jedis.Jedis;

import java.util.List;
import java.util.Map;

public class JedisTest &#123;
    @Test
    public void testJedis()&#123;
        &#x2F;&#x2F;1.连接redis
        Jedis jedis &#x3D; new Jedis(&quot;127.0.0.1&quot;, 6379);
        &#x2F;&#x2F;2.操作redis
&#x2F;&#x2F;        jedis.set(&quot;name&quot;,&quot;itheima&quot;);
        String name &#x3D; jedis.get(&quot;name&quot;);
        System.out.println(name);
        &#x2F;&#x2F;3.关闭连接
        jedis.close();
    &#125;

    @Test
    public void testList()&#123;
        &#x2F;&#x2F;1.连接redis
        Jedis jedis &#x3D; new Jedis(&quot;127.0.0.1&quot;, 6379);
        &#x2F;&#x2F;2.操作redis
        jedis.lpush(&quot;list1&quot;,&quot;a&quot;,&quot;b&quot;,&quot;c&quot;);
        jedis.rpush(&quot;list1&quot;,&quot;x&quot;);

        List&lt;String&gt; list1 &#x3D; jedis.lrange(&quot;list1&quot;, 0, -1);
        for(String s : list1)&#123;
            System.out.println(s);
        &#125;

        System.out.println(jedis.llen(&quot;list1&quot;));

        System.out.println();
        &#x2F;&#x2F;3.关闭连接
        jedis.close();
    &#125;

    @Test
    public void testHash()&#123;
        &#x2F;&#x2F;1.连接redis
        Jedis jedis &#x3D; new Jedis(&quot;127.0.0.1&quot;, 6379);
        &#x2F;&#x2F;2.操作redis

        jedis.hset(&quot;hash1&quot;,&quot;a1&quot;,&quot;b1&quot;);
        jedis.hset(&quot;hash1&quot;,&quot;a2&quot;,&quot;a2&quot;);
        jedis.hset(&quot;hash1&quot;,&quot;a3&quot;,&quot;b3&quot;);

        Map&lt;String, String&gt; hash1 &#x3D; jedis.hgetAll(&quot;hash1&quot;);

        System.out.println(hash1);

        System.out.println(jedis.hlen(&quot;hash1&quot;));

        System.out.println();
        &#x2F;&#x2F;3.关闭连接
        jedis.close();
    &#125;

&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>① 设定一个服务方法，用于模拟实际业务调用的服务，内部采用打印模拟调用<br>
② 在业务调用前服务调用控制单元，内部使用 redis 进行控制，参照之前的方案<br>
③ 对调用超限使用异常进行控制，异常处理设定为打印提示信息<br>
④ 主程序启动 3 个线程，分别表示 3 种不同用户的调用</p>
<pre class="line-numbers language-none"><code class="language-none">package com.itheima;

import com.itheima.util.JedisUtils;
import redis.clients.jedis.Jedis;
import redis.clients.jedis.exceptions.JedisDataException;

public class Service &#123;
    private String id;
    private int num;

    public Service(String id,int num)&#123;
        this.id &#x3D; id;
        this.num &#x3D; num;
    &#125;
    &#x2F;&#x2F;控制单元
    public void service()&#123;
&#x2F;&#x2F;        Jedis jedis &#x3D; new Jedis(&quot;127.0.0.1&quot;,6379);
        Jedis jedis &#x3D; JedisUtils.getJedis();
        String value &#x3D; jedis.get(&quot;compid:&quot;+id);
        &#x2F;&#x2F;判断该值是否存在
        try&#123;
            if(value &#x3D;&#x3D; null)&#123;
                &#x2F;&#x2F;不存在，创建该值
                jedis.setex(&quot;compid:&quot;+id,5,Long.MAX_VALUE-num+&quot;&quot;);
            &#125;else&#123;
                &#x2F;&#x2F;存在，自增，调用业务
                Long val &#x3D; jedis.incr(&quot;compid:&quot;+id);
                business(id,num-(Long.MAX_VALUE-val));
            &#125;
        &#125;catch (JedisDataException e)&#123;
            System.out.println(&quot;使用已经到达次数上限，请升级会员级别&quot;);
            return;
        &#125;finally&#123;
            jedis.close();
        &#125;
    &#125;
    &#x2F;&#x2F;业务操作
    public void business(String id,Long val)&#123;
        System.out.println(&quot;用户:&quot;+id+&quot; 业务操作执行第&quot;+val+&quot;次&quot;);
    &#125;
&#125;

class MyThread extends Thread&#123;
    Service sc ;
    public MyThread(String id,int num)&#123;
        sc &#x3D; new Service(id,num);
    &#125;
    public void run()&#123;
        while(true)&#123;
            sc.service();
            try &#123;
                Thread.sleep(300L);
            &#125; catch (InterruptedException e) &#123;
                e.printStackTrace();
            &#125;
        &#125;
    &#125;
&#125;

class Main&#123;
    public static void main(String[] args) &#123;
        MyThread mt1 &#x3D; new MyThread(&quot;初级用户&quot;,10);
        MyThread mt2 &#x3D; new MyThread(&quot;高级用户&quot;,30);
        mt1.start();
        mt2.start();
    &#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-none"><code class="language-none">package com.itheima.util;

import redis.clients.jedis.Jedis;
import redis.clients.jedis.JedisPool;
import redis.clients.jedis.JedisPoolConfig;

import java.util.ResourceBundle;

public class JedisUtils &#123;
    private static JedisPool jp &#x3D; null;
    private static String host &#x3D; null;
    private static int port;
    private static int maxTotal;
    private static int maxIdle;

    static &#123;&#x2F;&#x2F;定义放到外面
        ResourceBundle rb &#x3D; ResourceBundle.getBundle(&quot;redis&quot;);&#x2F;&#x2F;redis.properties
        host &#x3D; rb.getString(&quot;redis.host&quot;);
        port &#x3D; Integer.parseInt(rb.getString(&quot;redis.port&quot;));
        maxTotal &#x3D; Integer.parseInt(rb.getString(&quot;redis.maxTotal&quot;));
        maxIdle &#x3D; Integer.parseInt(rb.getString(&quot;redis.maxIdle&quot;));
        JedisPoolConfig jpc &#x3D; new JedisPoolConfig();
        jpc.setMaxTotal(maxTotal);
        jpc.setMaxIdle(maxIdle);
        jp &#x3D; new JedisPool(jpc,host,port);
    &#125;

    public static Jedis getJedis()&#123;
        return jp.getResource();
    &#125;
    public static void main(String[] args)&#123;
        JedisUtils.getJedis();
    &#125;
&#125;
&#x2F;&#x2F; 原方法&#x2F;&#x2F;这种每次都要拿一个连接池，没有效率，所以放到static代码块中
public static Jedis getJedis() &#123;
    JedisPoolConfig jpc&#x3D;new JedisPoolConfig();
    jpc.setMaxTotal(30);
    jpc.setMaxIdle(10);
    String host&#x3D;&quot;127.0.0.1&quot;;
    int port&#x3D;6379;
    JedisPool jp&#x3D;new JedisPool(jpc,host,port);
    return jp.getResource();
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>redis.properties</p>
<pre class="line-numbers language-none"><code class="language-none">redis.host&#x3D;127.0.0.1
redis.port&#x3D;6379
redis.maxTotal&#x3D;30
redis.maxIdle&#x3D;10<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h1>第 6 章 Redis 事务</h1>
<h2 id="6-1-Redis-中事务的定义"><a class="header-anchor" href="#6-1-Redis-中事务的定义">¶</a>6.1 Redis 中事务的定义</h2>
<p>Redis 事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断</p>
<p>Redis 事务的主要作用就是串联多个命令防止别的命令插队</p>
<p>基本操作：</p>
<pre class="line-numbers language-none"><code class="language-none">multi # 开启事务
作用：设定事务的开启位置，此指令执行后，后续的所有指令均加入到事务中

exec # 执行事务
作用：设定事务的结束位置，同时执行事务。与multi成对出现，成对使用
注意：加入事务的命令暂时进入到任务队列中，并没有立即执行，只有执行exec命令才开始执行

discard # 取消事务
作用：终止当前事务的定义，发生在multi之后， exec之前<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol>
<li>
<p>从输入 Multi 命令开始，输入的命令都会依次进入命令队列中，但不会执行，至到输入 Exec 后，Redis 会将之前的命令队列中的命令依次执行。</p>
</li>
<li>
<p>组队的过程中可以通过 discard 来放弃组队。</p>
</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/img_convert/9316f10f5edd2367c675c4c30a0d7bd9.png" alt="" loading="lazy"></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/1c83ccc9b7bf2685e5a59555e846853e.png" alt="" loading="lazy"></p>
<p>事务的注意事项</p>
<ul>
<li>事务过程中，输入的<strong>语法错误</strong>：会造成取消事务，且整体事务的<strong>所有命令均不会执行</strong>。包括正确的指令也不执行</li>
<li>事务过程中，输入语法无误，但不符合逻辑：例如对 list 进行 incr 操作。能够正确运行的命令会执行，运行错误的命令不会被执行。注意：已经执行完毕的命令对应的数据不会自动回滚，需要程序员自己在代码中实现回滚。</li>
</ul>
<p>redis 事务三特性</p>
<ul>
<li>
<p>单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</p>
</li>
<li>
<p>没有隔离级别的概念：队列中的命令没有提交之前都不会实际的被执行，因为事务提交前任何指令都不会被实际执行，也就不存在 “事务内的查询要看到事务里的更新，在事务外查询不能看到” 这个让人万分头痛的问题</p>
</li>
<li>
<p>不保证原子性：Redis 同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚</p>
</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none">手动进行事务回滚
 记录操作过程中被影响的数据之前的状态
单数据： string
多数据： hash、 list、 set、 zset

 设置指令恢复所有的被修改的项
单数据：直接set（注意周边属性，例如时效）
多数据：修改对应值或整体克隆复制<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>业务场景</p>
<p>天猫双 11 热卖过程中，对已经售罄的货物追加补货， 4 个业务员都有权限进行补货。补货的操作可能是一系列的操作，牵扯到多个连续操作，如何保障不会重复操作？</p>
<p>业务分析：</p>
<p> 多个客户端有可能同时操作同一组数据，并且该数据一旦被操作修改后，将不适用于继续操作<br>
 在操作之前锁定要操作的数据，一旦发生变化，终止当前操作</p>
<h3 id="事务之—监视锁（超卖问题、分布式锁）"><a class="header-anchor" href="#事务之—监视锁（超卖问题、分布式锁）">¶</a>事务之—监视锁（超卖问题、分布式锁）</h3>
<p><strong>watch 的变量发生变化了，那么事务将不会执行</strong>。例如多终端修改。</p>
<pre class="line-numbers language-none"><code class="language-none"># 对 key 添加监视锁，在执行exec前如果key发生了变化，终止事务执行  # 得写在multi外
watch key1 [key2……]

# 取消对【所有】 key 的监视
unwatch

EXEC和DISCARD也有取消监视的效果：如果在执行 WATCH 命令之后， EXEC 命令或 DISCARD 命令先被执行了的话，那么就不需要再执行 UNWATCH 了。

Tips 18：redis 应用基于状态控制的批量任务执行<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>业务场景</p>
<p>天猫双 11 热卖过程中，对已经售罄的货物追加补货，且补货完成。客户购买热情高涨， 3 秒内将所有商品购买完毕。本次补货已经将库存全部清空，如何避免最后一件商品不被多人同时购买？ 【超卖问题】</p>
<p>业务分析</p>
<p> 使用 watch 监控一个 key 有没有改变已经不能解决问题，此处要监控的是具体数据<br>
 虽然 redis 是单线程的，但是多个客户端对同一数据同时进行操作时，如何避免不被同时修改？</p>
<p>watch 的值是不停在改变的，1 件的时候一个人买到其他人就消掉？他是监控一个值能不能变的，而不是监控其他人能不能改这个值的，</p>
<p>思想：</p>
<ul>
<li>利用 setnx 设置一个锁对象，拿到该锁对象才能操作业务，操作完是否该锁</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none">解决方案：

setnx lock-keyname value # 设置一个公共锁
#value值不重要，比如我们要锁name这个变量，那么就是setnx lock-name true
利用setnx命令的返回值特征，有值则返回设置失败，无值则返回设置成功
 对于返回设置成功的，拥有控制权，进行下一步的具体业务操作
 对于返回设置失败的，不具有控制权，排队或等待<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-none"><code class="language-none">set num 10
setnx lock-num 1 # setnx只是简单形式，实际比这复杂，还得加过期时间+更新过期时间
incrby num -1 #库存-1
del lock-num # 操作完毕通过del操作释放锁
如果别的终端在这个过程中页想加锁，别的终端是加不上的。到时他得重新输入命令他再锁<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>上面方案的问题：某个用户拿到锁之后还没 delete 呢，却宕机了，那该 key 岂不是永远不 delete 了？解决方案是给 key 加个<strong>过期时间</strong></p>
<pre class="line-numbers language-none"><code class="language-none">setnx lock-name 1
假如此时停电宕机了，却还没执行delete释放锁。

解决方案：给锁加失效时间
setnx lock-name 1
expire lock-name 20 #20s


# 此外，对象时间长的业务，可以检查所的失效时间，一旦小于1个值，重新设置过期时间，给自己的业务续命<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>由于操作通常都是微秒或毫秒级，因此该锁定时间不宜设置过大。具体时间需要业务测试后确认。</p>
<ul>
<li>例如：持有锁的操作最长执行时间 127ms，最短执行时间 7ms。</li>
<li>测试百万次最长执行时间对应命令的最大耗时，测试百万次网络延迟平均耗时</li>
<li>锁时间设定推荐：最大耗时 ×120%+ 平均网络延迟 ×110%</li>
<li>如果业务最大耗时 &lt;&lt; 网络平均延迟，通常为 2 个数量级，取其中单个耗时较长即可</li>
</ul>
<h2 id="6-3-事务中的错误处理"><a class="header-anchor" href="#6-3-事务中的错误处理">¶</a>6.3 事务中的错误处理</h2>
<ul>
<li>组队阶段： 语法错误，命令错了</li>
<li>执行阶段：对象错了，对象类型不对。（语法没错）</li>
</ul>
<ol>
<li>组队阶段，如果某个命令出现了报告错误，执行时整个的所有队列会都会被取消。</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/img_convert/cf0dfd3857feb14f75bb26c822a22e73.png" alt="" loading="lazy"></p>
<ol start="2">
<li>执行阶段，如果某个命令报出了错误，则只有报错的命令不会被执行，而其他的命令都会执行，不会回滚。</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/img_convert/cd70f0f9be21d9ebcd0befc390dc2f77.png" alt="" loading="lazy"></p>
<h2 id="6-4-为什么要做成事务"><a class="header-anchor" href="#6-4-为什么要做成事务">¶</a>6.4 为什么要做成事务?</h2>
<p>悲观锁 (Pessimistic Lock), 别人想拿这个数据就会 block 直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁</p>
<p>乐观锁适用于多读的应用类型，这样可以提高吞吐量。Redis 就是利用这种 check-and-set 机制实现事务的。</p>
<h2 id="6-6-Redis-事务-秒杀案例"><a class="header-anchor" href="#6-6-Redis-事务-秒杀案例">¶</a>6.6 Redis 事务 秒杀案例</h2>
<ol>
<li>解决计数器和人员记录的事务操作</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/img_convert/7c1ea079b586e2c453d3b30c1ed4f2b3.png" alt="" loading="lazy"></p>
<ol start="2">
<li>秒杀并发模拟 ab 工具</li>
</ol>
<p>CentOS6 默认安装 ,CentOS7 需要手动安装</p>
<ul>
<li>联网: yum install httpd-tools</li>
<li>无网络: 进入 cd /run/media/root/CentOS 7 x86_64/Packages ，顺序安装</li>
</ul>
<p>apr-1.4.8-3.el7.x86_64.rpm、 apr-util-1.5.2-6.el7.x86_64.rpm、 httpd-tools-2.4.6-67.el7.centos.x86_64.rpm</p>
<ul>
<li>ab –n 请求数 -c 并发数 -p 指定请求数据文件 -T “application/x-www-form-urlencoded” 测试的请求</li>
</ul>
<ol start="3">
<li>
<p>超卖问题</p>
</li>
<li>
<p>请求超时问题</p>
</li>
</ol>
<p>节省每次连接 redis 服务带来的消耗，把连接好的实例反复利用</p>
<p>连接池参数:</p>
<p>MaxTotal：控制一个 pool 可分配多少个 jedis 实例，通过 pool.getResource() 来获取；如果赋值为 - 1，则表示不限制；如果 pool 已经分配了 MaxTotal 个 jedis 实例，则此时 pool 的状态为 exhausted。</p>
<p>maxIdle：控制一个 pool 最多有多少个状态为 idle(空闲) 的 jedis 实例；</p>
<p>MaxWaitMillis：表示当 borrow 一个 jedis 实例时，最大的等待毫秒数，如果超过等待时间，则直接抛 JedisConnectionException；</p>
<p>testOnBorrow：获得一个 jedis 实例的时候是否检查连接可用性（ping()）；如果为 true，则得到的 jedis 实例均是可用的；</p>
<ol start="5">
<li>遗留问题</li>
</ol>
<ul>
<li>LUA 脚本</li>
</ul>
<p>Lua 是一个小巧的脚本语言，Lua 脚本可以很容易的被 C/C++ 代码调用，也可以反过来调用 C/C++ 的函数，Lua 并没有提供强大的库，一个完整的 Lua 解释器不过 200k，所以 Lua 不适合作为开发独立应用程序的语言，而是作为嵌入式脚本语言。</p>
<p>很多应用程序、游戏使用 LUA 作为自己的嵌入式脚本语言，以此来实现可配置性、可扩展性。这其中包括魔兽争霸地图、魔兽世界、博德之门、愤怒的小鸟等众多游戏插件或外挂</p>
<ul>
<li>LUA 脚本在 Redis 中的优势</li>
</ul>
<p>将复杂的或者多步的 redis 操作，写为一个脚本，一次提交给 redis 执行，减少反复连接 redis 的次数。提升性能。</p>
<p>LUA 脚本是类似 redis 事务，有一定的原子性，不会被其他命令插队，可以完成一些 redis 事务性的操作</p>
<p>但是注意 redis 的 lua 脚本功能，只有在 2.6 以上的版本才可以使用。</p>
<p>l 利用 lua 脚本淘汰用户，解决超卖问题。</p>
<h1>第 7 章 Redis 持久化</h1>
<pre class="line-numbers language-none"><code class="language-none">是否正在加载RDB文件内容
最后一次保存之后改变的键的个数
是否正在后台执行RDB保存任务
最后一次执行RDB保存任务的时间
最后一次执行RDB保存任务的状态
最后一次执行RDB保存任务消耗的时间
如果正在执行RDB保存任务，则为当前RDB任务已经消耗的时间，否则为一1
最后一次执行RDB保存任务消耗的内存
是否开启了AOF功能
是否正在后台执行AOF重写任务（重写在后续的章节介绍）
是否等待调度一次OF重写任务。如果触发了一次AOF重写，但是后台正在执行RDB保存任务时会将该状态置为1
最后一次执行AOF重写任务消耗的时间
如果正在执行AOF重写任务，则为当前该任务巳经消耗的时问，否则为一1
最后一次执行AOF重写任务的状态
最后一次执行AOF缓冲区写入的状态（服务端执行命令时会开辟一段内存空f司将命令放入其中，然后从该缓冲区中同步到文<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>怎么保证 redis 挂掉之后再重启数据可以进行恢复</p>
<p>Redis 提供了 2 个不同形式的持久化方式 RDB 和 AOF</p>
<ul>
<li>RDB：将当前数据状态进行保存，快照形式，存储数据结果，存储格式简单，关注点在数据</li>
<li>AOF：将数据的操作过程进行保存，日志形式，存储操作过程，存储格式复杂，关注点在数据的操作过程</li>
</ul>
<p><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422015831.png" alt="" loading="lazy"></p>
<h2 id="7-1-RDB"><a class="header-anchor" href="#7-1-RDB">¶</a>7.1 RDB</h2>
<p>原理是 redis 会单独创建（fork）一个与当前进程一模一样的子进程来进行持久化，这个子线程的所有数据（变量。环境变量，程序程序计数器等）都和原进程一模一样，会先将数据写入到一个临时文件中，待持久化结束了，再用这个临时文件替换上次持久化好的文件，整个过程中，主进程不进行任何的 io 操作，这就确保了极高的性能</p>
<p>Redis 可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis 创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用。</p>
<p>如果系统真的发生崩溃，用户将丢失最近一次生成快照之后更改的所有数据。因此，快照持久化只适用于即使丢失一部分数据也不会造成一些大问题的应用程序。不能接受这个缺点的话，可以考虑 AOF 持久化。</p>
<p><strong>创建快照的办法有如下几种：</strong></p>
<ul>
<li><strong>BGSAVE 命令：</strong> 客户端向 Redis 发送 <strong>BGSAVE 命令</strong> 来创建一个快照。对于支持 BGSAVE 命令的平台来说（基本上所有平台支持，除了 Windows 平台），Redis 会调用<code>fork</code>来创建一个子进程，然后<code>子进程负责将快照写入硬盘</code>，而父进程则继续处理命令请求。
<ul>
<li>这个子进程和原进程数据一模一样，会先将数据写入到一个临时文件中，待持久化结束了，再用这个临时文件替换上次持久化好的文件，</li>
<li>整个过程中，主进程不进程任何的 IO 操作，这就确保了极高的性能</li>
</ul>
</li>
<li><strong>SAVE 命令：</strong> 客户端还可以向 Redis 发送 <strong>SAVE 命令</strong> 来创建一个快照，接到 SAVE 命令的 Redis 服务器在快照创建完毕之前不会再响应任何其他命令。SAVE 命令不常用，我们通常只会在没有足够内存去执行 BGSAVE 命令的情况下，又或者即使等待持久化操作执行完毕也无所谓的情况下，才会使用这个命令。</li>
<li><strong>save 选项：</strong> 如果用户设置了 save 选项（一般会默认设置），比如 <strong>save 60 10000</strong>，那么从 Redis 最近一次创建快照之后开始算起，当 “60 秒之内有 10000 次写入” 这个条件被满足时，Redis 就会自动触发 BGSAVE 命令。</li>
<li><strong>SHUTDOWN 命令：</strong> 当 Redis 通过 SHUTDOWN 命令接收到关闭服务器的请求时，或者接收到标准 TERM 信号时，会执行一个 SAVE 命令，阻塞所有客户端，不再执行客户端发送的任何命令，并在 SAVE 命令执行完毕之后关闭服务器。</li>
<li><strong>一个 Redis 服务器连接到另一个 Redis 服务器：</strong> 当一个 Redis 服务器连接到另一个 Redis 服务器，并向对方发送 SYNC 命令来开始一次复制操作的时候，如果主服务器目前没有执行 BGSAVE 操作，或者主服务器并非刚刚执行完 BGSAVE 操作，那么主服务器就会执行 BGSAVE 命令</li>
</ul>
<h4 id="7-1-1-save"><a class="header-anchor" href="#7-1-1-save">¶</a>7.1.1 save</h4>
<pre class="line-numbers language-none"><code class="language-none">save #手动执行一次保存操作，会阻塞
bgsave # redis会在后台异步进行快照操作，同时可以响应客户端的请求
shutdown # 如果没有开启aof，会触发持久化
执行flushall命令，但是里面是空的，无意义

# 在redis.conf中配置
save 900 1           #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
save 300 10          #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>客户端执行 save 命令，该命令强制 redis 执行快照，这时候 redis 处于阻塞状态，不会响应任何其他客户端发来的请求，直到 RDB 快照文件执行完毕，所以请慎用。</p>
<p>save 指令操作配置：需要在 conf 文件中配置</p>
<ul>
<li>dbfilename dump.rdb
<ul>
<li>说明：设置持久化后文件名（本地数据库文件名），默认值为 dump.rdb</li>
<li>经验：通常设置为 dump - 端口号. rdb</li>
</ul>
</li>
<li>dir
<ul>
<li>说明：设置存储. rdb、log 等文件的路径。加载位置也是这个位置</li>
<li>经验：通常设置成存储空间较大的目录中，目录名称 data</li>
<li>保存时间分 3 种</li>
</ul>
</li>
<li>rdbcompression yes
<ul>
<li>说明：设置存储至本地数据库时是否压缩数据，默认为 yes，采用 LZF 压缩</li>
<li>经验：通常默认为开启状态，如果设置为 no，可以节省 CPU 运行时间，但会使存储的文件变大（巨大）</li>
</ul>
</li>
<li>rdbchecksum yes
<ul>
<li>说明：设置是否进行 RDB 文件格式校验，该校验过程在写文件和读文件过程均进行</li>
<li>经验：通常默认为开启状态，如果设置为 no，可以节约读写性过程约 10% 时间消耗，但是存储一定的数据损坏风险</li>
</ul>
</li>
</ul>
<p>要点：</p>
<ul>
<li>save 一次之后，删除 rdb 文件，重新 save 一次，rdb 文件又出现（恢复）了</li>
<li>退出后再登录，还有数据</li>
</ul>
<p>RDB 工作原理：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/0f467934646780b80335e1d9dae1400f.png" alt="" loading="lazy"></p>
<p>如图，4 个客户端分别输入指令，redis 是单线程的，所以需要排序。</p>
<p>有个问题是如果 save 是第三个，save 执行时间很长，所以后面的 get 需要等待很长时间。就会阻塞。所以线上不建议使用 save 指令，会很拖慢性能。</p>
<p>注意： save 指令的执行会阻塞当前 Redis 服务器， 直到当前 RDB 过程完成为止， 有可能会造成长时间阻塞， 线上环境不建议使用。</p>
<p>其他</p>
<pre class="line-numbers language-none"><code class="language-none"># 查看最近一次持久化时间：
info Persistence

# 查看存储文件位置
CONFIG GET dir<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="7-1-2-bgsave"><a class="header-anchor" href="#7-1-2-bgsave">¶</a>7.1.2 bgsave</h4>
<pre class="line-numbers language-none"><code class="language-none">bgsave # 后台save#手动启动后台保存操作，但不是立即执行<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h4 id="bgsave-原理："><a class="header-anchor" href="#bgsave-原理：">¶</a>bgsave 原理：</h4>
<p><img src="https://images2018.cnblogs.com/blog/1075473/201807/1075473-20180725172641202-1573986143.png" alt="" loading="lazy"></p>
<ol>
<li>客户端执行 bgsave 命令，redis 主进程收到指令并判断此时是否在执行<code>bgrewriteaof</code>(AOF 文件重写过程，后续会讲解)，如果此时正好在执行则 bgsave 直接返回，不 fork 子进程，如果没有执行 bgrewriteaof 重写 AOF 文件，则进入下一个阶段；</li>
<li>主进程调用 fork 方法创建子进程，在创建子进程过程中 redis 主进程阻塞，所以不能响应客户端请求；</li>
<li>子进程创建完成以后，bgsave 命令返回 “Background saving started”，此时标志着 redis 可以响应客户端请求了；</li>
<li>子进程根据主进程的内存副本创建临时快照文件，当快照文件完成以后对原快照文件进行替换；</li>
<li>子进程发送信号给 redis 主进程完成快照操作，主进程更新统计信息（info Persistence 可查看）, 子进程退出；</li>
</ol>
<p>注意： bgsave 命令是针对 save 阻塞问题做的优化。 Redis 内部所有涉及到 RDB 操作都采用 bgsave 的方式， save 命令可以放弃使用</p>
<p>bgsave 命令可以理解为 background save 即：“后台保存”。当执行 bgsave 命令时，redis 会 fork 出一个子进程来执行快照生成操作，需要注意的 redis 是在 fork 子进程这个简短的时间 redis 是阻塞的（此段时间不会响应客户端请求，），当子进程创建完成以后 redis 响应客户端请求。其实 redis 自动快照也是使用 bgsave 来完成的。</p>
<p>bgsave 相关配置：</p>
<pre class="line-numbers language-none"><code class="language-none">dbfilename dump.rdb
dir
rdbcompression yes
rdbchecksum yes
stop-writes-on-bgsave-error yes
说明：后台存储过程中如果出现错误现象，是否停止保存操作
经验：通常默认为开启状态<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>但是 save 和 bgsave 都需要手动保存，难免疏忽，使用需要自动执行。</p>
<p>conf 文件配置持久化条件：</p>
<pre class="line-numbers language-none"><code class="language-none"># 在配置文件中设置
格式：save 时间段 key修改次数
作用:满足限定时间范围内key的变化数量达到指定数量即进行持久化。即时间片内变化大才自动保存，是快照的思想。

 位置:在conf文件中进行配置，把3个都关掉就把RDB持久化关掉了。或者save &quot;&quot; # 但是集群环境下RDB是关不掉的
save 900 1 # 900s内变化一个就保存
save 300 10
save 60 10000<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>配置文件中 save 原理</p>
<p><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422023420.png" alt="" loading="lazy"></p>
<p>发送 3 条指令，每条都会返回个结果，通过结果判断这条指令算不算影响数量。不进行数据比对指的是两个 set 就都算</p>
<p>RDB 三种保存方式对比：</p>
<table><thead><tr><th>方式</th><th>save 指令</th><th>bgsave 指令</th><th>save 配置</th></tr></thead><tbody><tr><td>读写</td><td>同步</td><td>异步</td><td></td></tr><tr><td>阻塞客户端指令</td><td>是</td><td>否</td><td></td></tr><tr><td>额外内存消耗</td><td>否</td><td>是</td><td></td></tr><tr><td>启动新进程</td><td>否</td><td>是</td><td></td></tr></tbody></table>
<p>RDB 特殊启动形式：</p>
<ul>
<li>全量复制：在主从复制中详细讲解</li>
<li>服务器运行过程中重启：debug reload</li>
<li>关闭服务器时指定保存数据：shutdown、 save</li>
</ul>
<p>RDB 优点：</p>
<p>RDB 是一个紧凑压缩的二进制文件， 存储效率较高<br>
 RDB 内部存储的是 redis 在某个时间点的数据快照， 非常适合用于数据备份，全量复制等场景<br>
 RDB 恢复数据的速度要比 AOF 快很多<br>
 应用：服务器中每 X 小时执行 bgsave 备份，并将 RDB 文件拷贝到远程机器中，用于灾难恢复。</p>
<p>RGB 缺点：</p>
<p>RDB 方式无论是执行指令还是利用配置，无法做到实时持久化，具有较大的可能性丢失数据<br>
 bgsave 指令每次运行要执行 fork 操作创建子进程， 要牺牲掉一些性能<br>
 Redis 的众多版本中未进行 RDB 文件格式的版本统一，有可能出现各版本服务之间数据格式无法兼容现象</p>
<ol>
<li>
<p>在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是行话讲的 Snapshot 快照，它恢复时是将快照文件直接读到内存里。</p>
</li>
<li>
<p>备份是如何执行的</p>
</li>
</ol>
<p>Redis 会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何 IO 操作的，这就确保了极高的性能如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那 RDB 方式要比 AOF 方式更加的高效。RDB 的缺点是最后一次持久化后的数据可能丢失。</p>
<ol start="3">
<li>关于 fork</li>
</ol>
<p>在 Linux 程序中，fork() 会产生一个和父进程完全相同的子进程，但子进程在此后多会 exec 系统调用，出于效率考虑，Linux 中引入了 “写时复制技术”，一般情况父进程和子进程会共用同一段物理内存，只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程。</p>
<ol start="4">
<li>RDB 保存的文件名</li>
</ol>
<p>在 redis.conf 中配置文件名称，默认为 dump.rdb</p>
<ol start="5">
<li>RDB 文件的保存路径</li>
</ol>
<p>默认为 Redis 启动时命令行所在的目录下, 也可以修改 dir</p>
<ol start="6">
<li>
<p>RDB 的保存策略</p>
</li>
<li>
<p>手动保存快照</p>
</li>
</ol>
<p>save: 只管保存，其它不管，全部阻塞</p>
<p>bgsave: 按照保存策略自动保存</p>
<ol start="8">
<li>RDB 的相关配置</li>
</ol>
<ul>
<li>stop-writes-on-bgsave-error yes</li>
</ul>
<p>当 Redis 无法写入磁盘的话，直接关掉 Redis 的写操作</p>
<ul>
<li>rdbcompression yes</li>
</ul>
<p>进行 rdb 保存时，将文件压缩</p>
<ul>
<li>rdbchecksum yes</li>
</ul>
<p>在存储快照后，还可以让 Redis 使用 CRC64 算法来进行数据校验，但是这样做会增加大约 10% 的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能</p>
<ol start="9">
<li>RDB 的备份 与恢复</li>
</ol>
<p>备份: 先通过 config get dir 查询 rdb 文件的目录 , 将 *.rdb 的文件拷贝到别的地方</p>
<p>恢复: 关闭 Redis，把备份的文件拷贝到工作目录下, 启动 redis, 备份数据会直接加载。</p>
<ol start="10">
<li>RDB 的优缺点</li>
</ol>
<p>优点: 节省磁盘空间, 恢复速度快.</p>
<p>缺点: 虽然 Redis 在 fork 时使用了写时拷贝技术, 但是如果数据庞大时还是比较消耗性能。 在备份周期在一定间隔时间做一次备份，所以如果 Redis 意外 down 掉的话，就会丢失最后一次快照后的所有修改</p>
<h2 id="7-2-AOF"><a class="header-anchor" href="#7-2-AOF">¶</a>7.2 AOF</h2>
<p>RDB 弊端：</p>
<p>存储数据量较大，效率较低<br>
基于快照思想，每次读写都是全部数据，当数据量巨大时，效率非常低<br>
 大数据量下的 IO 性能较低<br>
 基于 fork 创建子进程，内存产生额外消耗<br>
 宕机带来的数据丢失风险</p>
<p>解决思路：</p>
<p>不写全数据，仅记录部分数据<br>
 降低区分数据是否改变的难度，改记录数据为记录操作过程<br>
 对所有操作均进行记录，排除丢失数据的风险</p>
<p>什么是 AOF：</p>
<ul>
<li>AOF(append only file) 持久化：以独立日志的方式记录每次 (写) 命令，重启时再重新执行 AOF 文件中命令达到恢复数据的目的。与 RDB 相比可以简单描述为改记录数据为记录数据产生的过程</li>
<li>AOF 的主要作用是解决了数据持久化的实时性，目前已经是 Redis 持久化的主流方式</li>
<li>比如 10 条 incre 命令，就自动替换为了 set lock 11</li>
</ul>
<p>当 redis 存储非临时数据时，为了降低 redis 故障而引起的数据丢失，redis 提供了 AOF(Append Only File) 持久化，从单词意思讲，将命令追加到文件。AOF 可以将 Redis 执行的每一条写命令追加到磁盘文件 (appendonly.aof) 中, 在 redis 启动时候优先选择从 AOF 文件恢复数据。由于每一次的写操作，redis 都会记录到文件中，所以开启 AOF 持久化会对性能有一定的影响，但是大部分情况下这个影响是可以接受的，我们可以使用读写速率高的硬盘提高 AOF 性能。与 RDB 持久化相比，AOF 持久化数据丢失更少，其消耗内存更少 (RDB 方式执行 bgsve 会有内存拷贝)。</p>
<p>默认情况下，redis 是关闭了 AOF 持久化，开启 AOF 通过配置<code>appendonly</code>为 yes 开启，我们修改配置文件或者在命令行直接使用 config set 修改，在用 config rewrite 同步到配置文件。通过客户端修改好处是不用重启 redis，AOF 持久化直接生效。</p>
<h5 id="AOF-刷新缓存区"><a class="header-anchor" href="#AOF-刷新缓存区">¶</a>AOF 刷新缓存区</h5>
<p>AOF 写数据过程：</p>
<p>当客户端发出一条指令给服务器时，服务器收到并没有马上记录，而是放到临时区域：刷新缓存区，缓存区是最终存成文件时用的。<br>
<img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422024611.png" alt="" loading="lazy"></p>
<h4 id="AOF-持久化策略-写数据"><a class="header-anchor" href="#AOF-持久化策略-写数据">¶</a>AOF 持久化策略 (写数据)</h4>
<p>与快照持久化相比，AOF 持久化 的<strong>实时性更好</strong>，因此已成为主流的持久化方案。默认情况下 Redis 没有开启 AOF（append only file）方式的持久化，可以通过 appendonly 参数开启：</p>
<p>开启 AOF 功能：<code>appendonly yes|no(默认)</code></p>
<p>从缓冲区同步到文件调用的是 fsync 方法</p>
<ol>
<li>追加写入</li>
</ol>
<p>redis 将每一条写命令以 redis 通讯协议添加至<strong>缓冲区 aof_buf</strong>，这样的好处在于在大量写请求情况下，采用缓冲区暂存一部分命令随后根据策略一次性写入磁盘，这样可以减少磁盘的 I/O 次数，提高性能。</p>
<ol start="2">
<li>同步命令到硬盘</li>
</ol>
<p>当写命令写入 aof_buf 缓冲区后，redis 会将缓冲区的命令写入到文件。</p>
<p>什么情况下缓冲区同步到文件中是个问题。redis 提供了三种同步策略，由配置参数 appendfsync 决定，下面是每个策略所对应的含义：<br>
可以在 conf 文件中配置 appendfsync</p>
<ul>
<li>no：不使用 fsync 方法同步，而是交给操作系统 write 函数去执行同步操作，在 linux 操作系统中大约每 30 秒刷一次缓冲。这种情况下，缓冲区数据同步不可控，并且在大量的写操作下，aof_buf 缓冲区会堆积会越来越严重，一旦 redis 出现故障，数据丢失严重。</li>
<li>always：表示每次有写操作都调用 fsync 方法强制内核将数据写入到 aof 文件。这种情况下由于<strong>每次写命令都写到了文件中</strong>, 虽然数据比较安全，但是因为每次写操作都会同步到 AOF 文件中，所以在性能上会有影响，同时由于频繁的 IO 操作，硬盘的使用寿命会降低。</li>
<li>everysec：数据将使用调用操作系统 write 写入文件，并使用 fsync <strong>每秒一次从内核刷新到磁盘</strong>。 这是折中的方案，兼顾性能和数据安全，所以 redis 默认推荐使用该配置。</li>
</ul>
<p>dir：与 RDB 同，默认<code>appendonly.aof</code></p>
<p>appendfilename：AOF 持久化文件名，默认文件名未 appendonly.aof，建议配置为 appendonly - 端口号. aof</p>
<p>开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入硬盘中的 AOF 文件。</p>
<p>AOF 写数据遇到的问题：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/def1c5bb11ff1a075e5eebead0dbf571.png" alt="" loading="lazy"></p>
<p><strong>虽然 AOF 持久化非常灵活地提供了多种不同的选项来满足不同应用程序对数据安全的不同要求，但 AOF 持久化也有缺陷——AOF 文件的体积太大。</strong></p>
<h4 id="AOF-重写"><a class="header-anchor" href="#AOF-重写">¶</a><strong>AOF 重写</strong></h4>
<p>随着命令不断写入 AOF，文件会越来越大，为了解决这个问题， Redis 引入了 AOF 重写机制压缩文件体积，redis 能够调用<code>bgrewriteaof</code>对日志文件进行重写。 AOF 文件重写是将 Redis 进程内的数据转化为写命令同步到新 AOF 文件的过程。 简单说就是将对同一个数据的若干个条命令执行结果转化成最终结果数据对应的指令进行记录。</p>
<p>AOF 重写可以产生一个新的 AOF 文件，这个新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。</p>
<p>触发 AOF 文件重写条件（后续会说明）时候，redis 将使用 bgrewriteaof 对 AOF 文件进行重写。这样的好处在于减少 AOF 文件大小，同时有利于数据的恢复。</p>
<p>为了解决 AOF 体积过大的问题，用户可以向 Redis 发送 <strong>BGREWRITEAOF 命令</strong> ，这个命令会通过移除 AOF 文件中的冗余命令来重写（rewrite）AOF 文件来减小 AOF 文件的体积。BGREWRITEAOF 命令和 BGSAVE 创建快照原理十分相似，所以 AOF 文件重写也需要用到<strong>子进程</strong>，这样会导致性能问题和内存占用问题，和快照持久化一样。更糟糕的是，如果不加以控制的话，AOF 文件的体积可能会比快照文件大好几倍。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/2a2b74011307bda37dad2b2be2bf81fd.png" alt="" loading="lazy"><img src="https://images2018.cnblogs.com/blog/1075473/201807/1075473-20180726171841786-525684493.png" alt="" loading="lazy"></p>
<h4 id="AOF-重写过程-AOF-重写缓冲区"><a class="header-anchor" href="#AOF-重写过程-AOF-重写缓冲区">¶</a>AOF 重写过程 (AOF 重写缓冲区)</h4>
<p>在执行 <code>BGREWRITEAOF</code>命令时，Redis 服务器会维护一个 <strong>AOF 重写缓冲区，该缓冲区会在子进程创建新 AOF 文件期间，记录服务器执行的所有写命令</strong>。<strong>当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新旧两个 AOF 文件所保存的数据库状态一致</strong>。最后，服务器用新的 AOF 文件替换旧的 AOF 文件，以此来完成 AOF 文件重写操作</p>
<p>AOF 文件重写过程与 RDB 快照 bgsave 工作过程有点相似，都是通过 fork 子进程，由子进程完成相应的操作，同样的在 fork 子进程简短的时间内，redis 是阻塞的：</p>
<p>重写过程说明：</p>
<p>aof_rewrite_buf 代表重写缓冲区 。aof_buf 代表写命令存放的缓冲区</p>
<ul>
<li>
<ol>
<li>开始<code>bgrewriteaof</code>，判断当前有没有<code>bgsave</code>命令 (RDB 持久化)/bgrewriteaof 在执行，倘若有，则这些命令执行完成以后在执行。</li>
</ol>
</li>
<li>
<ol start="2">
<li>主进程 fork 出子进程，在这一个短暂的时间内，redis 是阻塞的。</li>
</ol>
</li>
<li>
<ol start="3">
<li>主进程 fork 完子进程继续接受客户端请求，<strong>所有写命令依然写入 AOF 文件缓冲区</strong>并根据 appendfsync 策略同步到磁盘，保证原有 AOF 文件完整和正确。由于 fork 的子进程仅仅只共享主进程 fork 时的内存，因此 Redis 使用采用重写缓冲区 (aof_rewrite_buf) 机制保存 fork 之后的客户端的写请求，防止新 AOF 文件生成期间丢失这部分数据。此时，客户端的写请求不仅仅写入原来 aof_buf 缓冲，还写入重写缓冲区(aof_rewrite_buf)。</li>
</ol>
</li>
<li>
<ol start="4">
<li>子进程通过内存快照，按照命令重写策略写入到新的 AOF 文件。</li>
</ol>
<ul>
<li>4.1 子进程写完新的 AOF 文件后，向主进程发信号，父进程更新统计信息。</li>
<li>4.2 主进程把 AOFaof_rewrite_buf 中的数据写入到新的 AOF 文件 (避免写文件是数据丢失)。</li>
</ul>
</li>
<li>
<ol start="5">
<li>使用新的 AOF 文件覆盖旧的 AOF 文件，标志 AOF 重写完成。</li>
</ol>
</li>
</ul>
<p>重写时机：</p>
<p>redis 开启在 AOF 功能开启的情况下，会维持以下三个变量</p>
<ul>
<li>记录当前 AOF 文件大小的变量 aof_current_size。</li>
<li>记录最后一次 AOF 重写之后，AOF 文件大小的变量 aof_rewrite_base_size。</li>
<li>增长百分比变量 aof_rewrite_perc。</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none">#手动重写
命令行输入bgrewriteaof

#自动重写
#配置文件里写
auto-aof-rewrite-min-size 64Mb #达到这个大小才重写 #改为5GB，因为会fork子进程，我们尽量让他少触发
auto-aof-rewrite-percentage 100   # 达到百分比

每次重写完后重新设置baseSize大小，下一次重写的标准是相当于这个baseSize计算的
系统载入时或者上次重写完毕时，Redis会记录此时AOF大小，设为base_size,如果Redis的AOF当前大小&gt;&#x3D; base_size +base_size*100% (默认)且当前大小&gt;&#x3D;64mb(默认)的情况下，Redis会对AOF进行重写。

 自动重写触发比对参数（ 运行指令info Persistence获取具体信息 ）
aof_current_size
aof_base_size

 自动重写触发条件<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="https://img-blog.csdnimg.cn/img_convert/e66715f07790a90354d96f77fe064477.png" alt="" loading="lazy"></p>
<p>每次当 serverCron（服务器周期性操作函数）函数执行时，它会检查以下条件是否全部满足，如果全部满足的话，就触发自动的 AOF 重写操作：</p>
<ul>
<li>没有 BGSAVE 命令（RDB 持久化）/AOF 持久化在执行；</li>
<li>没有 BGREWRITEAOF 在进行；</li>
<li>当前 AOF 文件大小要大于 server.aof_rewrite_min_size 的值；</li>
<li>当前 AOF 文件大小和最后一次重写后的大小之间的比率等于或者大于指定的增长百分比（auto-aof-rewrite-percentage 参数）</li>
</ul>
<p>AOP 重写会 fork 子进程</p>
<p>AOF 重写作用</p>
<ul>
<li>降低磁盘占用量，提高磁盘利用率</li>
<li>提高持久化效率，降低持久化写时间，提高 IO 性能</li>
<li>提高数据恢复效率</li>
</ul>
<p>AOF 重写规则</p>
<ul>
<li>进程内已超时的数据不再写入文件</li>
<li>忽略无效指令，重写时使用进程内数据直接生成，这样新的 AOF 文件只保留最终数据的写入命令<br>
如 del key1、 hdel key2、 srem key3、 set key4 111、 set key4 222 等</li>
<li>对同一数据的多条写命令合并为一条命令<br>
如 lpush list1 a、 lpush list1 b、 lpush list1 c 可以转化为： lpush list1 a b c。</li>
<li>为防止数据量过大造成客户端缓冲区溢出，对 list、 set、 hash、 zset 等类型， 每条指令最多写入 64 个元素</li>
</ul>
<h2 id="7-3-RDB-AOF-混合持久化"><a class="header-anchor" href="#7-3-RDB-AOF-混合持久化">¶</a>7.3 RDB+AOF 混合持久化</h2>
<p>redis4.0 相对与 3.X 版本其中一个比较大的变化是 4.0 添加了新的混合持久化方式。前面已经详细介绍了 AOF 持久化以及 RDB 持久化，这里介绍的混合持久化就是同时结合 RDB 持久化以及 AOF 持久化混合写入 AOF 文件。这样做的好处是可以结合 rdb 和 aof 的优点, 快速加载同时避免丢失过多的数据，缺点是 aof 里面的 rdb 部分就是压缩格式不再是 aof 格式，可读性差。</p>
<h4 id="开启混合持久化"><a class="header-anchor" href="#开启混合持久化">¶</a>开启混合持久化</h4>
<ul>
<li>4.0 版本的<code>混合持久化默认关闭</code>的，通过<code>aof-use-rdb-preamble</code>配置参数控制，yes 则表示开启，no 表示禁用，</li>
<li>5.0 之后默认开启。</li>
</ul>
<p>如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。</p>
<p>redis4.0 之后的混合持久化是对重写的进一步优化，他以 RDB 格式保存更节约内存</p>
<ul>
<li>RBD：会 fork 子进程，有可能会丢失最后一次写入的数据，启动 redis 的适合，从磁盘加载持久化数据快</li>
<li>AOF：不会 fork 子进程，最多丢失不会超过 2s 的数据（此时是因为选用是 EverySec），启动 redis 的适合，从磁盘加载持久化数据不如 RDB</li>
<li>AOF 重写：会 fork 子进程</li>
</ul>
<p>混合持久化同样也是通过<code>bgrewriteaof</code>完成的，不同的是当开启混合持久化时，fork 出的子进程先将共享的内存副本全量的以 RDB 方式写入 aof 文件，然后在将重写缓冲区的增量命令以 AOF 方式写入到文件，写入完成后通知主进程更新统计信息，并将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。简单的说：新的 AOF 文件前半段是 RDB 格式的全量数据后半段是 AOF 格式的增量数据，如下图：</p>
<p><img src="https://images2018.cnblogs.com/blog/1075473/201807/1075473-20180726181756270-1907770368.png" alt="" loading="lazy"></p>
<ul>
<li>优点：混合持久化结合了 RDB 持久化 和 AOF 持久化的优点, 由于绝大部分都是 RDB 格式，加载速度快，同时结合 AOF，增量的数据以 AOF 方式保存了，数据更少的丢失。</li>
<li>缺点：兼容性差，一旦开启了混合持久化，在 4.0 之前版本都不识别该 aof 文件，同时由于前部分是 RDB 格式，阅读性较差</li>
</ul>
<p>数库恢复：</p>
<ul>
<li>aof 文件开头是 rdb 的格式, 先加载 rdb 内容再加载剩余的 aof。</li>
<li>aof 文件开头不是 rdb 的格式，直接以 aof 格式加载整个文件</li>
</ul>
<p>AOF 工作流程：</p>
<ul>
<li>Always 时，Set 正常执行，另开一个子进程进行重写。</li>
<li>Sec 时会先放到缓存区。</li>
</ul>
<p>AOF 重写流程：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/f3bf2f42c120d30ebe8c1e4a1bb82512.png" alt="" loading="lazy"></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/5c7c5a3284f9179b95831155658dee84.png" alt="" loading="lazy"></p>
<p>AOF 缓冲区同步文件策略， 由参数 appendfsync 控制<br>
系统调用 write 和 fsync 说明：</p>
<p> write 操作会触发延迟写（ delayed write） 机制， Linux 在内核提供页缓冲区用来提高硬盘 IO 性能。 write 操作在写入系统缓冲区后直接返回。 同步硬盘操作依赖于系统调度机制， 列如：缓冲区页空间写满或达到特定时间周期。 同步文件之前， 如果此时系统故障宕机， 缓冲区内数据将丢失。</p>
<p> fsync 针对单个文件操作（ 比如 AOF 文件） ， 做强制硬盘同步， fsync 将阻塞知道写入硬盘完成后返回， 保证了数据持久化。</p>
<p>除了 write、 fsync、 Linx 还提供了 sync、 fdatasync 操作， 具体 API 说明参见：</p>
<ol start="5">
<li>AOF 文件故障备份</li>
</ol>
<p>AOF 的备份机制和性能虽然和 RDB 不同, 但是备份和恢复的操作同 RDB 一样，都是拷贝备份文件，需要恢复时再拷贝到 Redis 工作目录下，启动系统即加载</p>
<ol start="6">
<li>AOF 文件故障恢复</li>
</ol>
<p>如遇到 AOF 文件损坏，可通过 redis-check-aof --fix appendonly.aof 进行恢复</p>
<ol start="8">
<li>Rewrite</li>
</ol>
<p>l AOF 采用文件追加方式，文件会越来越大为避免出现此种情况，新增了重写机制, 当 AOF 文件的大小超过所设定的阈值时，Redis 就会启动 AOF 文件的内容压缩，只保留可以恢复数据的最小指令集. 可以使用命令 bgrewriteaof。</p>
<p>l Redis 如何实现重写</p>
<p>AOF 文件持续增长而过大时，会 fork 出一条新进程来将文件重写 (也是先写临时文件最后再 rename)，遍历新进程的内存中数据，每条记录有一条的 Set 语句。重写 aof 文件的操作，并没有读取旧的 aof 文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的 aof 文件，这点和快照有点类似。</p>
<h2 id="7-3-RDB-和-AOF-比较"><a class="header-anchor" href="#7-3-RDB-和-AOF-比较">¶</a>7.3 RDB 和 AOF 比较</h2>
<table><thead><tr><th>持久化方式</th><th>RDB</th><th>AOF</th></tr></thead><tbody><tr><td>占用存储空间</td><td>小（数据级：压缩）</td><td>大（指令级：重写）</td></tr><tr><td>存储速度</td><td>慢</td><td>快</td></tr><tr><td>恢复速度</td><td>快</td><td>慢</td></tr><tr><td>数据安全性</td><td>同步时间间隔大</td><td>同步时间间隔小</td></tr><tr><td>资源消耗</td><td>高 / 重量级</td><td>低 / 轻量级</td></tr><tr><td>启动优先级</td><td>低</td><td>高</td></tr></tbody></table>
<p>AOF 和 RDB 同时开启，redis 听谁的？：官方建议 两种持久化机制同时开启，如果两个同时开启 优先使用 aof</p>
<ul>
<li>官方推荐两个都启用。</li>
<li>如果对数据不敏感，可以选单独用 RDB</li>
<li>不建议单独用 AOF，因为可能会出现 Bug。</li>
<li>如果只是做纯内存缓存，可以都不用</li>
<li>双保险策略， 同时开启 RDB 和 AOF， 重启后， Redis 优先使用 AOF 来恢复数据，降低丢失数据的量</li>
</ul>
<p>对数据非常敏感， 建议使用默认的 AOF 持久化方案<br>
 AOF 持久化策略使用 everysecond，每秒钟 fsync 一次。该策略 redis 仍可以保持很好的处理性能， 当出<br>
现问题时，最多丢失 0-1 秒内的数据。<br>
 注意：由于 AOF 文件存储体积较大，且恢复速度较慢<br>
 数据呈现阶段有效性，建议使用 RDB 持久化方案<br>
 数据可以良好的做到阶段内无丢失（该阶段是开发者或运维人员手工维护的），且恢复速度较快，阶段<br>
点数据恢复通常采用 RDB 方案<br>
 注意：利用 RDB 实现紧凑的数据持久化会使 Redis 降的很低，慎重总结：<br>
 综合比对<br>
 RDB 与 AOF 的选择实际上是在做一种权衡，每种都有利有弊<br>
 如不能承受数分钟以内的数据丢失，对业务数据非常敏感， 选用 AOF<br>
 如能承受数分钟以内的数据丢失， 且追求大数据集的恢复速度， 选用 RDB<br>
 灾难恢复选用 RDB</p>
<h2 id="开机加载持久化步骤"><a class="header-anchor" href="#开机加载持久化步骤">¶</a>开机加载持久化步骤</h2>
<p>优先加载 aof 文件</p>
<p><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200605124921.png" alt="" loading="lazy"><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200908120235.png" alt="" loading="lazy"></p>
<h1>⑧ 过期数据删除策略</h1>
<p>Redis 中有个设置时间过期的功能，即对存储在 redis 数据库中的值可以设置一个过期时间。作为一个缓存数据库，这是非常实用的。如我们一般项目中的 token 或者一些登录信息，尤其是短信验证码都是有时间限制的，按照传统的数据库处理方式，一般都是自己判断过期，这样无疑会严重影响项目性能。</p>
<p>如果假设你设置了一批 key 只能存活 1 个小时，那么接下来 1 小时后，redis 是怎么对这批 key 进行删除的？</p>
<p>过期的数据真的被删除了吗？扔垃圾我们往往都是过会再扔。等 CPU 空闲时候再处理扔。这就是删除策略</p>
<ul>
<li>1 定时删除</li>
<li>2 惰性删除</li>
<li>3 定期删除</li>
</ul>
<h3 id="0-时效性数据的存储结构"><a class="header-anchor" href="#0-时效性数据的存储结构">¶</a>0 时效性数据的存储结构</h3>
<p><img src="https://img-blog.csdnimg.cn/img_convert/16d55a85a2b764e424a9800189966206.png" alt="" loading="lazy"></p>
<p>这四种操作会给 key 设置一个过期时间，这个过期时间存放在 expires 区域里。右面的 1359… 是一个系统时间点</p>
<p>数据删除策略的目标：在内存占用与 CPU 占用之间寻找一种平衡，顾此失彼都会造成整体 redis 性能的下降，甚至引发服务器宕机或内存泄露</p>
<p>内存释放的策略：Redis 中有专门释放内存的函数：freeMmoryIfNeeded。每当执行一个命令的时候，就会调用该函数来检测内存是否够用。如果已用内存大于最大内存限制，它就会进行内存释放。</p>
<p>代码：<a target="_blank" rel="noopener" href="https://blog.csdn.net/libafei/article/details/80311372">https://blog.csdn.net/libafei/article/details/80311372</a></p>
<h3 id="1-定时删除"><a class="header-anchor" href="#1-定时删除">¶</a>1 定时删除</h3>
<p> 创建一个定时器，当 key 设置有过期时间，且过期时间到达时，由定时器任务立即执行对键的删除操作。此时存储空间的东西也删除了 expires 空间的内容也删除了。（拿时间换空间）</p>
<p> 优点：节约内存，到时就删除，快速释放掉不必要的内存占用</p>
<p> 缺点： CPU 压力很大，无论 CPU 此时负载量多高，均占用 CPU 去进行删除，会影响 redis 服务器响应时间和指令吞吐量</p>
<h3 id="2-惰性删除"><a class="header-anchor" href="#2-惰性删除">¶</a>2 惰性删除</h3>
<p>数据到达过期时间，不做处理（此时还在 expires 区里存在）。等下次访问该数据时</p>
<ul>
<li>如果未过期，返回数据</li>
<li>发现已过期，删除，返回不存在</li>
</ul>
<p>惰性删除由<code>db.c/expireIfNeeded()</code>函数实现，所有读写数据库的命令在执行之前都会调用 expireIfNeeded（）函数对要操作的 key 进行检查。如果 key 已经过期，那么将会将 key 从数据库中删除</p>
<p> 优点：节约 CPU 性能，发现必须删除的时候才删除（拿时间换空间）<br>
 缺点：内存压力很大，出现长期占用内存的数据</p>
<h3 id="3-定期删除"><a class="header-anchor" href="#3-定期删除">¶</a>3 定期删除</h3>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/d0be3c255fc6">https://www.jianshu.com/p/d0be3c255fc6</a><br>
两种方案都走极端，有没有折中方案？</p>
<p>redis 默认是每隔 100ms 就<strong>随机抽取</strong>一些设置了过期时间的 key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？你想一想假如 redis 存了几十万个 key ，每隔 100ms 就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载！</p>
<p>定期删除由函数<code>redis.c/activeExpireCycle()</code>函数实现，每当 server 在调用 beforeSleep() 和 serverCron() 时，都会被调用。</p>
<p>每个库都有一个 expire 区，expire[0]…expire[15]，即 16 个 db</p>
<ul>
<li>
<p>Redis 启动服务器初始化时，读取配置 server.hz 的值，默认为 10。（通过<code>info server</code>查询），该值代表 CPU 每秒对 16 个库整体进行的查询次数。每次过期 key 清理的时间不超过 CPU 时间的 25%，即若 hz=1，则一次清理时间最大为 250ms，若 hz=10，则一次清理时间最大为 25ms；清理时依次遍历所有的 db；从 db 中随机取 20 个 key，判断是否过期，若过期，则逐出；若有 5 个以上 key 过期，则重复步骤 4，否则遍历下一个 db；在清理过程中，若达到了 25%CPU 时间，退出清理过程；</p>
</li>
<li>
<p>每秒钟执行 server.hz 次 (10) 函数 ==serverCron()== 对服务器进行定时轮询。其中会调用：==databaseCron()== 继续对每个库进行轮询，该函数会调用：==activeExporeCycle()== 对变量进行检查</p>
</li>
<li>
<p>activeExpireCycle() 对每个 expires[0] 里的变量逐一进行检测，每次执行 250ms/server.hz</p>
</li>
<li>
<p>对某个 expires[0] 检测时，随机挑选 W 个 key 检测</p>
<ul>
<li>W=ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 属性值（配置文件中）</li>
<li>对这 W 个 key 进行以下操作：</li>
<li>如果 key 超时，删除 key</li>
<li>如果一轮中删除的 key 的数量 &gt; W*25%，说明删除的量比较大，很可能还有很多没删除的，循环该过程</li>
<li>如果一轮中删除的 key 的数量≤W*25%，检查下一个 expires[1]，如此轮询 16 个库， 0-15 循环</li>
</ul>
</li>
<li>
<p>那么下次轮询从几号库开始查询呢？：参数 current_db 用于记录 activeExpireCycle() 进入哪个 expires[] 执行。如果 activeExpireCycle() 执行时间到期，下次从 current_db 继续向下执行。取值 0-15？</p>
</li>
</ul>
<p>定期删除总结：</p>
<p> 特点 1： CPU 性能占用设置有峰值，检测频度可自定义设置<br>
 特点 2：内存压力不是很大，长期占用内存的冷数据会被持续清理</p>
<p>周期性抽查，抽查不合格的停着监督让整改后再检测他</p>
<p>但是仅仅通过设置过期时间还是有问题的。我们想一下：如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期 key 堆积在内存里，导致 redis 内存块耗尽了。怎么解决这个问题呢？ <strong>redis 内存淘汰机制。</strong></p>
<h1>⑨ 内存不足逐出算法：</h1>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/b1b4eeccc140">https://www.jianshu.com/p/b1b4eeccc140</a><br>
redis 内存淘汰机制 (MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据?)</p>
<p>新数据进入检测：当新数据进入 redis 时，如果 redis 内存不足怎么办？expire 控制的是过期数据，如果都不会过期怎么办？</p>
<p> Redis 使用内存存储数据，<strong>在执行每一个命令前</strong>，会调用 ==freeMemoryIfNeeded()== 检测内存是否充足。如果内存不满足新加入数据的最低存储要求， redis 要临时删除一些数据为当前指令清理存储空间。清理数据的策略称为逐出算法（临时淘汰）。</p>
<p> 注意：逐出算法不一定肯定成功：逐出数据的过程不是 100% 能够清理出足够的可使用的内存空间，如果不成功则反复执行。当对所有数据尝试完毕后，如果不能达到内存清理的要求，将出现错误信息：</p>
<p>(error) OOM command not allowed when used memory &gt;‘maxmemory’</p>
<p>设置方法：</p>
<pre class="line-numbers language-none"><code class="language-none"># 最大可使用内存：占用物理内存的比例，默认值为0，表示不限制，全用掉内存。生产环境中根据需求设定，通常设置在50%以上。
maxmemory
# 每次选取待删除数据的个数：选取数据时并不会全库扫描，导致严重的性能消耗，降低读写性能。因此采用随机获取数据的方式作为待检测删除数据
maxmemory-samples

# 删除策略，即删除哪个：达到最大内存后的，对被挑选出来的数据进行删除的策略  
maxmemory-policy  下面删除策略之一  # maxmemory-policy  volatile-lru
 检测易失数据（可能会过期的数据集server.db[i].expires ）
① volatile-lru：挑选最近最少使用的数据淘汰。Least Recently Used。从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
最久没使用
② volatile-lfu：挑选最近使用次数最少的数据淘汰。Least Frequently Used。从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰。当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key
时间段内使用次数最少
③ volatile-ttl：挑选将要过期的数据淘汰。从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
④ volatile-random：任意选择数据淘汰。从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰

 检测当前库全库数据（所有数据集server.db[i].dict ）
⑤ allkeys-lru：挑选最近最少使用的数据淘汰。当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的）
⑥ allkeys-lfu：挑选最近使用次数最少的数据淘汰。当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key
⑦ allkeys-random：任意选择数据淘汰。从数据集（server.db[i].dict）中任意选择数据淘汰

 放弃数据驱逐
⑧ no-enviction（驱逐）：禁止驱逐数据（ redis4.0中默认策略），会引发错误OOM（ Out Of Memory） 。禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>数据逐出策略配置依据： 使用 INFO 命令输出监控信息，查询缓存 hit 和 miss 的次数，根据业务需求调优 Redis 配置</p>
<h1>服务器配置</h1>
<pre class="line-numbers language-none"><code class="language-none"># -----服务器端设置-----
daemonize yes|no # 设置服务器以守护进程的方式运行

bind 127.0.0.1 # 绑定主机地址，如果不绑别人也能访问

port 6379 # 设置服务器端口号
databases 16  # 设置数据库数量


# -----日志配置-----
loglevel debug|verbose|notice|warning #  设置服务器以指定日志记录级别
logfile 端口号.log  #  日志记录文件名

#  -----客户端配置-----
maxclients 0  # 设置同一时间最大客户端连接数，默认无限制。当客户端连接到达上限， Redis会关闭新的连接
# 注意：日志级别开发期设置为verbose即可，生产环境中配置为notice，简化日志输出量，降低写日志IO的频度  
timeout 300 #  客户端闲置等待最大时长，达到最大值后关闭连接。如需关闭该功能，设置为 0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>多服务器快捷配置：</p>
<p> 导入并加载指定配置文件信息，用于快速创建 redis 公共配置较多的 redis 实例配置文件，便于维护</p>
<p>include /path/server - 端口号. conf</p>
<p>相当于继承</p>
<h1>高级数据模型</h1>
<h4 id="Pipline"><a class="header-anchor" href="#Pipline">¶</a>Pipline</h4>
<pre class="line-numbers language-none"><code class="language-none">Jedis jedis &#x3D; new Jedis(&quot;192.168.1.2&quot;,6379);
&#x2F;&#x2F; 原来 ：n个命令&#x3D;n个连接时间+n处理时间
for(int i&#x3D;0;i&lt;100;i++)&#123;&#x2F;&#x2F;原来每条命令都会请求一遍，管道会多条指令请求一次
    &#x2F;&#x2F; 现在：n个命令&#x3D;1次连接事件+n次处理时间
    Pipeline pipeline &#x3D; jedis.pipilined();
    for(int j&#x3D;i*100;i&lt;(i+1)*100;j++)&#123;
        pipeline.hset(&quot;bbbb&quot;+j,&quot;bbbb&quot;+j,&quot;bbbb&quot;+j);
    &#125;
    pipeline&#x3D;syncAndReturnAll(); 
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Bitmaps"><a class="header-anchor" href="#Bitmaps">¶</a>Bitmaps</h3>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_16399991/article/details/83512937">https://blog.csdn.net/qq_16399991/article/details/83512937</a></p>
<p>场景：</p>
<ul>
<li>统计日活</li>
</ul>
<p>点赞，取消点赞，查看是否点赞，统一一共有多少点赞</p>
<p>电影网站是有资源常年没有人浏览，可以删除。年度浏览最低起，月浏览量最低。我们用计算机上最小单位 bit 存储状态。用 string</p>
<p>Bitmaps 类型的基础操作：</p>
<ul>
<li><code>getbit key offset</code>：获取指定 key 对应偏移量上的 bit 值 :</li>
<li><code>setbit key offset value</code>：设置指定 key 对应偏移量上的 bit 值， value 只能是 1 或 0。 如<code>setbit 20200606 0 1</code>，就代表这个字符串的第 0 位为 1</li>
<li><code>bitcount key [start][end]</code>：计数 1</li>
<li><code>bitop op destkey key[key....]</code> ：op 可以为 and / or / not / nor</li>
</ul>
<p>比如我们统计电影网站上很多电影每天 / 每周 / 每月有没有人观看，一个人都没人看的电影就可以删了节约数据库了。</p>
<p>解决思路是我们可以【每日】给所以电影设置一个字符串，即这个字符串的每一位代表一部电影，如果有人浏览，这部电影对应的那一位就置为 1，这样就拿一个字符串就统计了全部电影的每日是否被点击。</p>
<p>如果我们想统计每周各部电影是否被观看，只需要把那七天的 7 个字符串进行按位或操作即可，即得到了一个字符串，各个位代表这周这部电影是否被观看</p>
<p>下图的意思是第一天有没有被观看，第二天有没有被关键，进行或操作后就是这两天有没有被观看。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/17cc08c1e8cc52e8d663621fc7128f12.png" alt="" loading="lazy"></p>
<h4 id="谷歌提供的位图计算器"><a class="header-anchor" href="#谷歌提供的位图计算器">¶</a>谷歌提供的位图计算器</h4>
<p>首先导入依赖：guava，其中不只有位图</p>
<h3 id="HyperLogLog："><a class="header-anchor" href="#HyperLogLog：">¶</a>HyperLogLog：</h3>
<p>用处：统计独立 UV</p>
<p> 原始方案： set<br>
 存储每个用户的 id（字符串）<br>
 改进方案： Bitmaps<br>
 存储每个用户状态（ bit）<br>
 全新的方案： Hyperloglog</p>
<p>基数：基数是数据集去重后元素个数，即 set<br>
 HyperLogLog 是用来做基数统计的，运用了 LogLog 的算法</p>
<p>HyperLogLog 类型的基本操作</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F;添加数据
pfadd key element [element ...]
    
&#x2F;&#x2F;统计数据
pfcount key [key ...]

&#x2F;&#x2F;合并数据
pfmerge des tkey sourcekey [sourcekey...]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Tips 22：<br>
 redis 应用于独立信息统计</p>
<p>相关说明<br>
 用于进行基数统计，不是集合，不保存数据，只记录数量而不是具体数据<br>
 核心是基数估算算法，最终数值存在一定误差<br>
 误差范围：基数估计的结果是一个带有 0.81% 标准错误的近似值<br>
 耗空间极小，每个 hyperloglog key 占用了 12K 的内存用于标记基数<br>
 pfadd 命令不是一次性分配 12K 内存使用，会随着基数的增加内存逐渐增大<br>
 Pfmerge 命令合并后占用的存储空间为 12K，无论合并之前数据量多少</p>
<h3 id="GEO："><a class="header-anchor" href="#GEO：">¶</a>GEO：</h3>
<pre class="line-numbers language-none"><code class="language-none">GEO类型的基本操作
# 添加坐标点
geoadd key longitude latitude member [longitude latitude member ...]
georadius key longitude latitude radius m|km|ft|mi [withcoord] [withdist] [withhash] [count count]
# 获取坐标点
geopos key member [member ...]
georadiusbymember key member radius m|km|ft|mi [withcoord] [withdist] [withhash] [count count]

# 计算坐标点距离
geodist key member1 member2 [unit]  

# 计算经纬度
geohash key member [member ...]

# 举例
GEOADD locations 116.419217 39.921133 beijing
GEOPOS locations beijing
GEODIST locations beijing tianjin km &#x2F;&#x2F;算计举例
GEORADIUSBYMEMBER locations beijing 150km &#x2F;&#x2F;通过举例计算城市
注意：没有删除命令，他的本质是zset（type locations）所以可以使用zrem key member<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1>第 8 章 redis 高可用</h1>
<p>先说下演变过程：</p>
<ul>
<li>单机版</li>
<li>主从复制：复制是高可用 redis 的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份，以及对读操作的负载均衡和简单的故障恢复。缺陷是故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制。</li>
<li>哨兵：在复制的基础上，哨兵实现了自动化的故障恢复，实现主从切换。缺陷是写操作无法负载均衡；存储能力受到单机的限制</li>
<li>集群：解决了写操作无法负载均衡，以及存储能力受到单击限制的问题，实现了较为完善的高可用方案</li>
</ul>
<h2 id="8-1-主从复制"><a class="header-anchor" href="#8-1-主从复制">¶</a>8.1 主从复制</h2>
<p>主从复制：即将 master 中的数据即时、有效的复制到 slave 中</p>
<p>特征：一个 master 可以拥有多个 slave，一个 slave 只对应一个 master。Master 以写为主，Slave 以读为主。</p>
<p>master 和 slave 是个相对的概念，下面的 slave 还可以当做下一级的 master</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/6527560fd25546dba0b3549f134d63ee.png" alt="" loading="lazy"></p>
<p>职责：</p>
<ul>
<li>master:<br>
 写数据<br>
 执行写操作时，将出现变化的数据自动同步到 slave<br>
 读数据（可忽略）</li>
<li>slave:<br>
 读数据<br>
 写数据（禁止）</li>
</ul>
<p>在 <strong>Redis</strong> 中，用户可以通过执行 <code>SLAVEOF</code> 命令或者设置 <code>slaveof</code> 选项，让一个服务器去复制另一个服务器，成为从服务器，以下三种方式是 <strong>完全等效</strong> 的：</p>
<ul>
<li><strong>配置文件</strong>：在从服务器的配置文件中加入：<code>slaveof &lt;masterip&gt; &lt;masterport&gt;</code></li>
<li><strong>启动命令</strong>：redis-server 启动命令后加入 <code>--slaveof &lt;masterip&gt; &lt;masterport&gt;</code></li>
<li><strong>客户端命令</strong>：Redis 服务器启动后，直接通过客户端执行命令：<code>slaveof &lt;masterip&gt; &lt;masterport&gt;</code>，让该 Redis 实例成为从节点。</li>
</ul>
<p>需要注意的是：<strong>主从复制的开启，完全是在从节点发起的，不需要我们在主节点做任何事情。</strong></p>
<p>在 master 端配置：</p>
<pre class="line-numbers language-none"><code class="language-none"># -----master授权slave访问-------
 master客户端发送命令设置密码&#96;requirepass &lt;password&gt;&#96;
 master配置文件设置密码
&#96;config set requirepass &lt;password&gt;&#96;
&#96;config get requirepass&#96;

 slave客户端发送命令设置密码 &#96;auth &lt;password&gt;&#96;
 slave配置文件设置密码 &#96;masterauth &lt;password&gt;&#96;
 slave启动服务器设置密  &#96;redis-server –a &lt;password&gt;&#96;

# ----------主从断开连接-----------
 客户端发送命令：&#96;slaveof no one &#96;
## 说明：slave断开连接后，不会删除已有数据，只是不再接受master发送的数据<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="https://img-blog.csdnimg.cn/img_convert/acc8264643d23e1a6fef6b3d7c52190b.png" alt="" loading="lazy"></p>
<h3 id="8-2-主从复制的目的"><a class="header-anchor" href="#8-2-主从复制的目的">¶</a>8.2 主从复制的目的</h3>
<p>主从复制的作用：</p>
<ul>
<li>读写分离： master 写、 slave 读，提高服务器的读写负载能力</li>
<li>负载均衡： 基于主从结构，配合读写分离，由 slave 分担 master 负载，并根据需求的变化，改变 slave 的数量，通过多个从节点分担数据读取负载，大大提高 Redis 服务器并发量与数据吞吐量</li>
<li>故障恢复：当 master 出现问题时，由 slave 提供服务，实现快速的故障恢复</li>
<li>数据冗余：实现数据热备份，是持久化之外的一种数据冗余方式</li>
<li>高可用基石： 基于主从复制，构建哨兵模式与集群，实现 Redis 的高可用方案</li>
</ul>
<h3 id="8-3-主从配置原理"><a class="header-anchor" href="#8-3-主从配置原理">¶</a>8.3 主从配置原理</h3>
<p>主从复制过程大体可以分为 3 个阶段</p>
<ul>
<li>1 建立连接阶段（设置通道）</li>
<li>2 数据同步阶段（RDB 全量复制）</li>
<li>3 命令传播阶段（）</li>
</ul>
<p><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422160534.png" alt="" loading="lazy"></p>
<h3 id="阶段一：建立连接阶段"><a class="header-anchor" href="#阶段一：建立连接阶段">¶</a>阶段一：建立连接阶段</h3>
<p> 建立 slave 到 master 的连接，使 master 能够识别 slave， 并保存 slave 端口号</p>
<p><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422160736.png" alt="" loading="lazy"></p>
<ul>
<li>步骤 1：在 slave 端设置 master 的 IP 和端口，</li>
<li>步骤 2：建立 socket 连接，以后通过这个通道传数据，以后 slave 会自动周期性发送 ping 命令（定时器任务）到 master，验证 master 还在不在。master 返回 pong 说明通道还在</li>
<li>步骤 3：master 查看配置中是否允许 slave 连接，进行身份验证。同时 master 也记录了 slave 的 IP 和端口</li>
<li>步骤 4：master 发送授权通过信息给 slave，建立了通道</li>
</ul>
<h3 id="阶段二：同步阶段"><a class="header-anchor" href="#阶段二：同步阶段">¶</a>阶段二：同步阶段</h3>
<p>思想：在 slave 初次连接 master 后，复制 master 中的所有数据到 slave，将 slave 的数据库状态更新成 master 当前的数据库状态 。复制完以后再同步数据只复制更改的部分就行了。</p>
<p>数据同步阶段工作流程：<br>
步骤 1： slave 发送<code>psync2</code>命令请求同步数据<br>
步骤 2： 创建 RDB 同步数据<br>
步骤 3： slave 拿到 master 发来的 RDB 文件后，删除原来 slave 里的 RDB 文件，执行文件恢复过程。恢复好后 slave 就保存了 master 刚才时刻的 RDB。然后通知 master 恢复好了。</p>
<p>这时就完成了开机后的工作，接下来的命令增量的同步工作叫命令传播阶段。</p>
<p><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422161130.png" alt="" loading="lazy"></p>
<p>注意：上面的缓冲区只在部分复制时才起作用，他里面是 AOF 指令，而不是数据快照。</p>
<p>master 说明：</p>
<ul>
<li>\1. 如果 master 数据量巨大，数据同步阶段应避开流量高峰期，避免造成 master 阻塞，影响业务正常执行</li>
<li>\2. 缓存区设置：复制缓冲区大小设定不合理，会导致数据溢出，后进的指令会冲掉先进的指令。如进行全量复制周期太长，进行部分复制时又出现数据已经存在丢失的情况，必须进行第二次全量复制，致使 slave 陷入死循环状态。在 master 端更改：<code>repl-backlog-size 1mb</code></li>
<li>\3. master 单机内存占用主机内存的比例不应过大，建议使用 50%-70% 的内存，留下 30%-50% 的内存用于执<br>
行 bgsave 命令和创建复制缓冲区</li>
</ul>
<p>slave 说明：</p>
<ul>
<li>\1. 为避免 slave 进行全量复制、部分复制时服务器响应阻塞或数据不同步，建议关闭此期间的对外服务<code>slave-serve-stale-data yes|no</code></li>
<li>\2. 数据同步阶段， master 发送给 slave 信息可以理解 master 是 slave 的一个客户端，主动向 slave 发送命令</li>
<li>\3. 多个 slave 同时对 master 请求数据同步， master 发送的 RDB 文件增多， 会对带宽造成巨大冲击， 如果 master 带宽不足， 因此数据同步需要根据业务需求， 适量错峰</li>
<li>\4. slave 过多时， 建议调整拓扑结构，由一主多从结构变为树状结构， 中间的节点既是 master，也是 slave。注意使用树状结构时，由于层级深度，导致深度越高的 slave 与最顶层 master 间数据同步延迟较大， 数据一致性变差， 应谨慎选择</li>
</ul>
<h3 id="阶段三：命令传播阶段"><a class="header-anchor" href="#阶段三：命令传播阶段">¶</a>阶段三：命令传播阶段</h3>
<p> 当 master 数据库状态被修改后，导致主从服务器数据库状态不一致，此时需要让主从数据同步到一致的状态，同步的动作称为命令传播。</p>
<p>数据库的状态信息是通过复制缓冲区实现的。</p>
<p><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422161130.png" alt="" loading="lazy"></p>
<p>命令传播阶段出现了断网现象<br>
 网络闪断闪连 忽略<br>
 短时间网络中断 部分复制<br>
 长时间网络中断 全量复制</p>
<p>部分复制的三个核心要素</p>
<ul>
<li>服务器的运行 id（ run id）</li>
<li>主服务器的复制积压缓冲区</li>
<li>主从服务器的复制偏移量 offset</li>
</ul>
<p>服务器运行 ID（ runid）：</p>
<ul>
<li> 概念：服务器运行 ID 是每一台服务器每次运行的身份识别码，一台服务器多次运行可以生成多个运行 id。每个计算机也有自己的运行 ID，slave 也有。运行 id 由 40 位字符组成，是一个随机的十六进制字符，如<code>fdc9ff13b9bbaab28db42b3d50f852bb5e3fcdce</code></li>
<li>作用：运行 id 被用于在服务器间进行传输，识别身份<br>
如果想两次操作均对同一台服务器进行，必须每次操作携带对应的运行 id，用于对方识别。master 发送 ID，slave 比对 ID，</li>
<li>实现方式： 运行 id 在每台服务器启动时自动生成的， master 在首次连接 slave 时，会将自己的运行 ID 发<br>
送给 slave， slave 保存此 ID，通过 info Server 命令，可以查看节点的 runid</li>
</ul>
<h4 id="复制缓冲区"><a class="header-anchor" href="#复制缓冲区">¶</a>复制缓冲区</h4>
<p>复制缓冲区是一个先进先出 FIFO 队列，master 先把命令信息放到复制缓冲区，不是放整个命令，而是放入 <strong>AOF 日志</strong>文件里的 $3 \r \n,set 等。此时将缓冲区分格，每个格放一个字符。有个类似数组索引的 &quot; <strong>偏移量</strong> &quot; 识别当前 slave 执行到哪里了。所以不同 slave 的偏移量是不一样的。</p>
<blockquote>
<p> 缓冲区大小建议设置如下：<br>
\1. 测算从 master 到 slave 的重连平均时长 second<br>
\2. 获取 master 平均每秒产生写命令数据总量 write_size_per_second<br>
\3. 最优复制缓冲区空间 = 2 * second * write_size_per_second</p>
</blockquote>
<p>复制缓冲区：</p>
<ul>
<li>复制缓冲区默认数据存储空间大小是 1M，由于存储空间大小是固定的，当入队元素的数量大于队列长度时，最先入队的元素会被弹出，而新元素会被放入队列</li>
<li>master 有一个缓冲区，但有多个 offset。</li>
<li>当 master 接收到主客户端的指令时，除了将指令执行，会将该指令存储到缓冲区中</li>
<li>slave 请求部分同步时，会把 slave 的 offset(slave) 发送过来，master 是看 slave 发送过来的 offset(slave) 还在不在我们的缓冲区中，如果已经被挤出去，那么就触发<strong>全局复制</strong>。如果 offset(slave) 在 master 还没挤出去，就把还记录的部分再发给 slave，同时发送给 slave 新的 offset</li>
</ul>
<p>offset 偏移量：</p>
<ul>
<li>通过 offset 区分不同的 slave 当前数据传播的差异，offset 是复制偏移量，描述复制缓冲区中的指令字节位置
<ul>
<li>master 复制偏移量：master 记录已发送的信息对应的 offset（多个），发送一次记录一次</li>
<li>slave 复制偏移量：slave 记录已接收的信息对应的 offset（一个），接收一次记录一次</li>
</ul>
</li>
</ul>
<p><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422161507.png" alt="" loading="lazy"></p>
<p><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422161553.png" alt="" loading="lazy"></p>
<p><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422161821.png" alt="" loading="lazy"></p>
<p>下面的序号是执行的顺序</p>
<p><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422161652.png" alt="" loading="lazy"></p>
<h4 id="数据同步总结"><a class="header-anchor" href="#数据同步总结">¶</a>数据同步总结</h4>
<p>master 发过来的为红的 offset，slave 记下来的为蓝的 offset。</p>
<p>如果 ID 不匹配。那么就触发全部复制。或者 slave 传过来的 offset 没了（在 master 里找不到这个偏移量了，被队列挤出去了），那么就触发全量复制。</p>
<p>现象：网络环境不佳，出现网络中断， slave 不提供服务</p>
<p>原因：复制缓冲区过小，断网后 slave 的 offset 越界，频繁触发全量复制</p>
<p>解决：修改复制缓冲区大小<code>repl-backlog-size</code>。</p>
<h3 id="心跳机制"><a class="header-anchor" href="#心跳机制">¶</a>心跳机制</h3>
<p>心跳机制：<strong>进入命令传播阶段候， master 与 slave 间需要进行信息交换，使用心跳机制进行维护，实现双方连接保持在线</strong></p>
<p>master 心跳：</p>
<ul>
<li>指令： <code>PING</code></li>
<li>周期：由 repl-ping-slave-period 决定，默认 10 秒</li>
<li>作用：判断 slave 是否在线</li>
<li>查询： INFO replication 获取 slave 最后一次连接时间间隔， lag 项维持在 0 或 1 视为正常</li>
</ul>
<p>slave 心跳任务</p>
<ul>
<li>指令： <code>REPLCONF ACK &#123;offset&#125;</code></li>
<li>周期： 1 秒</li>
<li>作用 1：<strong>汇报 slave 自己的复制偏移量</strong>，获取最新的数据变更指令</li>
<li>作用 2：判断 master 是否在线</li>
</ul>
<p>心跳设置：</p>
<pre class="line-numbers language-none"><code class="language-none">问题现象：slave与master连接断开
问题原因
 master发送ping指令频度较低：提高ping指令发送的频度：repl-ping-slave-period
 master设定超时时间较短：超时时间repl-time的时间至少是ping指令频度的5到10倍，否则slave很容易判定超时 
 ping指令在网络中存在丢包<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>心跳阶段注意事项</p>
<p> 当 slave 多数掉线，或延迟过高时， master 为保障数据稳定性，将拒绝所有信息同步操作。都掉了就没有同步的意义了。或者同步完成时间太久了</p>
<pre class="line-numbers language-none"><code class="language-none">min-slaves-to-write 2 # 少于2时就不再写了
min-slaves-max-lag 8  # 链接延迟，在info里可以看到<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>slave 数量少于 2 个，或者所有 slave 的延迟都大于等于 10 秒时，强制关闭 master 写功能，停止数据同步<br>
 slave 数量由 slave 发送 REPLCONF ACK 命令做确认<br>
 slave 延迟由 slave 发送 REPLCONF ACK 命令做确认</p>
<p>PING 的设置会影响网络，可能会引起网络中断。</p>
<h3 id="主从复制常见问题"><a class="header-anchor" href="#主从复制常见问题">¶</a>主从复制常见问题</h3>
<p>这个地方还没看视频</p>
<h4 id="频繁的全量复制（-1）"><a class="header-anchor" href="#频繁的全量复制（-1）">¶</a>频繁的全量复制（ 1）</h4>
<p>伴随着系统的运行， master 的数据量会越来越大，一旦 master 重启， runid 将发生变化，会导致全部 slave 的全量复制操作</p>
<p>内部优化调整方案：<br>
\1. master 内部创建 master_replid 变量，使用 runid 相同的策略生成，长度 41 位，并发送给所有 slave<br>
\2. 在 master 关闭时执行命令 shutdown save，进行 RDB 持久化, 将 runid 与 offset 保存到 RDB 文件中<br>
 repl-id repl-offset<br>
 通过 redis-check-rdb 命令可以查看该信息<br>
\3. master 重启后加载 RDB 文件， 恢复数据<br>
重启后，将 RDB 文件中保存的 repl-id 与 repl-offset 加载到内存中<br>
 master_repl_id = repl master_repl_offset = repl-offset<br>
 通过 info 命令可以查看该信息<br>
作用：<br>
本机保存上次 runid，重启后恢复该值，使所有 slave 认为还是之前的 master</p>
<h4 id="频繁的网络中断（-1）"><a class="header-anchor" href="#频繁的网络中断（-1）">¶</a>频繁的网络中断（ 1）</h4>
<p> 问题现象<br>
 master 的 CPU 占用过高 或 slave 频繁断开连接<br>
 问题原因<br>
 slave 每 1 秒发送 REPLCONF ACK 命令到 master<br>
 当 slave 接到了慢查询时（ keys * ， hgetall 等），会大量占用 CPU 性能<br>
 master 每 1 秒调用复制定时函数 replicationCron()，比对 slave 发现长时间没有进行响应<br>
 最终结果<br>
 master 各种资源（输出缓冲区、带宽、连接等） 被严重占用<br>
 解决方案<br>
 通过设置合理的超时时间，确认是否释放 slave：repl-timeout</p>
<p>该参数定义了超时时间的阈值（默认 60 秒），超过该值，释放 slave</p>
<h4 id="数据不一致"><a class="header-anchor" href="#数据不一致">¶</a>数据不一致</h4>
<p> 问题现象<br>
 多个 slave 获取相同数据不同步<br>
 问题原因<br>
 网络信息不同步，数据发送有延迟<br>
 解决方案<br>
 优化主从间的网络环境，通常放置在同一个机房部署，如使用阿里云等云服务器时要注意此现象<br>
 监控主从节点延迟（通过 offset）判断，如果 slave 延迟过大，暂时屏蔽程序对该 slave 的数据访问：slave-serve-stale-data yes|no<br>
开启后仅响应 info、 slaveof 等少数命令（慎用，除非对数据一致性要求很高）</p>
<p>可以在 redis 里输入 <code>info application</code>查看当前 redis 的主从状态</p>
<h2 id="8-2-哨兵与选举"><a class="header-anchor" href="#8-2-哨兵与选举">¶</a>8.2 哨兵与选举</h2>
<p>哨兵 (sentinel) ：是一个分布式系统，用于对主从结构中的每台服务器进行监控，当 master 出现故障时通过投票机制从 slave 中选择新的 master 并将所有 slave 连接到新的 master。</p>
<p><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422162213.png" alt="" loading="lazy"></p>
<p>哨兵的作用</p>
<ul>
<li>监控：
<ul>
<li>不断的检查 master 和 slave 是否正常运行。</li>
<li>master 存活检测、 master 与 slave 运行情况检测</li>
</ul>
</li>
<li>通知（提醒）
<ul>
<li>当被监控的服务器出现问题时， 向其他（哨兵间，客户端） 发送通知。</li>
</ul>
</li>
<li>自动故障转移
<ul>
<li>断开 master 与 slave 连接，选举一个 slave 作为 master，将其他 slave 连接到新的 master，并告知客户端新的服务器地址</li>
</ul>
</li>
</ul>
<p>注意：哨兵也是一台 redis 服务器，只是不提供数据服务。通常哨兵配置数量为单数</p>
<p>哨兵会改变 conf 文件内容，删除与新增 slaveof。应用程序知道哨兵地址就可以了</p>
<p>哨兵 2 挂了后，剩下两个选 id 大的</p>
<h3 id="配置哨兵"><a class="header-anchor" href="#配置哨兵">¶</a>配置哨兵</h3>
<p> 配置一拖二的主从结构</p>
<p> 配置三个哨兵（配置相同，端口不同）</p>
<p>步骤：</p>
<ul>
<li>写好哨兵的配置文件：指定监听的 redis（只监听主节点）</li>
<li>启动哨兵：redis-sentinel /myredis/sentinel.conf</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none"># 在每个哨兵配置文件中修改

# redis-sentinel-1.conf------------------
port 26379
daemonize yes
logfile &quot;26379.log&quot;
sentinel monitor mymaster 127.0.0.1 6379 2
# 监控127.0.0.1 6379这个主节点， # 只监听主节点
# 该主节点名称是mymaster。
# 2个哨兵同意才能判定主节点故障并进行故障转移。 #哨兵数量&#x2F;2+1

# redis-sentinel-2.conf------------------
port 26380
daemonize yes
logfile &quot;26380.log&quot;
sentinel monitor mymaster 127.0.0.1 6379 2

# redis-sentinel-3.conf------------------
port 26381
daemonize yes
logfile &quot;26381.log&quot;
sentinel monitor mymaster 127.0.0.1 6379 2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-none"><code class="language-none">entinel down-after-milliseconds master01 30000 #30000ms表示认为主节点挂了的超时时间
sentinel parallel-syncs master01 1 #表示切换主从节点时同时有多少个从节点进行复制
sentinel failover-timeout master01 180000  #表示切换主从节点超时时间<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p> 启动哨兵</p>
<pre class="line-numbers language-none"><code class="language-none">redis-server &#x2F;usr&#x2F;local&#x2F;redis-5.0.3&#x2F;redis-sentinel-1.conf --sentinel
redis-server &#x2F;usr&#x2F;local&#x2F;redis-5.0.3&#x2F;redis-sentinel-2.conf --sentinel
redis-server &#x2F;usr&#x2F;local&#x2F;redis-5.0.3&#x2F;redis-sentinel-3.conf --sentinel<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>启动顺序：先启动主机，再启动从机，再启动哨兵</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/35dc7fcf139eee595512c737ba6dc36b.png" alt="" loading="lazy"></p>
<table><thead><tr><th>配置项</th><th>范例</th><th>说明</th></tr></thead><tbody><tr><td><code>sentinel auth-pass &lt;服务器名称&gt; &lt;password&gt;</code></td><td>sentinel auth-pass mymaster itcast</td><td>连接服务器口令</td></tr><tr><td><code>sentinel down-after-milliseconds &lt;自定义服 务名称&gt;&lt;主机地址&gt;&lt;端口&gt;&lt;主从服务器总量&gt;</code></td><td>sentinel monitor mymaster 192.168.194.131 6381 1</td><td>设置哨兵监听的主服务器信息，最后的参数决定了最终参与选举的服务器 数量（ -1）</td></tr><tr><td><code>sentinel down-after-milliseconds &lt;服务名称&gt;&lt;毫秒数（整数） &gt;</code></td><td>sentinel down-after milliseconds mymaster 3000</td><td>指定哨兵在监控 Redis 服务时，判定服务器挂掉的时间周期，默认 30 秒 （ 30000），也是主从切换的启动条件之一</td></tr><tr><td>sentinel parallel-syncs &lt;服务名称&gt;&lt; 服务器数（整数） &gt;</td><td>sentinel parallel-syncs mymaster 1</td><td>指定同时进行主从的 slave 数量，数值越大，要求网络资源越高，要求约 小，同步时间约长</td></tr><tr><td>sentinel failover-timeout &lt;服务名称&gt;&lt; 毫秒数（整数） &gt;</td><td>sentinel failover-timeout mymaster 9000</td><td>指定出现故障后，故障切换的最大超时时间，超过该值，认定切换失败， 默认 3 分钟</td></tr><tr><td>sentinel notification-script &lt;服务名称&gt;&lt; 脚本路径 &gt;</td><td></td><td>服务器无法正常联通时，设定的执行脚本，通常调试使用。</td></tr></tbody></table>
<p>查看状态</p>
<pre class="line-numbers language-none"><code class="language-none"># 连接端口为 26379 的 Redis 节点
➜  ~ redis-cli -p 26379
127.0.0.1:26379&gt; info Sentinel
# Sentinel
sentinel_masters:1
sentinel_tilt:0
sentinel_running_scripts:0
sentinel_scripts_queue_length:0
sentinel_simulate_failure_flags:0
master0:name&#x3D;mymaster,status&#x3D;ok,address&#x3D;127.0.0.1:6379,slaves&#x3D;2,sentinels&#x3D;3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>哨兵也是一台 redis 服务器，只是不提供数据服务。通常哨兵配置数量为单数</p>
<pre class="line-numbers language-none"><code class="language-none">@Test
public void sentinel()&#123;
    Set&lt;String&gt; sentinels&#x3D;new HashSet&lt;String&gt;();
    sentinels.add(&quot;192.168.58.145:26379&quot;);
    sentinels.add(&quot;192.168.58.145:26380&quot;);
    sentinels.add(&quot;192.168.58.145:26381&quot;);
    GenericObjectPoolConfig poolConfig &#x3D; new GenericObjectPoolConfig();
    JedisSentinelPool jedisSentinelPool &#x3D; new JedisSentinelPool(&quot;master01&quot;,sentinels,poolConfig);
    Jedis jedis&#x3D;null;
    try&#123;
        jedis&#x3D;jedisSentinelPool.getResource();
        jedis.set(&quot;hello&quot;, &quot;world&quot;);
        System.out.println(jedis.get(&quot;hello&quot;));
    &#125;catch (Exception e) &#123;
        e.printStackTrace();
    &#125;finally&#123;
        jedis.close();
    &#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="https://img-blog.csdnimg.cn/20190220172520981.png" alt="" loading="lazy"><img src="https://img-blog.csdnimg.cn/img_convert/eccb7f3c010bf908238f62652447fcc2.png" alt="" loading="lazy"></p>
<h3 id="哨兵工作原理："><a class="header-anchor" href="#哨兵工作原理：">¶</a>哨兵工作原理：</h3>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/bingshu/p/9776610.html">https://www.cnblogs.com/bingshu/p/9776610.html</a></p>
<h4 id="主从切换"><a class="header-anchor" href="#主从切换">¶</a>主从切换</h4>
<p>哨兵在进行主从切换过程中经历三个阶段<br>
 监控<br>
 通知<br>
 故障转移</p>
<h5 id="阶段一：监控阶段"><a class="header-anchor" href="#阶段一：监控阶段">¶</a>阶段一：监控阶段</h5>
<p>哨兵里只配置了主节点的信息，哨兵要通过主节点拿到别的哨兵的信息</p>
<p>获取 master 的信息，从而获取到 slave 的信息</p>
<p>主节点</p>
<ul>
<li>runid</li>
<li>role</li>
</ul>
<p>从节点</p>
<ul>
<li>runid</li>
<li>role</li>
<li>master-host,master-port</li>
<li>offset</li>
</ul>
<p>流程：</p>
<ul>
<li>哨兵 1 向 master 发送 info，然后建立了一个 cmd 连接（创建 <code>cmd</code> 和 <code>pub/sub</code> 两个 <strong>连接</strong>。<code>Sentinel</code> 通过 <code>cmd</code> 连接给 <code>Redis</code> 发送命令，通过 <code>pub/sub</code> 连接到 <code>Redis</code> 实例上的其他 <code>Sentinel</code> 实例。），</li>
<li>哨兵 1 拿到了 master、slaves、sentiels，主节点拿到了 master、slaves、sentiels</li>
<li>哨兵 1 根据拿到的 slaves 信息去连每个 slaves</li>
<li><code>-----------</code></li>
<li>哨兵 2 连接 master，看到有 master 里有哨兵 1，哨兵 2 就拿到了哨兵 1 的信息，去连接哨兵 1（哨兵 1 和哨兵 2 互相发布订阅），哨兵 1 和哨兵 2 同步了</li>
<li>哨兵 3 连接 master，看到有哨兵 1 和 2，于是各个哨兵互联</li>
<li>总结：哨兵会向 master、slave 和其他哨兵获取状态。哨兵间会组件网络同步信息。</li>
</ul>
<p><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422162527.png" alt="" loading="lazy"><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422162610.png" alt="" loading="lazy"></p>
<h5 id="阶段二：通知阶段"><a class="header-anchor" href="#阶段二：通知阶段">¶</a>阶段二：通知阶段</h5>
<ul>
<li>主哨兵 1 去问 master 和 slave 的状态，然后哨兵 1 把状态告诉哨兵 2 和 3</li>
<li>过了一会可能是哨兵 2 做了上面工作然后告诉其他哨兵</li>
</ul>
<p><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422162630.png" alt="" loading="lazy"></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/11ac3d82eb2546eeef704de6a710e62f.png" alt="" loading="lazy"></p>
<h5 id="阶段三：故障转移阶段"><a class="header-anchor" href="#阶段三：故障转移阶段">¶</a>阶段三：故障转移阶段</h5>
<p>哨兵 1 给 master 发 hello 发现没人理，就判断为 master 宕机，告诉其他哨兵，其他哨兵也验证一下挂没挂（半数以上就可以，前面配置的），于是选举新 master</p>
<ul>
<li>主观下线代表只有一台哨兵认为挂了 Sdown；客观下线代表半数哨兵都认为 master 挂了 Odown
<ul>
<li><strong>主观下线</strong> 适用于所有 <strong>主节点</strong> 和 <strong>从节点</strong>。如果在 <code>down-after-milliseconds</code> 毫秒内，<code>Sentinel</code> 没有收到 <strong>目标节点</strong> 的有效回复，则会判定 <strong>该节点</strong> 为 <strong>主观下线</strong>。</li>
<li><strong>客观下线</strong> 只适用于 <strong>主节点</strong>。如果 <strong>主节点</strong> 出现故障，<code>Sentinel</code> 节点会通过 <code>sentinel is-master-down-by-addr</code> 命令，向其它 <code>Sentinel</code> 节点询问对该节点的 <strong>状态判断</strong>。如果超过 <code>&lt;quorum&gt;</code> 个数的节点判定 <strong>主节点</strong> 不可达，则该 <code>Sentinel</code> 节点会判断 <strong>主节点</strong> 为 <strong>客观下线</strong>。</li>
</ul>
</li>
<li>投票机制先选举哪个哨兵负责去处理选举新 master 的任务。3 个哨兵同时投票自己（还会带自己的竞选次数），哨兵先收到谁的投票就把票投给谁，从而得到哨兵领导</li>
<li>哨兵领导去看哪个 slave 适合当 master
<ul>
<li>找在线的</li>
<li>pass 响应慢的</li>
<li>pass 与 master 断开时间久的</li>
<li>优先级：offset、runid</li>
</ul>
</li>
<li>通知被选上的 slave 当 master，通知其他 slave 新 master</li>
</ul>
<p><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422162714.png" alt="" loading="lazy"></p>
<p><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422162737.png" alt="" loading="lazy"></p>
<p>应用程序连哨兵，哨兵知道当前谁是主节点。</p>
<h3 id="Redis-Sentinel-的工作原理"><a class="header-anchor" href="#Redis-Sentinel-的工作原理">¶</a>Redis Sentinel 的工作原理</h3>
<p>每个 <code>Sentinel</code> 节点都需要 <strong>定期执行</strong> 以下任务：</p>
<ul>
<li>每个 <code>Sentinel</code> 以 <strong>每秒钟</strong> 一次的频率，向它所知的 <strong>主服务器</strong>、<strong>从服务器</strong> 以及其他 <code>Sentinel</code> <strong>实例</strong> 发送一个 <code>PING</code> 命令。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/img_convert/11ac3d82eb2546eeef704de6a710e62f.png" alt="" loading="lazy"></p>
<p>如果一个 <strong>实例</strong>（<code>instance</code>）距离 <strong>最后一次</strong> 有效回复 <code>PING</code> 命令的时间超过 <code>down-after-milliseconds</code> 所指定的值，那么这个实例会被 <code>Sentinel</code> 标记为 <strong>主观下线</strong>。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/ab9589e7e14243ab78c6d3d775b69ec3.png" alt="" loading="lazy"></p>
<p>如果一个 <strong>主服务器</strong> 被标记为 <strong>主观下线</strong>，那么正在 <strong>监视</strong> 这个 <strong>主服务器</strong> 的<strong>所有</strong><code>Sentinel</code> 节点，要以 <strong>每秒一次</strong> 的频率确认 <strong>主服务器</strong> 的确进入了 <strong>主观下线</strong> 状态。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/8b5906159669c7674479438af96cc009.png" alt="" loading="lazy"></p>
<p>如果一个 <strong>主服务器</strong> 被标记为 <strong>主观下线</strong>，并且有 <strong>足够数量</strong> 的 <code>Sentinel</code>（至少要达到 <strong>配置文件</strong> 指定的数量）在指定的 <strong>时间范围</strong> 内同意这一判断，那么这个 <strong>主服务器</strong> 被标记为 <strong>客观下线</strong>。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/9fd9e96c23836fb226ca3e97ed1e662e.png" alt="" loading="lazy"></p>
<p>在一般情况下， 每个 <code>Sentinel</code> 会以每 <code>10</code> 秒一次的频率，向它已知的所有 <strong>主服务器</strong> 和 <strong>从服务器</strong> 发送 <code>INFO</code> 命令。当一个 <strong>主服务器</strong> 被 <code>Sentinel</code> 标记为 <strong>客观下线</strong> 时，<code>Sentinel</code> 向 <strong>下线主服务器</strong> 的所有 <strong>从服务器</strong> 发送 <code>INFO</code> 命令的频率，会从 <code>10</code> 秒一次改为 <strong>每秒一次</strong>。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/7b4812d3f57c4fc213bdc2cd0961fe41.png" alt="" loading="lazy"></p>
<p><code>Sentinel</code> 和其他 <code>Sentinel</code> 协商 <strong>主节点</strong> 的状态，如果 <strong>主节点</strong> 处于 <code>SDOWN</code> 状态，则投票自动选出新的 <strong>主节点</strong>。将剩余的 <strong>从节点</strong> 指向 <strong>新的主节点</strong> 进行 <strong>数据复制</strong>。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/a25dfe621de03eb74b60bb513aa6f197.png" alt="" loading="lazy"></p>
<p>当没有足够数量的 <code>Sentinel</code> 同意 <strong>主服务器</strong> 下线时， <strong>主服务器</strong> 的 <strong>客观下线状态</strong> 就会被移除。当 <strong>主服务器</strong> 重新向 <code>Sentinel</code> 的 <code>PING</code> 命令返回 <strong>有效回复</strong> 时，<strong>主服务器</strong> 的 <strong>主观下线状态</strong> 就会被移除。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/28dac937400b802eefc161634892e7ab.png" alt="" loading="lazy"></p>
<blockquote>
<p>注意：一个有效的 <code>PING</code> 回复可以是：<code>+PONG</code>、<code>-LOADING</code> 或者 <code>-MASTERDOWN</code>。如果 <strong>服务器</strong> 返回除以上三种回复之外的其他回复，又或者在 <strong>指定时间</strong> 内没有回复 <code>PING</code> 命令， 那么 <code>Sentinel</code> 认为服务器返回的回复 <strong>无效</strong>（<code>non-valid</code>）。</p>
</blockquote>
<h2 id="8-3-Redis-集群"><a class="header-anchor" href="#8-3-Redis-集群">¶</a>8.3 Redis 集群</h2>
<p>要解决的问题：</p>
<ul>
<li>并发写</li>
<li>扩容</li>
</ul>
<p>集群好处：</p>
<ul>
<li>Redis 集群实现了对 Redis 的水平扩容，即启动 N 个 redis 节点，将整个数据库分布存储在这 N 个节点中，每个节点存储总数据的 1/N。</li>
<li>Redis 集群通过分区（partition）来提供一定程度的可用性（availability）： 即使集群中有一部分节点失效或者无法进行通讯， 集群也可以继续处理命令请求</li>
<li><strong>数据分区：</strong> 数据分区 <em>(或称数据分片)</em> 是集群最核心的功能。集群将数据分散到多个节点，<strong>一方面</strong> 突破了 Redis 单机内存大小的限制，<strong>存储容量大大增加</strong>；<strong>另一方面</strong> 每个主节点都可以对外提供读服务和写服务，<strong>大大提高了集群的响应能力</strong>。Redis 单机内存大小受限问题，在介绍持久化和主从复制时都有提及，例如，如果单机内存太大，<code>bgsave</code> 和 <code>bgrewriteaof</code> 的 <code>fork</code> 操作可能导致主进程阻塞，主从环境下主机切换时可能导致从节点长时间无法提供服务，全量复制阶段主节点的复制缓冲区可能溢出……</li>
<li><strong>高可用：</strong> 集群支持主从复制和主节点的 <strong>自动故障转移</strong> <em>（与哨兵类似）</em>，当任一节点发生故障时，集群仍然可以对外提供服务。</li>
</ul>
<p>0-16383 共 16384 个槽位</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7896890-516eb4a9465451a6.png" alt="" loading="lazy"></p>
<p><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200908141231.png" alt="" loading="lazy"></p>
<p>上图 展示了 <strong>Redis Cluster</strong> 典型的架构图，集群中的每一个 Redis 节点都 <strong>互相两两相连</strong>，客户端任意 <strong>直连</strong> 到集群中的 <strong>任意一台</strong>，就可以对其他 Redis 节点进行 <strong>读写</strong> 的操作。</p>
<h3 id="基本原理"><a class="header-anchor" href="#基本原理">¶</a>基本原理</h3>
<p><img src="https://upload-images.jianshu.io/upload_images/7896890-f65c71ca6811c634.png" alt="" loading="lazy"></p>
<p>Redis 集群中内置了 <code>16384</code> 个哈希槽。当客户端连接到 Redis 集群之后，会同时得到一份关于这个 <strong>集群的配置信息</strong>，当客户端具体对某一个 <code>key</code> 值进行操作时，会计算出它的一个 Hash 值，然后把结果对 <code>16384</code> <strong>求余数</strong>，这样每个 <code>key</code> 都会对应一个编号在 <code>0-16383</code> 之间的哈希槽，Redis 会根据节点数量 <strong>大致均等</strong> 的将哈希槽映射到不同的节点。</p>
<p>再结合集群的配置信息就能够知道这个 <code>key</code> 值应该存储在哪一个具体的 Redis 节点中，如果不属于自己管，那么就会使用一个特殊的 <code>MOVED</code> 命令来进行一个跳转，告诉客户端去连接这个节点以获取数据：</p>
<pre class="line-numbers language-none"><code class="language-none">GET x
-MOVED 3999 127.0.0.1:6381<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p><code>MOVED</code> 指令第一个参数 <code>3999</code> 是 <code>key</code> 对应的槽位编号，后面是目标节点地址，<code>MOVED</code> 命令前面有一个减号，表示这是一个错误的消息。客户端在收到 <code>MOVED</code> 指令后，就立即纠正本地的 <strong>槽位映射表</strong>，那么下一次再访问 <code>key</code> 时就能够到正确的地方去获取了。</p>
<p>数据存储设计</p>
<p>这个 key 存到哪个 redis 存储空间：</p>
<p> 通过 CRC16 算法设计，计算出 key 应该保存的位置<br>
 将所有的存储空间计划切割成 16384 份，每台主机保存一部分<br>
每份代表的是一个存储空间，不是一个 key 的保存空间<br>
 将 key 按照计算出的结果，然后 (%16384)，比如得到 37，放到对应的 37 存储空间</p>
<p><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422185737.png" alt="" loading="lazy"></p>
<p>那如何加入一台新的计算机，怎么重新划分？每个原来的 redis 拿出一部分存到新的 redis 上。即改变槽的位置。</p>
<p><img src="https://fermhan.oss-cn-qingdao.aliyuncs.com/img/20200422185954.png" alt="" loading="lazy"></p>
<p>怎么知道槽新地址？</p>
<p>集群内部通讯设计：</p>
<ul>
<li>各个数据库相互通信，保存各个库中槽的编号数据。槽可以不连续</li>
<li>一次命中，直接返回</li>
<li>一次未命中，告知具体位置。不是 A 去 B 里找，而是链接请求客户端去 B 里找。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/img_convert/032dea75c958da075af378b6b9680362.png" alt="" loading="lazy"></p>
<h4 id="搭建方式"><a class="header-anchor" href="#搭建方式">¶</a>搭建方式</h4>
<p> 原生安装（单条命令）<br>
 配置服务器（ 3 主 3 从）<br>
 建立通信（ Meet）<br>
 分槽（ Slot）<br>
 搭建主从（ master-slave）<br>
 工具安装（批处理）</p>
<h4 id="Cluster-配置"><a class="header-anchor" href="#Cluster-配置">¶</a>Cluster 配置</h4>
<p> 添加节点：cluster-enabled yes|no<br>
 cluster 配置文件名，该文件属于自动生成，仅用于快速查找文件并查询文件内容 cluster-config-file <code>&lt;filename&gt;</code><br>
 节点服务响应超时时间，用于判定该节点是否下线或切换为从节点 cluster-node-timeout <code>&lt;milliseconds&gt;</code><br>
 master 连接的 slave 最小数量</p>
<p>cluster-migration-barrier<code>&lt;count&gt;</code></p>
<p>查看集群节点信息 cluster nodes<br>
 进入一个从节点 redis，切换其主节点<code>cluster replicate &lt;master-id&gt;</code><br>
 发现一个新节点，新增主节点 cluster meet ip:port<br>
 忽略一个没有 solt 的节点<code>cluster forget &lt;id&gt;</code><br>
 手动故障转移 cluster failover</p>
<p>redis-trib 命令<br>
 添加节点 redis-trib.rb add-node<br>
 删除节点 redis-trib.rb del-node<br>
 重新分片 redis-trib.rb reshard</p>
<h4 id="8-3-4-集群搭建"><a class="header-anchor" href="#8-3-4-集群搭建">¶</a>8.3.4 集群搭建</h4>
<p>第一步：创建集群节点配置文件</p>
<pre class="line-numbers language-none"><code class="language-none"># 创建一个集群配置文件的目录
mkdir -p ~&#x2F;Desktop&#x2F;redis-cluster<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>创建六个配置文件，分别命名为：<code>redis_7000.conf</code>、<code>redis_7001.conf</code>…<code>redis_7005.conf</code>，然后根据不同的端口号修改对应的端口值就好了：</p>
<pre class="line-numbers language-none"><code class="language-none"># 后台执行
daemonize yes
# 端口号 
port 7000 # 每个redis不一样
# 为每一个集群节点指定一个 pid_file
pidfile ~&#x2F;Desktop&#x2F;redis-cluster&#x2F;redis_7000.pid
# 启动集群模式
cluster-enabled yes
# 每一个集群节点都有一个配置文件，这个文件是不能手动编辑的。确保每一个集群节点的配置文件不通
cluster-config-file nodes-7000.conf
# 集群节点的超时时间，单位：ms，超时后集群会认为该节点失败
cluster-node-timeout 5000
# 最后将 appendonly 改成 yes(AOF 持久化)
appendonly yes
#dir<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-none"><code class="language-none">sed &#39;s&#x2F;7000&#x2F;7001&#x2F;g&#39; redis7000.conf &gt; redis7001.conf
# 把redis7000.conf文件里所有7000改成7001后输入到redis7001.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>记得把对应上述配置文件中根端口对应的配置都修改掉 <em>(port/ pidfile/ cluster-config-file)</em>。</p>
<p>第二步：分别启动 6 个 Redis 实例</p>
<pre class="line-numbers language-none"><code class="language-none"># 用的是redis-server，但是值得注意的是下面相当于是6个集群，我们后面还需要操作
redis-server ~&#x2F;Desktop&#x2F;redis-cluster&#x2F;redis_7000.conf
redis-server ~&#x2F;Desktop&#x2F;redis-cluster&#x2F;redis_7001.conf
redis-server ~&#x2F;Desktop&#x2F;redis-cluster&#x2F;redis_7002.conf
redis-server ~&#x2F;Desktop&#x2F;redis-cluster&#x2F;redis_7003.conf
redis-server ~&#x2F;Desktop&#x2F;redis-cluster&#x2F;redis_7004.conf
redis-server ~&#x2F;Desktop&#x2F;redis-cluster&#x2F;redis_7005.conf
#此时是写不了数据的，因为还没有分配槽位 #只有主节点有槽，从结点没有槽位的概念<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>然后执行 <code>ps -ef | grep redis</code> 查看是否启动成功：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/d31ddccd938381c23a61a9970e8b20f5.png" alt="" loading="lazy"></p>
<p>可以看到 <code>6</code> 个 Redis 节点都以集群的方式成功启动了，<strong>但是现在每个节点还处于独立的状态</strong>，也就是说它们每一个都各自成了一个集群，还没有互相联系起来，我们需要手动地把他们之间建立起联系。</p>
<p>第三步：建立集群</p>
<p>执行下列命令：</p>
<pre class="line-numbers language-none"><code class="language-none"># 5.0后才能这么用，之前版本要用lua
# redis-cli --cluster 
redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 --cluster-replicas 1 
# 考前的是主节点<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li><code>--replicas 1</code>：集群中的每个主节点创建一个从节点，即备份一份。如上会把 6 个结点分别 3 个主从模型，每个主从 2 个结点</li>
</ul>
<p>观察控制台输出：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/1c455870bde86277383fa31c55ce5ff9.png" alt="" loading="lazy"></p>
<p>看到 <code>[OK]</code> 的信息之后，就表示集群已经搭建成功了，可以看到，这里我们正确地创建了三主三从的集群。</p>
<p>第四步：验证集群</p>
<p>我们先使用 <code>redic-cli</code> 任意连接一个节点：</p>
<pre class="line-numbers language-none"><code class="language-none">redis-cli -c -h 127.0.0.1 -p 7000<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<ul>
<li><code>-c</code>表示集群模式；<code>-h</code> 指定 ip 地址；<code>-p</code> 指定端口。</li>
</ul>
<p>然后随便 <code>set</code> 一些值观察控制台输入：</p>
<pre class="line-numbers language-none"><code class="language-none">127.0.0.1:7000&gt; SET name wmyskxz
-&gt; Redirected to slot [5798] located at 127.0.0.1:7001 # 重定向到7001机器上的5798槽位
OK


&gt; cluster nodes查看结点信息<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以看到这里 Redis 自动帮我们进行了 <code>Redirected</code> 操作跳转到了 <code>7001</code> 这个实例上。</p>
<p>我们再使用 <code>cluster info</code> <em>(查看集群信息)</em> 和 <code>cluster nodes</code> <em>(查看节点列表)</em> 来分别看看：<em>(任意节点输入均可)</em></p>
<pre class="line-numbers language-none"><code class="language-none">127.0.0.1:7001&gt; CLUSTER INFO
cluster_state:ok
cluster_slots_assigned:16384
cluster_slots_ok:16384
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:6
cluster_size:3
cluster_current_epoch:6
cluster_my_epoch:2
cluster_stats_messages_ping_sent:1365
cluster_stats_messages_pong_sent:1358
cluster_stats_messages_meet_sent:4
cluster_stats_messages_sent:2727
cluster_stats_messages_ping_received:1357
cluster_stats_messages_pong_received:1369
cluster_stats_messages_meet_received:1
cluster_stats_messages_received:2727
#----------------------------------------
127.0.0.1:7001&gt; CLUSTER NODES
56a04742f36c6e84968cae871cd438935081e86f 127.0.0.1:7003@17003 slave 4ec8c022e9d546c9b51deb9d85f6cf867bf73db6 0 1584428884000 4 connected
4ec8c022e9d546c9b51deb9d85f6cf867bf73db6 127.0.0.1:7000@17000 master - 0 1584428884000 1 connected 0-5460
e2539c4398b8258d3f9ffa714bd778da107cb2cd 127.0.0.1:7005@17005 slave a3406db9ae7144d17eb7df5bffe8b70bb5dd06b8 0 1584428885222 6 connected
d31cd1f423ab1e1849cac01ae927e4b6950f55d9 127.0.0.1:7004@17004 slave 236cefaa9cdc295bc60a5bd1aed6a7152d4f384d 0 1584428884209 5 connected
236cefaa9cdc295bc60a5bd1aed6a7152d4f384d 127.0.0.1:7001@17001 myself,master - 0 1584428882000 2 connected 5461-10922
a3406db9ae7144d17eb7df5bffe8b70bb5dd06b8 127.0.0.1:7002@17002 master - 0 1584428884000 3 connected 10923-16383

# jedis不提供这种重定向功能<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="扩容"><a class="header-anchor" href="#扩容">¶</a>扩容</h4>
<pre class="line-numbers language-none"><code class="language-none">redis-server &#x2F;redis-7007.conf
cluster nodes
redis.cli --cluster help
redis.cli --cluster add-node 182.168.294.188:7007 192.168.204.177:7000这个参数只要指定集群中任意机器就行 #以主节点加入
cluster nodes
redis.cli --cluster add-node 182.168.294.188:7008 192.168.204.177:7000 --cluster-slave --cluster-master-id 9saudsiodno上面查到的id
# 此时新加入的主节点还没有槽位
redis-cli --cluster reshard 已存在节点id:端口<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>一、原生搭建</p>
<ul>
<li>配置开启 cluster 结点
<ul>
<li>cluster-enabled yes</li>
<li>cluster-config-file nodes-8001.conf</li>
</ul>
</li>
<li>meet
<ul>
<li>cluster meet ip port</li>
</ul>
</li>
<li>指派槽
<ul>
<li>查看 crc16 算法算出 key 的槽位命令 cluster keyslot key</li>
<li>默认平均分配
<ul>
<li>3 个主从时 16384/3 0-5461 5462-10922 10923-16383</li>
<li>4 额主从时 36384/4 4096</li>
</ul>
</li>
<li>cluster addslots slot (槽位下标)</li>
</ul>
</li>
<li>分配主从
<ul>
<li>cluster replcate node-id</li>
</ul>
</li>
</ul>
<p>二、使用 redis 提供的 rb 脚本</p>
<p>redis cluster 集群需要至少三个 master 结点，我们这里搭建三个 master 结点，并且给每个 master 再搭建一个 slave 结点，总共 6 个 redis 结点，由于节点数较多，这里采用在一台机器上创建 6 个 redis 实例，并将这 6 个 redis 实例配置成集群模式，所以这里搭建的是为集群模式，当然真正的分布式集群的配置方法几乎一样，搭建伪集群的步骤如下</p>
<ul>
<li>在 / usr/local 下创建文件夹 redis-cluster，然后在其下面分别创建 6 个文件夹如下
<ul>
<li>mkdir -p /usr/local/redis-cluster</li>
</ul>
</li>
</ul>
<h2 id="数据分区方案简析"><a class="header-anchor" href="#数据分区方案简析">¶</a>数据分区方案简析</h2>
<h5 id="方案一：哈希值-节点数"><a class="header-anchor" href="#方案一：哈希值-节点数">¶</a>方案一：哈希值 % 节点数</h5>
<p>哈希取余分区思路非常简单：计算 <code>key</code> 的 hash 值，然后对节点数量进行取余，从而决定数据映射到哪个节点上。</p>
<p>不过该方案最大的问题是，<strong>当新增或删减节点时</strong>，节点数量发生变化，系统中所有的数据都需要 <strong>重新计算映射关系</strong>，引发大规模数据迁移。</p>
<h5 id="方案二：一致性哈希分区"><a class="header-anchor" href="#方案二：一致性哈希分区">¶</a>方案二：一致性哈希分区</h5>
<p>一致性哈希算法将 <strong>整个哈希值空间</strong> 组织成一个虚拟的圆环，范围是 [0 , 232-1]，对于每一个数据，根据 <code>key</code> 计算 hash 值，确数据在环上的位置，然后从此位置沿顺时针行走，找到的第一台服务器就是其应该映射到的服务器：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7896890-40e8a2c096c8da92.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" loading="lazy"></p>
<p>与哈希取余分区相比，一致性哈希分区将 增减节点的影响限制在相邻节点。以上图为例，如果在 <code>node1</code> 和 <code>node2</code> 之间增加 <code>node5</code>，则只有 <code>node2</code> 中的一部分数据会迁移到 <code>node5</code>；如果去掉 <code>node2</code>，则原 <code>node2</code> 中的数据只会迁移到 <code>node4</code> 中，只有 <code>node4</code> 会受影响。</p>
<p>一致性哈希分区的主要问题在于，当 <strong>节点数量较少</strong> 时，增加或删减节点，<strong>对单个节点的影响可能很大</strong>，造成数据的严重不平衡。还是以上图为例，如果去掉 <code>node2</code>，<code>node4</code> 中的数据由总数据的 <code>1/4</code> 左右变为 <code>1/2</code> 左右，与其他节点相比负载过高。</p>
<h5 id="方案三：带有虚拟节点的一致性哈希分区"><a class="header-anchor" href="#方案三：带有虚拟节点的一致性哈希分区">¶</a>方案三：带有虚拟节点的一致性哈希分区</h5>
<p>该方案在 <strong>一致性哈希分区的基础上</strong>，引入了 <strong>虚拟节点</strong> 的概念。Redis 集群使用的便是该方案，其中的虚拟节点称为 <strong>槽（slot）</strong>。槽是介于数据和实际节点之间的虚拟概念，每个实际节点包含一定数量的槽，每个槽包含哈希值在一定范围内的数据。</p>
<p>在使用了槽的一致性哈希分区中，<strong>槽是数据管理和迁移的基本单位</strong>。槽 <strong>解耦</strong> 了 <strong>数据和实际节点</strong> 之间的关系，增加或删除节点对系统的影响很小。仍以上图为例，系统中有 <code>4</code> 个实际节点，假设为其分配 <code>16</code> 个槽 (0-15)；</p>
<ul>
<li>槽 0-3 位于 node1；4-7 位于 node2；以此类推…</li>
</ul>
<p>如果此时删除 <code>node2</code>，只需要将槽 4-7 重新分配即可，例如槽 4-5 分配给 <code>node1</code>，槽 6 分配给 <code>node3</code>，槽 7 分配给 <code>node4</code>；可以看出删除 <code>node2</code> 后，数据在其他节点的分布仍然较为均衡。</p>
<h4 id="节点通信机制简析"><a class="header-anchor" href="#节点通信机制简析">¶</a>节点通信机制简析</h4>
<p>集群的建立离不开节点之间的通信，例如我们上访在 <em>快速体验</em> 中刚启动六个集群节点之后通过 <code>redis-cli</code> 命令帮助我们搭建起来了集群，实际上背后每个集群之间的两两连接是通过了 <code>CLUSTER MEET &lt;ip&gt; &lt;port&gt;</code> 命令发送 <code>MEET</code> 消息完成的，下面我们展开详细说说。</p>
<h4 id="两个端口"><a class="header-anchor" href="#两个端口">¶</a>两个端口</h4>
<p>在 <strong>哨兵系统</strong> 中，节点分为 <strong>数据节点</strong> 和 <strong>哨兵节点</strong>：前者存储数据，后者实现额外的控制功能。在 <strong>集群</strong> 中，没有数据节点与非数据节点之分：<strong>所有的节点都存储数据，也都参与集群状态的维护</strong>。为此，集群中的每个节点，都提供了两个 TCP 端口：</p>
<ul>
<li><strong>普通端口：</strong> 即我们在前面指定的端口 <em>(7000 等)</em>。普通端口主要用于为客户端提供服务 <em>（与单机节点类似）</em>；但在节点间数据迁移时也会使用。</li>
<li><strong>集群端口：</strong> 端口号是普通端口 + 10000 <em>（10000 是固定值，无法改变）</em>，如 <code>7000</code> 节点的集群端口为 <code>17000</code>。<strong>集群端口只用于节点之间的通信</strong>，如搭建集群、增减节点、故障转移等操作时节点间的通信；不要使用客户端连接集群接口。为了保证集群可以正常工作，在配置防火墙时，要同时开启普通端口和集群端口。</li>
</ul>
<h4 id="Gossip-协议"><a class="header-anchor" href="#Gossip-协议">¶</a>Gossip 协议</h4>
<p>节点间通信，按照通信协议可以分为几种类型：单对单、广播、Gossip 协议等。重点是广播和 Gossip 的对比。</p>
<ul>
<li>广播是指向集群内所有节点发送消息。<strong>优点</strong> 是集群的收敛速度快 (集群收敛是指集群内所有节点获得的集群信息是一致的)，<strong>缺点</strong> 是每条消息都要发送给所有节点，CPU、带宽等消耗较大。</li>
<li>Gossip 协议的特点是：在节点数量有限的网络中，<strong>每个节点都 “随机” 的与部分节点通信</strong> <em>（并不是真正的随机，而是根据特定的规则选择通信的节点）</em>，经过一番杂乱无章的通信，每个节点的状态很快会达到一致。Gossip 协议的 <strong>优点</strong> 有负载 <em>(比广播)</em> 低、去中心化、容错性高 <em>(因为通信有冗余)</em> 等；<strong>缺点</strong> 主要是集群的收敛速度慢。</li>
</ul>
<h4 id="消息类型"><a class="header-anchor" href="#消息类型">¶</a>消息类型</h4>
<p>集群中的节点采用 <strong>固定频率（每秒 10 次）</strong> 的 <strong>定时任务</strong> 进行通信相关的工作：判断是否需要发送消息及消息类型、确定接收节点、发送消息等。如果集群状态发生了变化，如增减节点、槽状态变更，通过节点间的通信，所有节点会很快得知整个集群的状态，使集群收敛。</p>
<p>节点间发送的消息主要分为 <code>5</code> 种：<code>meet 消息</code>、<code>ping 消息</code>、<code>pong 消息</code>、<code>fail 消息</code>、<code>publish 消息</code>。不同的消息类型，通信协议、发送的频率和时机、接收节点的选择等是不同的：</p>
<ul>
<li><strong>MEET 消息：</strong> 在节点握手阶段，当节点收到客户端的 <code>CLUSTER MEET</code> 命令时，会向新加入的节点发送 <code>MEET</code> 消息，请求新节点加入到当前集群；新节点收到 MEET 消息后会回复一个 <code>PONG</code> 消息。</li>
<li><strong>PING 消息：</strong> 集群里每个节点每秒钟会选择部分节点发送 <code>PING</code> 消息，接收者收到消息后会回复一个 <code>PONG</code> 消息。<strong>PING 消息的内容是自身节点和部分其他节点的状态信息</strong>，作用是彼此交换信息，以及检测节点是否在线。<code>PING</code> 消息使用 Gossip 协议发送，接收节点的选择兼顾了收敛速度和带宽成本，<strong>具体规则如下</strong>：(1) 随机找 5 个节点，在其中选择最久没有通信的 1 个节点；(2) 扫描节点列表，选择最近一次收到 <code>PONG</code> 消息时间大于 <code>cluster_node_timeout / 2</code> 的所有节点，防止这些节点长时间未更新。</li>
<li><strong>PONG 消息：</strong> <code>PONG</code> 消息封装了自身状态数据。可以分为两种：<strong>第一种</strong> 是在接到 <code>MEET/PING</code> 消息后回复的 <code>PONG</code> 消息；<strong>第二种</strong> 是指节点向集群广播 <code>PONG</code> 消息，这样其他节点可以获知该节点的最新信息，例如故障恢复后新的主节点会广播 <code>PONG</code> 消息。</li>
<li><strong>FAIL 消息：</strong> 当一个主节点判断另一个主节点进入 <code>FAIL</code> 状态时，会向集群广播这一 <code>FAIL</code> 消息；接收节点会将这一 <code>FAIL</code> 消息保存起来，便于后续的判断。</li>
<li><strong>PUBLISH 消息：</strong> 节点收到 <code>PUBLISH</code> 命令后，会先执行该命令，然后向集群广播这一消息，接收节点也会执行该 <code>PUBLISH</code> 命令。</li>
</ul>
<h2 id="数据结构简析"><a class="header-anchor" href="#数据结构简析">¶</a>数据结构简析</h2>
<p>节点需要专门的数据结构来存储集群的状态。所谓集群的状态，是一个比较大的概念，包括：集群是否处于上线状态、集群中有哪些节点、节点是否可达、节点的主从状态、槽的分布……</p>
<p>节点为了存储集群状态而提供的数据结构中，最关键的是 <code>clusterNode</code> 和 <code>clusterState</code> 结构：前者记录了一个节点的状态，后者记录了集群作为一个整体的状态。</p>
<h4 id="clusterNode-结构"><a class="header-anchor" href="#clusterNode-结构">¶</a>clusterNode 结构</h4>
<p><code>clusterNode</code> 结构保存了 <strong>一个节点的当前状态</strong>，包括创建时间、节点 id、ip 和端口号等。每个节点都会用一个 <code>clusterNode</code> 结构记录自己的状态，并为集群内所有其他节点都创建一个 <code>clusterNode</code> 结构来记录节点状态。</p>
<p>下面列举了 <code>clusterNode</code> 的部分字段，并说明了字段的含义和作用：</p>
<pre class="line-numbers language-none"><code class="language-none">typedef struct clusterNode &#123;
    &#x2F;&#x2F;节点创建时间
    mstime_t ctime;
    &#x2F;&#x2F;节点id
    char name[REDIS_CLUSTER_NAMELEN];
    &#x2F;&#x2F;节点的ip和端口号
    char ip[REDIS_IP_STR_LEN];
    int port;
    &#x2F;&#x2F;节点标识：整型，每个bit都代表了不同状态，如节点的主从状态、是否在线、是否在握手等
    int flags;
    &#x2F;&#x2F;配置纪元：故障转移时起作用，类似于哨兵的配置纪元
    uint64_t configEpoch;
    &#x2F;&#x2F;槽在该节点中的分布：占用16384&#x2F;8个字节，16384个比特；每个比特对应一个槽：比特值为1，则该比特对应的槽在节点中；比特值为0，则该比特对应的槽不在节点中
    unsigned char slots[16384&#x2F;8];
    &#x2F;&#x2F;节点中槽的数量
    int numslots;
    …………
&#125; clusterNode;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>除了上述字段，<code>clusterNode</code> 还包含节点连接、主从复制、故障发现和转移需要的信息等。</p>
<h4 id="clusterState-结构"><a class="header-anchor" href="#clusterState-结构">¶</a>clusterState 结构</h4>
<p><code>clusterState</code> 结构保存了在当前节点视角下，集群所处的状态。主要字段包括：</p>
<pre class="line-numbers language-none"><code class="language-none">typedef struct clusterState &#123;
    &#x2F;&#x2F;自身节点
    clusterNode *myself;
    &#x2F;&#x2F;配置纪元
    uint64_t currentEpoch;
    &#x2F;&#x2F;集群状态：在线还是下线
    int state;
    &#x2F;&#x2F;集群中至少包含一个槽的节点数量
    int size;
    &#x2F;&#x2F;哈希表，节点名称-&gt;clusterNode节点指针
    dict *nodes;
    &#x2F;&#x2F;槽分布信息：数组的每个元素都是一个指向clusterNode结构的指针；如果槽还没有分配给任何节点，则为NULL
    clusterNode *slots[16384];
    …………
&#125; clusterState;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>除此之外，<code>clusterState</code> 还包括故障转移、槽迁移等需要的信息。</p>
<h3 id="redis-相关阅读"><a class="header-anchor" href="#redis-相关阅读">¶</a>redis 相关阅读</h3>
<ol>
<li>Redis(1)——5 种基本数据结构 - <a target="_blank" rel="noopener" href="https://www.wmyskxz.com/2020/02/28/redis-1-5-chong-ji-ben-shu-ju-jie-gou/">https://www.wmyskxz.com/2020/02/28/redis-1-5-chong-ji-ben-shu-ju-jie-gou/</a></li>
<li>Redis(2)——跳跃表 - <a target="_blank" rel="noopener" href="https://www.wmyskxz.com/2020/02/29/redis-2-tiao-yue-biao/">https://www.wmyskxz.com/2020/02/29/redis-2-tiao-yue-biao/</a></li>
<li>Redis(3)——分布式锁深入探究 - <a target="_blank" rel="noopener" href="https://www.wmyskxz.com/2020/03/01/redis-3/">https://www.wmyskxz.com/2020/03/01/redis-3/</a></li>
<li>Reids(4)——神奇的 HyperLoglog 解决统计问题 - <a target="_blank" rel="noopener" href="https://www.wmyskxz.com/2020/03/02/reids-4-shen-qi-de-hyperloglog-jie-jue-tong-ji-wen-ti/">https://www.wmyskxz.com/2020/03/02/reids-4-shen-qi-de-hyperloglog-jie-jue-tong-ji-wen-ti/</a></li>
<li>Redis(5)——亿级数据过滤和布隆过滤器 - <a target="_blank" rel="noopener" href="https://www.wmyskxz.com/2020/03/11/redis-5-yi-ji-shu-ju-guo-lu-he-bu-long-guo-lu-qi/">https://www.wmyskxz.com/2020/03/11/redis-5-yi-ji-shu-ju-guo-lu-he-bu-long-guo-lu-qi/</a></li>
<li>Redis(6)——GeoHash 查找附近的人 <a target="_blank" rel="noopener" href="https://www.wmyskxz.com/2020/03/12/redis-6-geohash-cha-zhao-fu-jin-de-ren/">https://www.wmyskxz.com/2020/03/12/redis-6-geohash-cha-zhao-fu-jin-de-ren/</a></li>
<li>Redis(7)——持久化【一文了解】 - <a target="_blank" rel="noopener" href="https://www.wmyskxz.com/2020/03/13/redis-7-chi-jiu-hua-yi-wen-liao-jie/">https://www.wmyskxz.com/2020/03/13/redis-7-chi-jiu-hua-yi-wen-liao-jie/</a></li>
<li>Redis(8)——发布 / 订阅与 Stream - [<a target="_blank" rel="noopener" href="https://www.wmyskxz.com/2020/03/15/redis-8-fa-bu-ding-yue-yu-stream/">https://www.wmyskxz.com/2020/03/15/redis-8-fa-bu-ding-yue-yu-stream/</a>](</li>
</ol>
<h2 id="9-6-集群操作"><a class="header-anchor" href="#9-6-集群操作">¶</a>9.6 集群操作</h2>
<ol>
<li>以集群的方式进入客户端</li>
</ol>
<p>redis-cli -c -p 端口号</p>
<ol start="2">
<li>
<p>通过<code>cluster nodes</code> 命令查看集群信息</p>
</li>
<li>
<p>redis cluster 如何分配这六个节点</p>
</li>
</ol>
<p>一个集群至少要有三个主节点。</p>
<p>选项 --replicas 1 表示我们希望为集群中的每个主节点创建一个从节点。</p>
<p>分配原则尽量保证每个主数据库运行在不同的 IP 地址，每个从库和主库不在一个 IP 地址上。</p>
<ol start="4">
<li>什么是 slots</li>
</ol>
<p>l 一个 Redis 集群包含 16384 个插槽（hash slot）， 数据库中的每个键都属于这 16384 个插槽的其中一个， 集群使用公式 CRC16(key) % 16384 来计算键 key 属于哪个槽， 其中 CRC16(key) 语句用于计算键 key 的 CRC16 校验和 。</p>
<p>l 集群中的每个节点负责处理一部分插槽。 举个例子， 如果一个集群可以有主节点， 其中：</p>
<p>​ 节点 A 负责处理 0 号至 5500 号插槽。</p>
<p>​ 节点 B 负责处理 5501 号至 11000 号插槽。</p>
<p>​ 节点 C 负责处理 11001 号至 16383 号插槽</p>
<ol start="5">
<li>在集群中录入值</li>
</ol>
<p>l 在 redis-cli 每次录入、查询键值，redis 都会计算出该 key 应该送往的插槽，如果不是该客户端对应服务器的插槽，redis 会报错，并告知应前往的 redis 实例地址和端口.</p>
<p>l redis-cli 客户端提供了 –c 参数实现自动重定向。</p>
<p>如 redis-cli -c –p 6379 登入后，再录入、查询键值对可以自动重定向。</p>
<p>l 不在一个 slot 下的键值，是不能使用 mget,mset 等多键操作。</p>
<p>l 可以通过 {} 来定义组的概念，从而使 key 中 {} 内相同内容的键值对放到一个 slot 中去</p>
<ol start="6">
<li>查询集群中的值</li>
</ol>
<ul>
<li><code>CLUSTER KEYSLOT &lt;key&gt;</code> 计算键 key 应该被放置在哪个槽上。</li>
<li><code>CLUSTER COUNTKEYSINSLOT &lt;slot&gt;</code> 返回槽 slot 目前包含的键值对数量</li>
<li><code>CLUSTER GETKEYSINSLOT &lt;slot&gt; &lt;count&gt;</code> 返回 count 个 slot 槽中的键</li>
</ul>
<ol start="7">
<li>故障恢复</li>
</ol>
<p>l 如果主节点下线？从节点能否自动升为主节点？</p>
<p>l 主节点恢复后，主从关系会如何？</p>
<p>l 如果所有某一段插槽的主从节点都当掉，redis 服务是否还能继续?</p>
<p>redis.conf 中的参数 cluster-require-full-coverage</p>
<h1>redis 客户端</h1>
<p>Jedis api 在线网址：<a target="_blank" rel="noopener" href="http://tool.oschina.net/uploads/apidocs/redis/clients/jedis/Jedis.html">http://tool.oschina.net/uploads/apidocs/redis/clients/jedis/Jedis.html</a></p>
<p>redisson 官网地址：<a target="_blank" rel="noopener" href="https://redisson.org/">https://redisson.org/</a></p>
<p>redisson git 项目地址：<a target="_blank" rel="noopener" href="https://github.com/redisson/redisson">https://github.com/redisson/redisson</a></p>
<p>lettuce 官网地址：<a target="_blank" rel="noopener" href="https://lettuce.io/">https://lettuce.io/</a></p>
<p>lettuce git 项目地址：<a target="_blank" rel="noopener" href="https://github.com/lettuce-io/lettuce-core">https://github.com/lettuce-io/lettuce-core</a></p>
<p>首先，在 spring boot2 之后，对 redis 连接的支持，默认就采用了 lettuce。这就一定程度说明了 lettuce 和 Jedis 的优劣。</p>
<p><strong>概念：</strong></p>
<p>Jedis：是老牌的 Redis 的 Java 实现客户端，提供了比较全面的 Redis 命令的支持，</p>
<p>Redisson：实现了分布式和可扩展的 Java 数据结构。</p>
<p>Lettuce：高级 Redis 客户端，用于线程安全同步，异步和响应使用，支持集群，Sentinel，管道和编码器。</p>
<p>优点：<br>
　　Jedis：比较全面的提供了 Redis 的操作特性</p>
<p>Redisson：促使使用者对 Redis 的关注分离，提供很多分布式相关操作服务，例如，<strong>分布式锁，分布式集合，可通过 Redis 支持延迟队列</strong></p>
<p>Lettuce：<strong>基于 Netty 框架的事件驱动的通信层</strong>，其方法调用是异步的。Lettuce 的 API 是<strong>线程安全</strong>的，所以可以操作单个 Lettuce 连接来完成各种操作</p>
<p>可伸缩：</p>
<p>Jedis：使用阻塞的 I/O，且其方法调用都是同步的，程序流需要等到 sockets 处理完 I/O 才能执行，不支持异步。<strong>Jedis 客户端实例不是线程安全的</strong>，所以需要通过连接池来使用 Jedis。</p>
<p>Redisson：基于 Netty 框架的事件驱动的通信层，其方法调用是异步的。Redisson 的 API 是线程安全的，所以可以操作单个 Redisson 连接来完成各种操作</p>
<p>Lettuce：基于 Netty 框架的事件驱动的通信层，其方法调用是异步的。Lettuce 的 API 是线程安全的，所以可以操作单个 Lettuce 连接来完成各种操作</p>
<p>lettuce 能够支持 redis4，需要 java8 及以上。<br>
lettuce 是基于 netty 实现的与 redis 进行同步和异步的通信。</p>
<p><strong>lettuce 和 jedis 比较：</strong><br>
jedis 使直接连接 redis server, 如果在多线程环境下是非线程安全的，这个时候只有使用连接池，为每个 jedis 实例增加物理连接 ；</p>
<p>lettuce 的连接是基于 Netty 的，连接实例（StatefulRedisConnection）可以在多个线程间并发访问，StatefulRedisConnection 是线程安全的，所以一个连接实例可以满足多线程环境下的并发访问，当然这也是可伸缩的设计，一个连接实例不够的情况也可以按需增加连接实例。</p>
<p>Redisson 实现了分布式和可扩展的 Java 数据结构，和 Jedis 相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等 Redis 特性。Redisson 的宗旨是促进使用者对 Redis 的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。</p>
<p><strong>总结：</strong><br>
优先使用 Lettuce，如果需要分布式锁，分布式集合等分布式的高级特性，添加 Redisson 结合使用，因为 Redisson 本身对字符串的操作支持很差。</p>
<h2 id="9-7-集群的-Jedis-开发"><a class="header-anchor" href="#9-7-集群的-Jedis-开发">¶</a>9.7 集群的 Jedis 开发</h2>
<pre class="line-numbers language-none"><code class="language-none">public class JedisClusterTest &#123;
    public static void main(String[] args) &#123;

        Set&lt;HostAndPort&gt; set &#x3D;new HashSet&lt;HostAndPort&gt;();
        set.add(new HostAndPort(&quot;192.168.31.211&quot;,6379));
        JedisCluster jedisCluster&#x3D;new JedisCluster(set);
        jedisCluster.set(&quot;k1&quot;, &quot;v1&quot;);
        System.out.println(jedisCluster.get(&quot;k1&quot;));
    &#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1>RedisTemplate</h1>
<p>直接传对象的话就报 未序列化的错误</p>
<p>Spring-data-redis 是 spring 大家族的一部分，提供了在 srping 应用中通过简单的配置访问 redis 服务，对 redis 底层开发包 (Jedis, JRedis, and RJC) 进行了高度封装，RedisTemplate 提供了 redis 各种操作、异常处理及序列化，支持发布订阅，并对 spring 3.1 cache 进行了实现。<br>
<strong>官网：<a target="_blank" rel="noopener" href="http://projects.spring.io/spring-data-redis/">http://projects.spring.io/spring-data-redis/</a></strong><br>
<strong>项目地址：<a target="_blank" rel="noopener" href="https://github.com/spring-projects/spring-data-redis">https://github.com/spring-projects/spring-data-redis</a></strong></p>
<h3 id="一、spring-data-redis-功能介绍"><a class="header-anchor" href="#一、spring-data-redis-功能介绍">¶</a>一、spring-data-redis 功能介绍</h3>
<p>jedis 客户端在编程实施方面存在如下不足：</p>
<p>1)connection 管理缺乏自动化，connection-pool 的设计缺少必要的容器支持。<br>
2)数据操作需要关注 “序列化”/“反序列化”，因为 jedis 的客户端 API 接受的数据类型为 string 和 byte，对结构化数据(json,xml,pojo 等) 操作需要额外的支持。<a target="_blank" rel="noopener" href="https://www.cnblogs.com/duanxz/p/3511695.html">https://www.cnblogs.com/duanxz/p/3511695.html</a><br>
3) 事务操作纯粹为硬编码。<br>
4)pub/sub 功能，缺乏必要的设计模式支持，对于开发者而言需要关注的太多。</p>
<p>spring-data-redis 针对 jedis 提供了如下功能：</p>
<ul>
<li>
<ol>
<li>连接池自动管理，提供了一个高度封装的 “RedisTemplate” 类</li>
</ol>
</li>
<li>
<ol start="2">
<li>针对 jedis 客户端中大量 api 进行了归类封装, 将同一类型操作封装为 operation 接口</li>
</ol>
<ul>
<li>ValueOperations：简单 K-V 操作</li>
<li>SetOperations：set 类型数据操作</li>
<li>ZSetOperations：zset 类型数据操作</li>
<li>HashOperations：针对 map 类型的数据操作</li>
<li>ListOperations：针对 list 类型的数据操作</li>
</ul>
</li>
<li>
<ol start="3">
<li>提供了对 key 的 “bound”(绑定) 便捷化操作 API，可以通过 bound 封装指定的 key，然后进行一系列的操作而无须 “显式” 的再次指定 Key，即 BoundKeyOperations：</li>
</ol>
<ul>
<li>BoundValueOperations</li>
<li>BoundSetOperations</li>
<li>BoundListOperations</li>
<li>BoundSetOperations</li>
<li>BoundHashOperations</li>
</ul>
</li>
<li>
<ol start="4">
<li>将事务操作封装，有容器控制。</li>
</ol>
</li>
<li>
<ol start="5">
<li>针对数据的 “序列化 / 反序列化”，提供了多种可选择策略 (RedisSerializer)</li>
</ol>
<ul>
<li>JdkSerializationRedisSerializer：POJO 对象的存取场景，使用 JDK 本身序列化机制，将 pojo 类通过 ObjectInputStream/ObjectOutputStream 进行序列化操作，最终 redis-server 中将存储字节序列。是目前最常用的序列化策略。</li>
<li>StringRedisSerializer：Key 或者 value 为字符串的场景，根据指定的 charset 对数据的字节序列编码成 string，是 “new String(bytes, charset)” 和“string.getBytes(charset)”的直接封装。是最轻量级和高效的策略。</li>
<li>JacksonJsonRedisSerializer：jackson-json 工具提供了 javabean 与 json 之间的转换能力，可以将 pojo 实例序列化成 json 格式存储在 redis 中，也可以将 json 格式的数据转换成 pojo 实例。因为 jackson 工具在序列化和反序列化时，需要明确指定 Class 类型，因此此策略封装起来稍微复杂。【需要 jackson-mapper-asl 工具支持】</li>
<li>OxmSerializer：提供了将 javabean 与 xml 之间的转换能力，目前可用的三方支持包括 jaxb，apache-xmlbeans；redis 存储的数据将是 xml 工具。不过使用此策略，编程将会有些难度，而且效率最低；不建议使用。【需要 spring-oxm 模块的支持】</li>
<li>针对 “序列化和发序列化” 中 JdkSerializationRedisSerializer 和 StringRedisSerializer 是最基础的策略，原则上，我们可以将数据存储为任何格式以便应用程序存取和解析 (其中应用包括 app，hadoop 等其他工具)，不过在设计时仍然不推荐直接使用“JacksonJsonRedisSerializer” 和“OxmSerializer”，因为无论是 json 还是 xml，他们本身仍然是 String。如果你的数据需要被第三方工具解析，那么数据应该使用 StringRedisSerializer 而不是 JdkSerializationRedisSerializer。如果你的数据格式必须为 json 或者 xml，那么在编程级别，在 redisTemplate 配置中仍然使用 StringRedisSerializer，在存储之前或者读取之后，使用 “SerializationUtils” 工具转换转换成 json 或者 xml</li>
</ul>
</li>
<li>
<ol start="6">
<li>基于设计模式，和 JMS 开发思路，将 pub/sub 的 API 设计进行了封装，使开发更加便捷。</li>
</ol>
</li>
<li>7.spring-data-redis 中，并没有对 sharding 提供良好的封装，如果你的架构是基于 sharding，那么你需要自己去实现，这也是 sdr 和 jedis 相比，唯一缺少的特性。</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none">RedisTemplate&lt;String,Object&gt; template &#x3D; new RedisTemplate&lt;&gt;();
template.setConnection(factory);&#x2F;&#x2F;LettuceConnectionFactory
Jackson2JsonRedisSerializer jackson2JsonRedisSerializer &#x3D; new Jackson2JsonRedisSerializer(Object.class);
ObjectMapper om &#x3D; new ObjectMapper();
om.set<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="redis-template-用法"><a class="header-anchor" href="#redis-template-用法">¶</a>redis-template 用法</h3>
<p>序列化：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/duanxz/p/3511695.html">https://www.cnblogs.com/duanxz/p/3511695.html</a></p>
<blockquote>
<ul>
<li>transient 修饰的属性，不会被序列化</li>
<li>静态 static 的属性，不会序列化</li>
<li>实现 Serializable 接口的时候，一定要给这个 serialVersionID 赋值。序列化的时候没有某个属性，反序列话的时候增加了某个属性，重新计算的 UID 就不一样了。<a target="_blank" rel="noopener" href="https://blog.csdn.net/u014750606/article/details/80040130">https://blog.csdn.net/u014750606/article/details/80040130</a></li>
<li>当属性是对象的时候，镀锡也有实现序列化的接口</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none">redisTemplate.opsForValue();&#x2F;&#x2F;操作字符串
redisTemplate.opsForHash();&#x2F;&#x2F;操作hash
redisTemplate.opsForList();&#x2F;&#x2F;操作list
redisTemplate.opsForSet();&#x2F;&#x2F;操作set
redisTemplate.opsForZSet();&#x2F;&#x2F;操作有序set<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</blockquote>
<h5 id="String"><a class="header-anchor" href="#String">¶</a>String</h5>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F;set void set(K key, V value);
redisTemplate.opsForValue().set(&quot;num&quot;,&quot;123&quot;);
redisTemplate.opsForValue().get(&quot;num&quot;)  输出结果为123

&#x2F;&#x2F;set void set(K key, V value, long timeout, TimeUnit unit); 
redisTemplate.opsForValue().set(&quot;num&quot;,&quot;123&quot;,10, TimeUnit.SECONDS);
redisTemplate.opsForValue().get(&quot;num&quot;)设置的是10秒失效，十秒之内查询有结果，十秒之后返回为null
		TimeUnit.DAYS          &#x2F;&#x2F;天
		TimeUnit.HOURS         &#x2F;&#x2F;小时
		TimeUnit.MINUTES       &#x2F;&#x2F;分钟
		TimeUnit.SECONDS       &#x2F;&#x2F;秒
		TimeUnit.MILLISECONDS  &#x2F;&#x2F;毫秒 

&#x2F;&#x2F;set void set(K key, V value, long offset);
&#x2F;&#x2F;覆写(overwrite)给定 key 所储存的字符串值，从偏移量 offset 开始
template.opsForValue().set(&quot;key&quot;,&quot;hello world&quot;);
template.opsForValue().set(&quot;key&quot;,&quot;redis&quot;, 6);
System.out.println(&quot;***************&quot;+template.opsForValue().get(&quot;key&quot;));
结果：***************hello redis

&#x2F;&#x2F;get V get(Object key);
template.opsForValue().set(&quot;key&quot;,&quot;hello world&quot;);
System.out.println(&quot;***************&quot;+template.opsForValue().get(&quot;key&quot;));
结果：***************hello world

&#x2F;&#x2F;getAndSet V getAndSet(K key, V value); 
&#x2F;&#x2F;设置键的字符串值并返回其旧值
template.opsForValue().set(&quot;getSetTest&quot;,&quot;test&quot;);
System.out.println(template.opsForValue().getAndSet(&quot;getSetTest&quot;,&quot;test2&quot;));
结果：test

&#x2F;&#x2F;append Integer append(K key, String value);
&#x2F;&#x2F;如果key已经存在并且是一个字符串，则该命令将该值追加到字符串的末尾。如果键不存在，则它被创建并设置为空字符串，因此APPEND在这种特殊情况下将类似于SET。
template.opsForValue().append(&quot;test&quot;,&quot;Hello&quot;);
System.out.println(template.opsForValue().get(&quot;test&quot;));
template.opsForValue().append(&quot;test&quot;,&quot;world&quot;);
System.out.println(template.opsForValue().get(&quot;test&quot;));
Hello
Helloworld

&#x2F;&#x2F;size Long size(K key);返回key所对应的value值得长度
template.opsForValue().set(&quot;key&quot;,&quot;hello world&quot;);
System.out.println(&quot;***************&quot;+template.opsForValue().size(&quot;key&quot;));
***************11<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="List"><a class="header-anchor" href="#List">¶</a>List</h5>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F;Long size(K key);返回存储在键中的列表的长度。如果键不存在，则将其解释为空列表，并返回0。当key存储的值不是列表时返回错误。

System.out.println(template.opsForList().size(&quot;list&quot;));


&#x2F;&#x2F;Long leftPush(K key, V value);
将所有指定的值插入存储在键的列表的头部。如果键不存在，则在执行推送操作之前将其创建为空列表。（从左边插入）

template.opsForList().leftPush(&quot;list&quot;,&quot;java&quot;);
template.opsForList().leftPush(&quot;list&quot;,&quot;python&quot;);
template.opsForList().leftPush(&quot;list&quot;,&quot;c++&quot;);
返回的结果为推送操作后的列表的长度


&#x2F;&#x2F;Long leftPushAll(K key, V... values);
批量把一个数组插入到列表中

String[] strs &#x3D; new String[]&#123;&quot;1&quot;,&quot;2&quot;,&quot;3&quot;&#125;;
template.opsForList().leftPushAll(&quot;list&quot;,strs);
System.out.println(template.opsForList().range(&quot;list&quot;,0,-1));
[3, 2, 1]

&#x2F;&#x2F;Long rightPush(K key, V value);
将所有指定的值插入存储在键的列表的头部。如果键不存在，则在执行推送操作之前将其创建为空列表。（从右边插入）

template.opsForList().rightPush(&quot;listRight&quot;,&quot;java&quot;);
template.opsForList().rightPush(&quot;listRight&quot;,&quot;python&quot;);
template.opsForList().rightPush(&quot;listRight&quot;,&quot;c++&quot;);

&#x2F;&#x2F;Long rightPushAll(K key, V... values);

String[] strs &#x3D; new String[]&#123;&quot;1&quot;,&quot;2&quot;,&quot;3&quot;&#125;;
template.opsForList().rightPushAll(&quot;list&quot;,strs);
System.out.println(template.opsForList().range(&quot;list&quot;,0,-1));
[1, 2, 3]

&#x2F;&#x2F;void set(K key, long index, V value);
在列表中index的位置设置value值

System.out.println(template.opsForList().range(&quot;listRight&quot;,0,-1));
template.opsForList().set(&quot;listRight&quot;,1,&quot;setValue&quot;);
System.out.println(template.opsForList().range(&quot;listRight&quot;,0,-1));
[java, python, oc, c++]
[java, setValue, oc, c++]

&#x2F;&#x2F;Long remove(K key, long count, Object value);
从存储在键中的列表中删除等于值的元素的第一个计数事件。
计数参数以下列方式影响操作：
count&gt; 0：删除等于从头到尾移动的值的元素。
count &lt;0：删除等于从尾到头移动的值的元素。
count &#x3D; 0：删除等于value的所有元素。

System.out.println(template.opsForList().range(&quot;listRight&quot;,0,-1));
template.opsForList().remove(&quot;listRight&quot;,1,&quot;setValue&quot;);&#x2F;&#x2F;将删除列表中存储的列表中第一次次出现的“setValue”。
System.out.println(template.opsForList().range(&quot;listRight&quot;,0,-1));
[java, setValue, oc, c++]
[java, oc, c++]

&#x2F;&#x2F;V index(K key, long index);
根据下表获取列表中的值，下标是从0开始的

System.out.println(template.opsForList().range(&quot;listRight&quot;,0,-1));
System.out.println(template.opsForList().index(&quot;listRight&quot;,2));
[java, oc, c++]
c++

&#x2F;&#x2F;V leftPop(K key);
弹出最左边的元素，弹出之后该值在列表中将不复存在

System.out.println(template.opsForList().range(&quot;list&quot;,0,-1));
System.out.println(template.opsForList().leftPop(&quot;list&quot;));
System.out.println(template.opsForList().range(&quot;list&quot;,0,-1));
[c++, python, oc, java, c#, c#]
c++
[python, oc, java, c#, c#]

&#x2F;&#x2F;V rightPop(K key);
弹出最右边的元素，弹出之后该值在列表中将不复存在

System.out.println(template.opsForList().range(&quot;list&quot;,0,-1));
System.out.println(template.opsForList().rightPop(&quot;list&quot;));
System.out.println(template.opsForList().range(&quot;list&quot;,0,-1));
[python, oc, java, c#, c#]
c#
[python, oc, java, c#]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="Hash"><a class="header-anchor" href="#Hash">¶</a>Hash</h5>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F;Long delete(H key, Object... hashKeys);
删除给定的哈希hashKeys

System.out.println(template.opsForHash().delete(&quot;redisHash&quot;,&quot;name&quot;));
System.out.println(template.opsForHash().entries(&quot;redisHash&quot;));
&#123;class&#x3D;6, age&#x3D;28.1&#125;

&#x2F;&#x2F;Boolean hasKey(H key, Object hashKey);
确定哈希hashKey是否存在

System.out.println(template.opsForHash().hasKey(&quot;redisHash&quot;,&quot;666&quot;));
System.out.println(template.opsForHash().hasKey(&quot;redisHash&quot;,&quot;777&quot;));
true
false

&#x2F;&#x2F;HV get(H key, Object hashKey);
从键中的哈希获取给定hashKey的值

System.out.println(template.opsForHash().get(&quot;redisHash&quot;,&quot;age&quot;));

&#x2F;&#x2F;Set&lt;HK&gt; keys(H key);
获取key所对应的散列表的key

System.out.println(template.opsForHash().keys(&quot;redisHash&quot;));
&#x2F;&#x2F;redisHash所对应的散列表为&#123;class&#x3D;1, name&#x3D;666, age&#x3D;27&#125;
[name, class, age]

&#x2F;&#x2F;Long size(H key);
获取key所对应的散列表的大小个数

System.out.println(template.opsForHash().size(&quot;redisHash&quot;));
&#x2F;&#x2F;redisHash所对应的散列表为&#123;class&#x3D;1, name&#x3D;666, age&#x3D;27&#125;

&#x2F;&#x2F;void putAll(H key, Map&lt;? extends HK, ? extends HV&gt; m);
使用m中提供的多个散列字段设置到key对应的散列表中

Map&lt;String,Object&gt; testMap &#x3D; new HashMap();
testMap.put(&quot;name&quot;,&quot;666&quot;);
testMap.put(&quot;age&quot;,27);
testMap.put(&quot;class&quot;,&quot;1&quot;);
template.opsForHash().putAll(&quot;redisHash1&quot;,testMap);
System.out.println(template.opsForHash().entries(&quot;redisHash1&quot;));
&#123;class&#x3D;1, name&#x3D;jack, age&#x3D;27&#125;

&#x2F;&#x2F;void put(H key, HK hashKey, HV value);
设置散列hashKey的值

template.opsForHash().put(&quot;redisHash&quot;,&quot;name&quot;,&quot;666&quot;);
template.opsForHash().put(&quot;redisHash&quot;,&quot;age&quot;,26);
template.opsForHash().put(&quot;redisHash&quot;,&quot;class&quot;,&quot;6&quot;);
System.out.println(template.opsForHash().entries(&quot;redisHash&quot;));
&#123;age&#x3D;26, class&#x3D;6, name&#x3D;666&#125;

&#x2F;&#x2F;List&lt;HV&gt; values(H key);
获取整个哈希存储的值根据密钥

System.out.println(template.opsForHash().values(&quot;redisHash&quot;));
[tom, 26, 6]

&#x2F;&#x2F;Map&lt;HK, HV&gt; entries(H key);
获取整个哈希存储根据密钥

System.out.println(template.opsForHash().entries(&quot;redisHash&quot;));
&#123;age&#x3D;26, class&#x3D;6, name&#x3D;tom&#125;

&#x2F;&#x2F;Cursor&lt;Map.Entry&lt;HK, HV&gt;&gt; scan(H key, ScanOptions options);
使用Cursor在key的hash中迭代，相当于迭代器。

Cursor&lt;Map.Entry&lt;Object, Object&gt;&gt; curosr &#x3D; template.opsForHash().scan(&quot;redisHash&quot;, 
  ScanOptions.ScanOptions.NONE);
    while(curosr.hasNext())&#123;
        Map.Entry&lt;Object, Object&gt; entry &#x3D; curosr.next();
        System.out.println(entry.getKey()+&quot;:&quot;+entry.getValue());
    &#125;
age:27
class:6
name:666<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="Set"><a class="header-anchor" href="#Set">¶</a>Set</h5>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F;Long add(K key, V... values);
无序集合中添加元素，返回添加个数
也可以直接在add里面添加多个值 如：template.opsForSet().add(&quot;setTest&quot;,&quot;aaa&quot;,&quot;bbb&quot;)

String[] strs&#x3D; new String[]&#123;&quot;str1&quot;,&quot;str2&quot;&#125;;
System.out.println(template.opsForSet().add(&quot;setTest&quot;, strs));

&#x2F;&#x2F; Long remove(K key, Object... values);
移除集合中一个或多个成员

String[] strs &#x3D; new String[]&#123;&quot;str1&quot;,&quot;str2&quot;&#125;;
System.out.println(template.opsForSet().remove(&quot;setTest&quot;,strs));

&#x2F;&#x2F; V pop(K key);
移除并返回集合中的一个随机元素

System.out.println(template.opsForSet().pop(&quot;setTest&quot;));
System.out.println(template.opsForSet().members(&quot;setTest&quot;));
bbb
[aaa, ccc]

&#x2F;&#x2F; Boolean move(K key, V value, K destKey);
将 member 元素从 source 集合移动到 destination 集合

template.opsForSet().move(&quot;setTest&quot;,&quot;aaa&quot;,&quot;setTest2&quot;);
System.out.println(template.opsForSet().members(&quot;setTest&quot;));
System.out.println(template.opsForSet().members(&quot;setTest2&quot;));
[ccc]
[aaa]

&#x2F;&#x2F; Long size(K key);
无序集合的大小长度

System.out.println(template.opsForSet().size(&quot;setTest&quot;));

&#x2F;&#x2F;Set&lt;V&gt; members(K key);
返回集合中的所有成员

System.out.println(template.opsForSet().members(&quot;setTest&quot;));
[ddd, bbb, aaa, ccc]

&#x2F;&#x2F; Cursor&lt;V&gt; scan(K key, ScanOptions options);
遍历set

Cursor&lt;Object&gt; curosr &#x3D; template.opsForSet().scan(&quot;setTest&quot;, ScanOptions.NONE);
  while(curosr.hasNext())&#123;
     System.out.println(curosr.next());
  &#125;
ddd
bbb
aaa
ccc<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="ZSet"><a class="header-anchor" href="#ZSet">¶</a>ZSet</h5>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F;Boolean add(K key, V value, double score);
新增一个有序集合，存在的话为false，不存在的话为true

System.out.println(template.opsForZSet().add(&quot;zset1&quot;,&quot;zset-1&quot;,1.0));
true

&#x2F;&#x2F; Long add(K key, Set&lt;TypedTuple&lt;V&gt;&gt; tuples);
新增一个有序集合

ZSetOperations.TypedTuple&lt;Object&gt; objectTypedTuple1 &#x3D; new DefaultTypedTuple&lt;&gt;(&quot;zset-5&quot;,9.6);
ZSetOperations.TypedTuple&lt;Object&gt; objectTypedTuple2 &#x3D; new DefaultTypedTuple&lt;&gt;(&quot;zset-6&quot;,9.9);
Set&lt;ZSetOperations.TypedTuple&lt;Object&gt;&gt; tuples &#x3D; new HashSet&lt;ZSetOperations.TypedTuple&lt;Object&gt;&gt;();
tuples.add(objectTypedTuple1);
tuples.add(objectTypedTuple2);
System.out.println(template.opsForZSet().add(&quot;zset1&quot;,tuples));
System.out.println(template.opsForZSet().range(&quot;zset1&quot;,0,-1));
[zset-1, zset-2, zset-3, zset-4, zset-5, zset-6]

&#x2F;&#x2F;Long remove(K key, Object... values);
从有序集合中移除一个或者多个元素

System.out.println(template.opsForZSet().range(&quot;zset1&quot;,0,-1));
System.out.println(template.opsForZSet().remove(&quot;zset1&quot;,&quot;zset-6&quot;));
System.out.println(template.opsForZSet().range(&quot;zset1&quot;,0,-1));
[zset-1, zset-2, zset-3, zset-4, zset-5, zset-6]
[zset-1, zset-2, zset-3, zset-4, zset-5]

&#x2F;&#x2F; Long rank(K key, Object o);
返回有序集中指定成员的排名，其中有序集成员按分数值递增(从小到大)顺序排列

System.out.println(template.opsForZSet().range(&quot;zset1&quot;,0,-1));
System.out.println(template.opsForZSet().rank(&quot;zset1&quot;,&quot;zset-2&quot;));
[zset-2, zset-1, zset-3, zset-4, zset-5]
0   &#x2F;&#x2F;表明排名第一

&#x2F;&#x2F;Set&lt;V&gt; range(K key, long start, long end);
通过索引区间返回有序集合成指定区间内的成员，其中有序集成员按分数值递增(从小到大)顺序排列

System.out.println(template.opsForZSet().range(&quot;zset1&quot;,0,-1));
[zset-2, zset-1, zset-3, zset-4, zset-5]

&#x2F;&#x2F;Long count(K key, double min, double max);
通过分数返回有序集合指定区间内的成员个数

System.out.println(template.opsForZSet().rangeByScore(&quot;zset1&quot;,0,5));
System.out.println(template.opsForZSet().count(&quot;zset1&quot;,0,5));
[zset-2, zset-1, zset-3]

&#x2F;&#x2F;Long size(K key);
获取有序集合的成员数，内部调用的就是zCard方法

System.out.println(template.opsForZSet().size(&quot;zset1&quot;));

&#x2F;&#x2F; Double score(K key, Object o);
获取指定成员的score值

System.out.println(template.opsForZSet().score(&quot;zset1&quot;,&quot;zset-1&quot;));
2.2

&#x2F;&#x2F;Long removeRange(K key, long start, long end);
移除指定索引位置的成员，其中有序集成员按分数值递增(从小到大)顺序排列

System.out.println(template.opsForZSet().range(&quot;zset2&quot;,0,-1));
System.out.println(template.opsForZSet().removeRange(&quot;zset2&quot;,1,2));
System.out.println(template.opsForZSet().range(&quot;zset2&quot;,0,-1));
[zset-1, zset-2, zset-3, zset-4]
[zset-1, zset-4]

&#x2F;&#x2F;Cursor&lt;TypedTuple&lt;V&gt;&gt; scan(K key, ScanOptions options);
遍历zset

Cursor&lt;ZSetOperations.TypedTuple&lt;Object&gt;&gt; cursor &#x3D; template.opsForZSet().scan(&quot;zzset1&quot;, ScanOptions.NONE);
    while (cursor.hasNext())&#123;
       ZSetOperations.TypedTuple&lt;Object&gt; item &#x3D; cursor.next();
       System.out.println(item.getValue() + &quot;:&quot; + item.getScore());
    &#125;
zset-1:1.0
zset-2:2.0
zset-3:3.0
zset-4:6.0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​</p>
<p>所有的对象需要序列化。在企业中，所有的 pojo 都会序列化。如果不想用 java 的序列化，就要编写自己的 redisTemplate</p>
<p>真实的开发一般都使用 json 来传递对象</p>
<pre class="line-numbers language-none"><code class="language-none">User user &#x3D; new User(&quot;123&quot;,12);
redisTemplate.opsForValue().set(&quot;user&quot;,user);
sout(redisTemplate.opsForValue().get(&quot;user&quot;))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h1>企业案例</h1>
<h5 id="高并发秒杀超卖"><a class="header-anchor" href="#高并发秒杀超卖">¶</a>高并发秒杀超卖</h5>
<pre class="line-numbers language-none"><code class="language-none">int stock &#x3D; Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;));&#x2F;&#x2F;jedis.get(&quot;stock&quot;);
if(stock&gt;0)&#123;
    int realStock &#x3D; stock-1;
    strngRedisTemplate.opsForValue().set(&quot;stock&quot;,realStock+&quot;&quot;);
    &#x2F;&#x2F;成功
&#125;else&#123;
    &#x2F;&#x2F;失败
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>解决方案：</p>
<p>setnx 若存在不操作 if not exists</p>
<p>思路：只是练习，不能实用</p>
<pre class="line-numbers language-none"><code class="language-none">String lockKey &#x3D; &quot;lockKey&quot;;
try&#123;
    &#x2F;&#x2F;Boolean result &#x3D; stringRedisTemplate.opsForValue().setIfAbsent(lockKey,&quot;hh&quot;)
      &#x2F;&#x2F;  stringRedisTemplate.expire(lockKey,10,TimeUnit.SECONDS);
    &#x2F;&#x2F;上两句应该合并才不会出错
    Boolean result &#x3D; stringRedisTemplate.opsForValue().setIfAbsent(lockKey,&quot;hh&quot;,10,TimeUnit.SECONDS);&#x2F;&#x2F;重载
    
    
        if(!result) return &quot;error&quot;;

    int stock &#x3D; Integer.parseInt(stringRedisTemplate.opsForValue().get(&quot;stock&quot;));&#x2F;&#x2F;jedis.get(&quot;stock&quot;);
    if(stock&gt;0)&#123;
        int realStock &#x3D; stock-1;
        strngRedisTemplate.opsForValue().set(&quot;stock&quot;,realStock+&quot;&quot;);
        &#x2F;&#x2F;成功
    &#125;else&#123;
        &#x2F;&#x2F;失败
    &#125;
&#125;finally&#123;
    stringRedisTemplate.delete(lockKey);
&#125;


return &quot;end&quot;;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="分布式锁："><a class="header-anchor" href="#分布式锁：">¶</a>分布式锁：</h4>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/wuzhiwei549/article/details/80692278">https://blog.csdn.net/wuzhiwei549/article/details/80692278</a></p>
<p>setnx 不支持设置时间，所以需要后面跟上 expire，但这样就非原子了，容易执行一般就挂了，死锁了。而 set 方法支持设置超时时间<code>set（lock_sale_商品ID，1，30，NX）</code>。还有个问题是如何给锁续命的问题，得用守护线程，当被守护的线程挂了，守护线程也就失去作用了。</p>
<p>其他解决方法：zk 的有序临时结点</p>
<p>Redission</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV16K411J754?p=3">https://www.bilibili.com/video/BV16K411J754?p=3</a></p>
<h3 id="热点数据"><a class="header-anchor" href="#热点数据">¶</a>热点数据</h3>
<blockquote>
<p>例如使用 Zset 数据结构，存储 Key 的访问次数 / 最后访问时间作为 Score，最后做排序，来淘汰那些最少访问的 Key。</p>
</blockquote>
<p>如果企业级应用，可以参考：[阿里云的 Redis 混合存储版][1]</p>
<h3 id="会话维持-Session"><a class="header-anchor" href="#会话维持-Session">¶</a>会话维持 Session</h3>
<p>会话维持 Session 场景，即使用 Redis 作为分布式场景下的登录中心存储应用。每次不同的服务在登录的时候，都会去统一的 Redis 去验证 Session 是否正确。但是在微服务场景，一般会考虑 Redis + JWT 做 Oauth2 模块。</p>
<blockquote>
<p>其中 Redis 存储 JWT 的相关信息主要是留出口子，方便以后做统一的防刷接口，或者做登录设备限制等。</p>
</blockquote>
<h3 id="表缓存"><a class="header-anchor" href="#表缓存">¶</a>表缓存</h3>
<p>Redis 缓存表的场景有黑名单、禁言表等。访问频率较高，即读高。根据业务需求，可以使用后台定时任务定时刷新 Redis 的缓存表数据。</p>
<h3 id="消息队列-list"><a class="header-anchor" href="#消息队列-list">¶</a>消息队列 list</h3>
<p>主要使用了 List 数据结构。<br>
List 支持在头部和尾部操作，因此可以实现简单的消息队列。</p>
<ol>
<li>发消息：在 List 尾部塞入数据。</li>
<li>消费消息：在 List 头部拿出数据。</li>
</ol>
<p>同时可以使用多个 List，来实现多个队列，根据不同的业务消息，塞入不同的 List，来增加吞吐量。</p>
<p>可视化页面：Anoter Redis DeskTop Manager</p>
<h1>企业级解决方案</h1>
<h3 id="更新一致性"><a class="header-anchor" href="#更新一致性">¶</a>更新一致性</h3>
<ul>
<li>读请求：先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。</li>
<li>写请求：先删除缓存，然后再更新数据库 (避免大量地写、却又不经常读的数据导致缓存频繁更新)。</li>
</ul>
<h3 id="缓存预热"><a class="header-anchor" href="#缓存预热">¶</a>缓存预热</h3>
<p>缓存预热就是系统启动前， 提前将相关的缓存数据直接加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据</p>
<p>场景 ：宕机：服务器启动后迅速宕机</p>
<p>问题排查<br>
\1. 请求数量较高<br>
\2. 主从之间数据吞吐量较大，数据同步操作频度较高</p>
<p>解决方案<br>
前置准备工作：</p>
<p>\1. 日常例行统计数据访问记录，启动之前统计访问频度较高的热点数据<br>
\2. 利用 LRU 数据删除策略，构建数据留存队列<br>
例如： storm 与 kafka 配合</p>
<p>准备工作：<br>
\1. 将统计结果中的数据分类，根据级别， redis 优先加载级别较高的热点数据<br>
\2. 利用分布式多服务器同时进行数据读取， 提速数据加载过程<br>
\3. 热点数据主从同时预热</p>
<p>实施：<br>
\1. 使用脚本程序固定触发数据预热过程<br>
\2. 如果条件允许， 使用了 CDN（内容分发网络），效果会更好</p>
<h3 id="缓存穿透"><a class="header-anchor" href="#缓存穿透">¶</a>缓存穿透</h3>
<p>缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，如发起为 id 为 “-1” 的数据或 id 为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。</p>
<p>查询数据库和缓存都没有的数据，每次都要查完缓存再查数据库，还是每次访问数据库，浪费了性能</p>
<ul>
<li>缓存空对象：代码简单，效果不好。查一条数据的时候，不管能不能查到，都加入到缓存。解决的是一个 id，多次访问的问题。还会导致 redis 中会有大量的空数据，占用我们的内存。</li>
<li>布隆过滤器 bloom Filter：代码复杂，效果很高。涉及到了位数据扩容。使用一个足够大的 bitmap，用于存储可能访问的 key，不存在的 key 直接被过滤；在缓存层前拦截非法请求、自动为空值添加黑名单 (同时可能要为误判的记录添加白名单). 但需要考虑布隆过滤器的维护 (离线生成 / 实时生成)。</li>
<li>在接口增增加校验，如用户鉴权校验，id 做基础校验，id&lt;=0 的直接拦截；</li>
</ul>
<p><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B-redis.png" alt="" loading="lazy"></p>
<p>一般 MySQL 默认的最大连接数在 150 左右，这个可以通过 <code>show variables like '%max_connections%';</code>命令来查看。最大连接数一个还只是一个指标，cpu，内存，磁盘，网络等无力条件都是其运行指标，这些指标都会限制其并发能力！所以，一般 3000 个并发请求就能打死大部分数据库了。</p>
<p>另外，这里多说一嘴，一般情况下我们是这样设计 key 的： <code>表名:列名:主键名:主键值</code>。</p>
<h4 id="布隆过滤器"><a class="header-anchor" href="#布隆过滤器">¶</a>布隆过滤器</h4>
<p><a target="_blank" rel="noopener" href="https://github.com/Snailclimb/JavaGuide/blob/master/docs/dataStructures-algorithms/data-structure/bloom-filter.md">https://github.com/Snailclimb/JavaGuide/blob/master/docs/dataStructures-algorithms/data-structure/bloom-filter.md</a></p>
<p>隆过滤器的主要是由一个很长的二进制向量和若干个（k 个）散列映射函数组成。因为每个元数据的存储信息值固定，而且总的二进制向量固定。所以在内存占用和查询时间上都远远超过一般的算法。当然存在一定的不准确率（可以控制）和不容易删除样本数据。</p>
<ul>
<li>
<p><strong>不支持删除</strong></p>
</li>
<li>
<p><strong>存在漏判率</strong></p>
</li>
<li>
<p>构造器 BloomFilter.create()</p>
<ul>
<li>只有两个方法：<code>put()</code>、<code>mightContain()</code></li>
</ul>
</li>
<li>
<p>先查布隆，再查缓存，再查数据库</p>
</li>
<li>
<p>size 预计插入多少数据</p>
</li>
<li>
<p>fpp 容错率 出现误判的概率是多少。不能为 0</p>
</li>
<li>
<p>bloomFilter 位数组</p>
</li>
<li>
<p>list 创建的是 object 数组</p>
</li>
<li>
<p>bit 位数组：redis 底层就是用二进制存储的。一个字符是 8 位，还可以用<code>setbit key值 第几位 0/1</code>修改指定位，就可以把 a 改成 b。同样我们还可以用 setbit 来进行扩容，这样就能设置为我们想要的 1000 位，在后面补 0</p>
</li>
<li>
<p>位数组：JVM 内存，没有持久化</p>
</li>
<li>
<p>redis：redis 内存，redis 持久化</p>
</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/img_convert/0894c7cbbf05ed70d7cc68546ee66011.png" alt="" loading="lazy"></p>
<p>二进制的向量初始状态（JAVA 中由 BitSet 实现）</p>
<p>​ <img src="https://img-blog.csdn.net/20180803155708102" alt="" loading="lazy"></p>
<p>2：添加一个样本数据</p>
<p>​ <img src="https://img-blog.csdn.net/20180803160634250" alt="" loading="lazy"></p>
<p>为了表达存储 N 个元素的集合，使用 <strong>K 个独立的函数来进行哈希运算。</strong></p>
<ul>
<li>{x1，x2……xk} 为 k 个哈希算法。</li>
<li>如果集合元素有 N1，N2……NN，</li>
</ul>
<p>N1 经过 x1 运算后得到的结果映射的位置标 1，经过 x2 运算后结果映射也标 1，已经为 1 的保持 1 不变。经过 k 次散列后，对 N1 的散列完成。</p>
<p>依次对 N2，NN 等所有数据进行散列，最终得到一个部分为 1，部分位为 0 的字节数组。当然了，这个字节数组会比较长，不然散列效果不好。</p>
<p><img src="https://img-blog.csdn.net/20170707154022077" alt="" loading="lazy"></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/fadbddc6e9e43464bbc841d44334b2d4.png" alt="" loading="lazy"></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/042526ce752d07f26409d15bd28647a2.png" alt="" loading="lazy"></p>
<p>​ 样本数据经过函数组后获得位置数组，对应改变二进制向量的值为 1。继续添加样本数据，重复上述过程。</p>
<p>那么怎么判断一个外来的元素是否已经在集合里呢，譬如已经散列了 10 亿个垃圾邮箱，现在来了一个邮箱，怎么判断它是否在这 10 亿里面呢？</p>
<p>很简单，就拿这个新来的也依次经历 x1，x2……xk 个哈希算法即可。</p>
<p>在任何一个哈希算法譬如到 x2 时，得到的映射值有 0，那就说明这个邮箱肯定不在这 10 亿内。</p>
<p>如果是一个黑名单对象，那么可以肯定的是所有映射都为 1，肯定跑不了它。也就是说是坏人，一定会被抓。</p>
<p>那么误伤是为什么呢，就是指一些非黑名单对象的值经过 k 次哈希后，也全部为 1，但它确实不是黑名单里的值，这种概率是存在的，但是是可控的。</p>
<p>​ 3：得到最终二进制向量</p>
<p>​ <img src="https://img-blog.csdn.net/20180803161053730" alt="" loading="lazy"></p>
<p>​ 4：新数据比对</p>
<p>​ <img src="https://img-blog.csdn.net/20180803161427905" alt="" loading="lazy"></p>
<p>获取到位置数组，判断二进制向量上对应位置是否为 1，只要有一个不为 1（为 0），那么就能肯定不存在。如果都为 1，那么就很可能存在。</p>
<pre class="line-numbers language-none"><code class="language-none">package com.java.base;

import java.util.ArrayList;
import java.util.BitSet;
import java.util.List;

public class TestBloomFilter &#123;

    private static final int DEFAULT_SIZE &#x3D; (1 &lt;&lt; 31) - 1; &#x2F;&#x2F; m的值 ，最大有符号int&#x2F;&#x2F;1后面31个0,；-1的补码为32个1，相加为0后面31个1
    private static final int[] seeds &#x3D; new int[] &#123; 9, 11, 13, 31, 37, 57 &#125;; &#x2F;&#x2F; 6个函数
    private BitSet bits &#x3D; new BitSet(DEFAULT_SIZE);
    private HashFunc[] func &#x3D; new HashFunc[seeds.length];
    private static String words &#x3D; &quot;abcdefghijklmnopqrstuvwxyz1234567890_&quot;; &#x2F;&#x2F;37

    &#x2F;**
	 * 创建过滤器
	 *&#x2F;
    public TestBloomFilter () &#123; &#x2F;&#x2F; 构造器
        for (int i &#x3D; 0; i &lt; seeds.length; i++) &#123;
            func[i] &#x3D; new HashFunc(DEFAULT_SIZE, seeds[i]);
        &#125;
    &#125;

    public static void main(String[] args) &#123;
        runFilter();
    &#125;

    public static void runFilter() &#123;
        TestBloomFilter  filter &#x3D; new TestBloomFilter ();
        List&lt;String&gt; existList &#x3D; new ArrayList&lt;String&gt;();
        List&lt;String&gt; noExistList &#x3D; new ArrayList&lt;String&gt;();
        int countExist &#x3D; 0;
        System.out.println(&quot;开始添加数据&quot;);
        int SampleCount &#x3D; 100000000;
        for (int i &#x3D; 0; i &lt; SampleCount; i++) &#123;
            String value &#x3D; getStr();
            if (!filter.contains(value)) &#123;
                if (existList.size() &lt; 1000) &#123;
                    existList.add(value);
                &#125;
                filter.add(value);
            &#125; else &#123; &#x2F;&#x2F; 重复值
                countExist++;
            &#125;
            if (i % 1000000 &#x3D;&#x3D; 0) &#123;
                System.out.println(&quot;已经添加:&quot; + i);
            &#125;
        &#125;&#x2F;&#x2F;数据添加完
        System.out.println(&quot;随机保存值重复了&quot; + countExist);
        System.out.println(SampleCount + &quot;比对样本值保存完毕&quot;);
        boolean flag &#x3D; true;
        while (flag) &#123;
            if (noExistList.size() &gt; 999) &#123;
                flag &#x3D; false;
            &#125; else &#123;
                String str &#x3D; getStr();
                if (!filter.contains(str)) &#123;
                    noExistList.add(str);
                &#125;
            &#125;
        &#125;
        System.out.println(&quot;1千的存在和不存在的待比对数据准备完毕&quot;);
        long start &#x3D; System.currentTimeMillis();
        System.out.println(&quot;开始比对存在字符串&quot;);
        int existCount &#x3D; 0;
        for (int i &#x3D; 0; i &lt; existList.size(); i++) &#123;
            if (filter.contains(existList.get(i))) &#123;
                existCount++;
            &#125;
        &#125;
        System.out.println(&quot;比对正确率:&quot; + existCount + &quot;&#x2F;1000&quot;);
        System.out.println(&quot;开始比对不存在字符串&quot;);
        int noExistCount &#x3D; 0;
        for (int i &#x3D; 0; i &lt; noExistList.size(); i++) &#123;
            if (!filter.contains(noExistList.get(i))) &#123;
                noExistCount++;
            &#125;
        &#125;
        System.out.println(&quot;比对正确率:&quot; + noExistCount + &quot;&#x2F;1000&quot;);
        System.out.println(&quot;比对2千数据耗时：&quot; + (System.currentTimeMillis() - start) + &quot;毫秒&quot;);
        System.out.println(&quot;over&quot;);
    &#125;

    &#x2F;**
	 * 获取随机比对字符串
	 *&#x2F;
    public static String getStr() &#123;&#x2F;&#x2F; 得到一个长度为30多的字符串
        StringBuilder sb &#x3D; new StringBuilder();
        &#x2F;&#x2F; 添加30个字母
        for (int i &#x3D; 0; i &lt; 30; i++) &#123;
            sb.append(words.charAt((int) (Math.random() * 37)));&#x2F;&#x2F; &quot;abcdefghijklmnopqrstuvwxyz1234567890_&quot;;
        &#125;
        &#x2F;&#x2F; 添加0~10W的一个整数
        sb.append(Math.random() * 100000);
        &#x2F;&#x2F; sb.append(System.nanoTime());
        return sb.toString();
    &#125;



    &#x2F;**
	 * 添加样本数据
	 * @param value
	 *&#x2F;
    public void add(String value) &#123;
        for (HashFunc f : func) &#123;
            bits.set(f.hash(value), true);
        &#125;
    &#125;

    &#x2F;**
	 * 判断是否存在
	 * @param value
	 * @return
	 *&#x2F;
    public boolean contains(String value) &#123;
        if (value &#x3D;&#x3D; null) &#123;
            return false;
        &#125;
        boolean ret &#x3D; true;
        for (HashFunc f : func) &#123;
            ret &#x3D; ret &amp;&amp; bits.get(f.hash(value));&#x2F;&#x2F;获取对象位置上的bit。0&#x2F;1
        &#125;
        return ret;
    &#125;

    &#x2F;**
	 * 哈希函数
	 *&#x2F;
    public static class HashFunc &#123;
        private int maxCount;&#x2F;&#x2F; DEFAULT_SIZE
        private int seed;&#x2F;&#x2F; seeds[i]

        public HashFunc(int maxCount, int seed) &#123;
            this.maxCount &#x3D; maxCount;
            this.seed &#x3D; seed;
        &#125;

        public int hash(String value) &#123;&#x2F;&#x2F;计算得到要放的位置
            int result &#x3D; 0;
            int len &#x3D; value.length();
            for (int i &#x3D; 0; i &lt; len; i++) &#123;
                result &#x3D; seed * result + value.charAt(i);
            &#125;
            return (maxCount - 1) &amp; result;
        &#125;
    &#125;

&#125;&#x2F;&#x2F; https:&#x2F;&#x2F;blog.csdn.net&#x2F;daobaliangbanana2&#x2F;article&#x2F;details&#x2F;81388045<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="哈希函数个数和布隆过滤器长度"><a class="header-anchor" href="#哈希函数个数和布隆过滤器长度">¶</a>哈希函数个数和布隆过滤器长度</h5>
<p>很显然，过小的布隆过滤器很快所有的 bit 位均为 1，那么查询任何值都会返回 “可能存在”，起不到过滤的目的了。布隆过滤器的长度会直接影响误报率，布隆过滤器越长其误报率越小。</p>
<p>另外，哈希函数的个数也需要权衡，个数越多则布隆过滤器 bit 位置位 1 的速度越快，且布隆过滤器的效率越低；但是如果太少的话，那我们的误报率会变高。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/05e222c654dcfd4856e1eafa99190a1d.png" alt="" loading="lazy"></p>
<ul>
<li>k 为哈希函数个数</li>
<li>m 为布隆过滤器长度</li>
<li>n 为插入的元素个数</li>
<li>p 为误报率</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/img_convert/ffa5637c59ffb4f4b0376fc15d29fcef.png" alt="" loading="lazy"></p>
<h4 id="Guava"><a class="header-anchor" href="#Guava">¶</a>Guava</h4>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u014106644/article/details/91491807">https://blog.csdn.net/u014106644/article/details/91491807</a></p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F;https:&#x2F;&#x2F;blog.csdn.net&#x2F;u014653197&#x2F;article&#x2F;details&#x2F;76397037
public class BloomFilter implements Serializable&#123;
	
	private final int[] seeds;
	private final int size;
	private final BitSet notebook;&#x2F;&#x2F;
	private final MisjudgmentRate rate;
	private final AtomicInteger useCount &#x3D; new AtomicInteger();&#x2F;&#x2F;Atomic类型
	private final Double autoClearRate;
	
	&#x2F;&#x2F;dataCount逾预期处理的数据规模
	public BloomFilter(int dataCount)&#123;
		this(MisjudgmentRate.MIDDLE, dataCount, null);&#x2F;&#x2F;重载构造
	&#125;
	
	public BloomFilter(MisjudgmentRate rate, &#x2F;&#x2F; 第一个参数是一个Enum，有个属性为int[] seeds1331
                       int dataCount, 
                       Double autoClearRate)&#123;&#x2F;&#x2F;自动清空过滤器内部信息的使用比率，传null则表示不会自动清理;&#x2F;&#x2F;当过滤器使用率达到100%时，则无论传入什么数据，都会认为在数据已经存在了;&#x2F;&#x2F;当希望过滤器使用率达到80%时自动清空重新使用，则传入0.8
        
		&#x2F;&#x2F;每个字符串需要的bit位数*总数据量
		long bitSize &#x3D; rate.seeds.length * dataCount;&#x2F;&#x2F;getSeed()
		if(bitSize&lt;0 || bitSize&gt;Integer.MAX_VALUE)&#123;
			throw new RuntimeException(&quot;位数太大溢出了，请降低误判率或者降低数据大小&quot;);
		&#125;
		this.rate &#x3D; rate;
		seeds &#x3D; rate.seeds;
		size &#x3D; (int)bitSize;
		&#x2F;&#x2F;创建一个BitSet位集合
		notebook &#x3D; new BitSet(size);
		this.autoClearRate &#x3D; autoClearRate;
	&#125;
	
	&#x2F;&#x2F;如果存在返回true,不存在返回false
	public boolean addIfNotExist(String data)&#123;
		&#x2F;&#x2F;是否需要清理
		checkNeedClear();
		&#x2F;&#x2F;seeds.length决定每一个string对应多少个bit位，每一位都有一个索引值
		&#x2F;&#x2F;给定data，求出data字符串的第一个索引值index，如果第一个index值对应的bit&#x3D;false说明，该data值不存在，则直接将所有对应bit位置为true即可;
		&#x2F;&#x2F;如果第一个index值对应bit&#x3D;true，则将index值保存，但此4时并不能说明data已经存在，
		&#x2F;&#x2F;则继续求解第二个index值，若所有index值都不存在则说明该data值不存在，将之前保存的index数组对应的bit位置为true
		int[] indexs &#x3D; new int[seeds.length];
		&#x2F;&#x2F;假定data已经存在
		boolean exist &#x3D; true;
		int index;
		for(int i&#x3D;0; i&lt;seeds.length; i++)&#123;
			&#x2F;&#x2F;计算位hash值
			indexs[i] &#x3D; index &#x3D; hash(data, seeds[i]);
			if(exist)&#123;
				&#x2F;&#x2F;如果某一位bit不存在，则说明该data不存在
				if(!notebook.get(index))&#123;
					exist &#x3D; false;
					&#x2F;&#x2F;将之前的bit位置为true
					for(int j&#x3D;0; j&lt;&#x3D;i; j++)&#123;
						setTrue(indexs[j]);
					&#125;
				&#125;
			&#125;else&#123;
				&#x2F;&#x2F;如果不存在则直接置为true
				setTrue(index);
			&#125;
		&#125;
		
		return exist;
	&#125;
	
	private int hash(String data, int seeds) &#123;
		char[] value &#x3D; data.toCharArray();
		int hash &#x3D; 0;
		if(value.length&gt;0)&#123;
			for(int i&#x3D;0; i&lt;value.length; i++)&#123;
				hash &#x3D; i * hash + value[i];
			&#125;
		&#125;
		hash &#x3D; hash * seeds % size;
		return Math.abs(hash);
	&#125;
 
	private void setTrue(int index) &#123;
		useCount.incrementAndGet();
		notebook.set(index, true);
	&#125;
 
	&#x2F;&#x2F;如果BitSet使用比率超过阈值，则将BitSet清零
	private void checkNeedClear() &#123;
		if(autoClearRate !&#x3D; null)&#123;
			if(getUseRate() &gt;&#x3D; autoClearRate)&#123;
				synchronized (this) &#123;
					if(getUseRate() &gt;&#x3D; autoClearRate)&#123;
						notebook.clear();
						useCount.set(0);
					&#125;
				&#125;
			&#125;
		&#125;
	&#125;
 
	private Double getUseRate() &#123;
		return (double)useCount.intValue()&#x2F;(double)size;
	&#125;
	
	public void saveFilterToFile(String path) &#123;
		try (ObjectOutputStream oos &#x3D; new ObjectOutputStream(new FileOutputStream(path))) &#123;
			oos.writeObject(this);
		&#125; catch (Exception e) &#123;
			throw new RuntimeException(e);
		&#125;
 
	&#125;
 
	public static BloomFilter readFilterFromFile(String path) &#123;
		try (ObjectInputStream ois &#x3D; new ObjectInputStream(new FileInputStream(path))) &#123;
			return (BloomFilter) ois.readObject();
		&#125; catch (Exception e) &#123;
			throw new RuntimeException(e);
		&#125;
	&#125;
 
	&#x2F;**
	 * 清空过滤器中的记录信息
	 *&#x2F;
	public void clear() &#123;
		useCount.set(0);
		notebook.clear();
	&#125;
 
	public MisjudgmentRate getRate() &#123;
		return rate;
	&#125;
	
	&#x2F;**
	 * 分配的位数越多，误判率越低但是越占内存
	 * 
	 * 4个位误判率大概是0.14689159766308
	 * 
	 * 8个位误判率大概是0.02157714146322
	 * 
	 * 16个位误判率大概是0.00046557303372
	 * 
	 * 32个位误判率大概是0.00000021167340
	 *
	 *&#x2F;
	public enum MisjudgmentRate &#123;
		&#x2F;&#x2F; 这里要选取质数，能很好的降低错误率
		&#x2F;**
		 * 每个字符串分配4个位
		 *&#x2F;
		VERY_SMALL(new int[] &#123; 2, 3, 5, 7 &#125;), &#x2F;&#x2F; 后面跟的参数传入构造器了
		&#x2F;**
		 * 每个字符串分配8个位
		 *&#x2F;
		SMALL(new int[] &#123; 2, 3, 5, 7, 11, 13, 17, 19 &#125;), &#x2F;&#x2F;
		&#x2F;**
		 * 每个字符串分配16个位
		 *&#x2F;
		MIDDLE(new int[] &#123; 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53 &#125;), &#x2F;&#x2F;
		&#x2F;**
		 * 每个字符串分配32个位
		 *&#x2F;
		HIGH(new int[] &#123; 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 
                        43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97,
                        101, 103, 107, 109, 113, 127, 131 &#125;);
		
		private int[] seeds;
		
		&#x2F;&#x2F;枚举类型MIDDLE构造函数将seeds数组初始化 &#x2F;&#x2F; 私有构造，防止被外部调用
		private MisjudgmentRate(int[] seeds) &#123; &#x2F;&#x2F; 前面new[]就会自动传入
			this.seeds &#x3D; seeds;
		&#125;
		
		public int[] getSeeds() &#123;
			return seeds;
		&#125;
		
		public void setSeeds(int[] seeds) &#123;
			this.seeds &#x3D; seeds;
		&#125;
	&#125;
	
	public static void main(String[] args) &#123;
		BloomFilter fileter &#x3D; new BloomFilter(7);
		System.out.println(fileter.addIfNotExist(&quot;1111111111111&quot;));
		System.out.println(fileter.addIfNotExist(&quot;2222222222222222&quot;));
		System.out.println(fileter.addIfNotExist(&quot;3333333333333333&quot;));
		System.out.println(fileter.addIfNotExist(&quot;444444444444444&quot;));
		System.out.println(fileter.addIfNotExist(&quot;5555555555555&quot;));
		System.out.println(fileter.addIfNotExist(&quot;6666666666666&quot;));
		System.out.println(fileter.addIfNotExist(&quot;1111111111111&quot;));
		&#x2F;&#x2F;fileter.saveFilterToFile(&quot;C:\\Users\\john\\Desktop\\1111\\11.obj&quot;);
		&#x2F;&#x2F;fileter &#x3D; readFilterFromFile(&quot;C:\\Users\\john\\Desktop\\111\\11.obj&quot;);
		System.out.println(fileter.getUseRate());
		System.out.println(fileter.addIfNotExist(&quot;1111111111111&quot;));
	&#125;
	
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-none"><code class="language-none">&lt;dependency&gt;
    &lt;groupId&gt;com.google.guava&lt;&#x2F;groupId&gt;
    &lt;artifactId&gt;guava&lt;&#x2F;artifactId&gt;
    &lt;version&gt;25.1-jre&lt;&#x2F;version&gt;
&lt;&#x2F;dependency&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-none"><code class="language-none">public class Test1 &#123;

    private static int size &#x3D; 1000000;

    private static BloomFilter&lt;Integer&gt; bloomFilter &#x3D; BloomFilter.create(Funnels.integerFunnel(), size);
    &#x2F;&#x2F; 自定义错误率
    &#x2F;&#x2F; private static BloomFilter&lt;Integer&gt; bloomFilter &#x3D; BloomFilter.create(Funnels.integerFunnel(), size, 0.01);

    public static void main(String[] args) &#123;
        for (int i &#x3D; 0; i &lt; size; i++) &#123;
            bloomFilter.put(i);
        &#125;

        long startTime &#x3D; System.nanoTime(); &#x2F;&#x2F; 获取开始时间
        &#x2F;&#x2F;判断这一百万个数中是否包含29999这个数
        if (bloomFilter.mightContain(29999)) &#123;
            System.out.println(&quot;命中了&quot;);
        &#125;
        long endTime &#x3D; System.nanoTime();   &#x2F;&#x2F; 获取结束时间
        System.out.println(&quot;程序运行时间： &quot; + (endTime - startTime) + &quot;纳秒&quot;);
    &#125;

&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="分布式自定义"><a class="header-anchor" href="#分布式自定义">¶</a>分布式自定义</h5>
<h5 id="redis-实现类"><a class="header-anchor" href="#redis-实现类">¶</a>redis 实现类</h5>
<pre class="line-numbers language-none"><code class="language-none">@Component
public class RedisUtil &#123;
    @Autowired
    private RedisTemplate redisTemplate;

    &#x2F;**
     * 设置bitMap
     *
     * @param key    bitMap key
     * @param offset 设置在多少位
     * @param flag   设置的值
     *&#x2F;
    public void setBit(String key, Long offset, Boolean flag) &#123;
        redisTemplate.opsForValue().setBit(key, offset, flag);
    &#125;

    &#x2F;**
     * 获取bitMap指定位置的值
     *
     * @param key    bitMap key
     * @param offset 位置
     *&#x2F;
    public Boolean getBit(String key, Long offset) &#123;
        return redisTemplate.opsForValue().getBit(key, offset);
    &#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="建立-hash-函数所需要的-seed"><a class="header-anchor" href="#建立-hash-函数所需要的-seed">¶</a>建立 hash 函数所需要的 seed</h5>
<pre class="line-numbers language-none"><code class="language-none">public enum CorrectRatio &#123;
    &#x2F;**
     * 32位代表一个数
     *&#x2F;
    HIGH(new int[]&#123;2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 
                   41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 
                   89, 97,101, 103, 107, 109, 113, 127, 131&#125;);

    private int[] seed;

    CorrectRatio(int[] size) &#123;
        this.seed &#x3D; size;
    &#125;

    public int[] getSeed() &#123;
        return seed;
    &#125;

    public void setSeed(int[] seed) &#123;
        this.seed &#x3D; seed;
    &#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>布隆过滤器</p>
<pre class="line-numbers language-none"><code class="language-none">public class BoolmfilterForRedis &#123;

    @Autowired
    private RedisUtil redisUtil;

    &#x2F;**
     * BKRD Hash算法seed
     *&#x2F;
    private int[] seed;

    &#x2F;**
     * hash方法 数组
     *&#x2F;
    private HashFunction[] hashFunction;

    &#x2F;**
     * 所需bitMap 位数 为2的幂次方
     *&#x2F;
    private Long cap;

    private static final String bitMapPrefix &#x3D; &quot;bitMapForBoolmfilter&quot;;


    &#x2F;**
     * 初始化容量 redis中位图的容量
     *
     * @param n 输入量
     *&#x2F;
    private void initCap(CorrectRatio correctRatio, Long n) &#123;
        &#x2F;*
         * 如果correctRatio.getSeed().length 为32 即有32个hash函数对一个数做映射
         * 那么 bitSet中 32位代表一个数 所需要的最大容量为32*n
         *&#x2F;
        this.cap &#x3D; correctRatio.getSeed().length * n;
    &#125;


    &#x2F;**
     * 构造 hash函数
     *
     * @param correctRatio
     *&#x2F;
    private void createHashFunctions(CorrectRatio correctRatio) &#123;
        this.seed &#x3D; correctRatio.getSeed();
        this.hashFunction &#x3D; new HashFunction[this.seed.length];
        for (int i &#x3D; 0; i &lt; seed.length; i++) &#123;
            this.hashFunction[i] &#x3D; new HashFunction(seed[i], this.cap);
        &#125;
    &#125;

    &#x2F;**
     * 初始化
     *
     * @param correctRatio
     * @param n
     *&#x2F;
    public BoolmfilterForRedis(CorrectRatio correctRatio, Long n) &#123;
        initCap(correctRatio, n);
        createHashFunctions(correctRatio);
    &#125;

    &#x2F;**
     * 添加
     *
     * @param value
     *&#x2F;
    public void add(String value) &#123;
        for (int i &#x3D; 0; i &lt; seed.length; i++) &#123;
            redisUtil.setBit(bitMapPrefix, this.hashFunction[i].hash(value), true);
        &#125;
    &#125;

    &#x2F;**
     * 包含
     *
     * @param value
     * @return
     *&#x2F;
    public Boolean contain(String value) &#123;
        boolean flag &#x3D; true;
        for (int i &#x3D; 0; i &lt; seed.length; i++) &#123;
            flag &#x3D; flag &amp;&amp; redisUtil.getBit(bitMapPrefix, this.hashFunction[i].hash(value));
            if (!flag) &#123;
                return false;
            &#125;
        &#125;
        return flag;
    &#125;


    &#x2F;**
     * hash算法
     *&#x2F;
    private class HashFunction &#123;
        private Integer seed;

        private Long cap;

        public HashFunction(Integer seed, Long cap) &#123;
            this.seed &#x3D; seed;
            this.cap &#x3D; cap;
        &#125;

        public Long hash(String value) &#123;
            Integer result &#x3D; 0;
            for (int i &#x3D; 0; i &lt; value.length(); i++) &#123;
                result &#x3D; result * this.seed + value.charAt(i);
            &#125;
            &#x2F;&#x2F;求余数 防止redis中bitMap无限膨胀  类似循环队列 可以防止系统OOM
            return result &amp; (cap - 1);
        &#125;
    &#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>由于初始化不能通过无参构造函数 所以还要配置</p>
<pre class="line-numbers language-none"><code class="language-none">@Configuration
public class BoolmfilterConfig &#123;
    @Value(&quot;$&#123;boolmfilter.inputnum.pow&#125;&quot;)
    private Integer pow;

    @Bean
    public BoolmfilterForRedis getBoolmfilter()&#123;
        &#x2F;&#x2F;输入数据量cap&#x3D;输入数据量 * hash个数  
        &#x2F;&#x2F; hash个数就是seed数 所以要求seed个数为2的幂次方 输入量也要是2的幂次方 详情参考hashMap容量为什么为2的幂次方
        BoolmfilterForRedis boolmfilter&#x3D;new BoolmfilterForRedis(CorrectRatio.HIGH,(long)1&lt;&lt;pow);
        return boolmfilter;
    &#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="测试"><a class="header-anchor" href="#测试">¶</a>测试</h5>
<p>测试前准备 1000uuid 存入</p>
<pre class="line-numbers language-none"><code class="language-none">@RunWith(SpringRunner.class)
@SpringBootTest
public class GatewayApplicationTests &#123;
    @Autowired
    private BoolmfilterForRedis boolmfilter;
    @Autowired
    private RedisTemplate redisTemplate;

    @Test
    public void contextLoads() &#123;
        &#x2F;&#x2F;1.先存入1000个uuid
        for (int i&#x3D;0;i&lt;1000;i++) &#123;
            redisTemplate.opsForList().rightPush(&quot;xx&quot;, UUID.randomUUID().toString());
        &#125;
    &#125;

&#125;

&#x2F;&#x2F; 2.将数据填入boolmfilter
List&lt;String&gt; xx &#x3D; redisTemplate.opsForList().range(&quot;bitMapForBoolmfilter&quot;, 0L, 100L);
xx.forEach(s -&gt; &#123;
    boolmfilter.add(s);
&#125;);

&#x2F;&#x2F;3.测试通过率 由于uuid基本不重复 所以这里生成的uuid通过率在不误判的情况下应为0
int count &#x3D; 0;
for (int i &#x3D; 0; i &lt; 10000; i++) &#123;
    boolean contains &#x3D; boolmfilter.contain(UUID.randomUUID().toString());
    if (contains &#x3D;&#x3D; true) &#123;
        count++;
    &#125;
&#125;
System.out.println(count);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>数据库服务器崩溃（ 3）<br>
\1. 系统平稳运行过程中<br>
\2. 应用服务器流量随时间增量较大<br>
\3. Redis 服务器命中率随时间逐步降低<br>
\4. Redis 内存平稳，内存无压力<br>
\5. Redis 服务器 CPU 占用激增<br>
\6. 数据库服务器压力激增<br>
\7. 数据库崩溃</p>
<p>问题排查<br>
\1. Redis 中大面积出现未命中<br>
\2. 出现非正常 URL 访问</p>
<p>问题分析<br>
 获取的数据在数据库中也不存在，数据库查询未得到对应数据<br>
 Redis 获取到 null 数据未进行持久化，直接返回<br>
 下次此类数据到达重复上述过程<br>
 出现黑客攻击服务器</p>
<p>解决方案（术）<br>
\1. 缓存 null<br>
对查询结果为 null 的数据进行缓存（长期使用，定期清理）， 设定短时限，例如 30-60 秒， 最高 5 分钟</p>
<p>\3. 实施监控<br>
实时监控 redis 命中率（ 业务正常范围时，通常会有一个波动值）与 null 数据的占比<br>
 非活动时段波动：通常检测 3-5 倍，超过 5 倍纳入重点排查对象<br>
 活动时段波动：通常检测 10-50 倍， 超过 50 倍纳入重点排查对象<br>
根据倍数不同，启动不同的排查流程。然后使用黑名单进行防控（运营）<br>
\4. key 加密<br>
问题出现后，临时启动防灾业务 key，对 key 进行业务层传输加密服务，设定校验程序，过来的 key 校验<br>
例如每天随机分配 60 个加密串，挑选 2 到 3 个，混淆到页面数据 id 中，发现访问 key 不满足规则，驳回数据访问</p>
<p>总结<br>
缓存击穿访问了不存在的数据，跳过了合法数据的 redis 数据缓存阶段，每次访问数据库，导致对数据库服务器造成压力。通常此类数据的出现量是一个较低的值，当出现此类情况以毒攻毒，并及时报警。应对策略应该在临时预案防范方面多做文章。<br>
无论是黑名单还是白名单，都是对整体系统的压力，警报解除后尽快移除。</p>
<h3 id="缓存击穿"><a class="header-anchor" href="#缓存击穿">¶</a>缓存击穿</h3>
<p>缓存雪崩和缓存击穿不同的是：</p>
<ul>
<li><strong>缓存击穿指并发查同一条数据</strong>。缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力</li>
<li><strong>缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。</strong></li>
</ul>
<p><strong>解决方案：</strong></p>
<ul>
<li>设置热点数据永远不过期。</li>
<li>加互斥锁：业界比较常用的做法，是使用 mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去 load db 去数据库加载，而是先使用缓存工具的某些带成功操作返回值的操作（比如 Redis 的<code>SETNX</code>或者 Memcache 的<code>ADD</code>）去 set 一个 mutex key，当操作返回成功时，再进行 load db 的操作并回设缓存；否则，就重试整个 get 缓存的方法。<br>
互斥锁参考代码如下：</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none">public static String getData(String key)throws InterruptedException&#123;
    &#x2F;&#x2F;从缓存中读取数据
    String result &#x3D; getDataFromRedis(key);
    &#x2F;&#x2F;如果缓存中不存在数据
    if(result&#x3D;&#x3D;null)&#123;
        &#x2F;&#x2F;去获取锁，获取成功，去数据库取数据
        if(reenLock.tryLock())&#123;&#x2F;&#x2F;redisLock.lock(String.valueOf(id))
            &#x2F;&#x2F;从数据库获取数据
            result &#x3D; getDataFromMysql(key);
            &#x2F;&#x2F;更新缓存数据
            if(result!&#x3D;null)&#123;
                setDataToCache(key,result);
            &#125;
            &#x2F;&#x2F;释放锁
            reenLock.unlock();
        &#125;else&#123;&#x2F;&#x2F;获取锁失败
            &#x2F;&#x2F;暂停100ms再去缓存再去缓存获取数据
            Thread.sleep(100);
            result &#x3D; getData(key);
        &#125;
    &#125;
    return result;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>说明：</p>
<pre class="line-numbers language-none"><code class="language-none">1）缓存中有数据，直接走上述代码13行后就返回结果了

2）缓存中没有数据，第1个进入的线程，获取锁并从数据库去取数据，没释放锁之前，其他并行进入的线程会等待100ms，再重新去缓存取数据。这样就防止都去数据库重复取数据，重复往缓存中更新数据情况出现。

3）当然这是简化处理，理论上如果能根据key值加锁就更好了，就是线程A从数据库取key1的数据并不妨碍线程B取key2的数据，上面代码明显做不到这点。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol>
<li>使用互斥锁 (mutex key)</li>
</ol>
<p>SETNX，是「SET if Not eXists」的缩写，也就是只有不存在的时候才设置，可以利用它来实现锁的效果。在 redis2.6.1 之前版本未实现 setnx 的过期时间，所以这里给出两种版本代码参考：</p>
<pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F;2.6.1前单机版本锁
String get(String key) &#123;  
    String value &#x3D; redis.get(key);  
    if (value  &#x3D;&#x3D; null) &#123;  
        if (redis.setnx(key_mutex, &quot;1&quot;)) &#123;  
            &#x2F;&#x2F; 3 min timeout to avoid mutex holder crash  
            redis.expire(key_mutex, 3 * 60) ;
            value &#x3D; db.get(key);  
            redis.set(key, value);  
            redis.delete(key_mutex);  
        &#125; else &#123;  
            &#x2F;&#x2F;其他线程休息50毫秒后重试  
            Thread.sleep(50);     
            get(key);  
        &#125;  
    &#125;  
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>最新版本代码：</p>
<pre class="line-numbers language-none"><code class="language-none">public String get(key) &#123;
    String value &#x3D; redis.get(key);
    if (value &#x3D;&#x3D; null) &#123; &#x2F;&#x2F;代表缓存值过期
        &#x2F;&#x2F;设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db
        if (redis.setnx(key_mutex, 1, 3 * 60) &#x3D;&#x3D; 1) &#123;  &#x2F;&#x2F;代表设置成功
            value &#x3D; db.get(key);
            redis.set(key, value, expire_secs);
            redis.del(key_mutex);
        &#125; else &#123;  &#x2F;&#x2F;这个时候代表同时候的其他线程已经load db并回设到缓存了，这时候重试获取缓存值即可
            sleep(50);
            get(key);  &#x2F;&#x2F;重试
        &#125;
    &#125; else &#123;
        return value;      
    &#125;
&#125;
memcache代码：
    if (memcache.get(key) &#x3D;&#x3D; null) &#123;  
        &#x2F;&#x2F; 3 min timeout to avoid mutex holder crash  
        if (memcache.add(key_mutex, 3 * 60 * 1000) &#x3D;&#x3D; true) &#123;  
            value &#x3D; db.get(key);  
            memcache.set(key, value);  
            memcache.delete(key_mutex);  
        &#125; else &#123;  
            sleep(50);  
            retry();  
        &#125;  
    &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>2 “提前” 使用互斥锁 (mutex key)：<br>
在 value 内部设置 1 个超时值 (timeout1), timeout1 比实际的 memcache timeout(timeout2) 小。当从 cache 读取到 timeout1 发现它已经过期时候，马上延长 timeout1 并重新设置到 cache。然后再从数据库加载数据并设置到 cache 中。伪代码如下：</p>
<pre class="line-numbers language-none"><code class="language-none">v &#x3D; memcache.get(key);  
if (v &#x3D;&#x3D; null) &#123;  
    if (memcache.add(key_mutex, 3 * 60 * 1000) &#x3D;&#x3D; true) &#123;  
        value &#x3D; db.get(key);  
        memcache.set(key, value);  
        memcache.delete(key_mutex);  
    &#125; else &#123;  
        sleep(50);  
        retry();  
    &#125;  
&#125; else &#123;  
    if (v.timeout &lt;&#x3D; now()) &#123;  
        if (memcache.add(key_mutex, 3 * 60 * 1000) &#x3D;&#x3D; true) &#123;  
            &#x2F;&#x2F; extend the timeout for other threads  
            v.timeout +&#x3D; 3 * 60 * 1000;  
            memcache.set(key, v, KEY_TIMEOUT * 2);  
            &#x2F;&#x2F; load the latest value from db  
            v &#x3D; db.get(key);  
            v.timeout &#x3D; KEY_TIMEOUT;  
            memcache.set(key, value, KEY_TIMEOUT * 2);  
            memcache.delete(key_mutex);  
        &#125; else &#123;  
            sleep(50);  
            retry();  
        &#125;  
    &#125;  
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol start="3">
<li>“永远不过期”：<br>
这里的 “永远不过期” 包含两层意思：</li>
</ol>
<p>(1) 从 redis 上看，确实没有设置过期时间，这就保证了，不会出现热点 key 过期问题，也就是 “物理” 不过期。</p>
<p>(2) 从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在 key 对应的 value 里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是 “逻辑” 过期</p>
<p>从实战看，这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程 (非构建缓存的线程) 可能访问的是老数据，但是对于一般的互联网功能来说这个还是可以忍受。</p>
<pre class="line-numbers language-none"><code class="language-none">String get(final String key) &#123;  
    V v &#x3D; redis.get(key);  
    String value &#x3D; v.getValue();     
    long timeout &#x3D; v.getTimeout();  
    if (v.timeout &lt;&#x3D; System.currentTimeMillis()) &#123;  
        &#x2F;&#x2F; 异步更新后台异常执行  
        threadPool.execute(new Runnable() &#123;  
            public void run() &#123;  
                String keyMutex &#x3D; &quot;mutex:&quot; + key;  
                if (redis.setnx(keyMutex, &quot;1&quot;)) &#123;  
                    &#x2F;&#x2F; 3 min timeout to avoid mutex holder crash  
                    redis.expire(keyMutex, 3 * 60);  
                    String dbValue &#x3D; db.get(key);  
                    redis.set(key, dbValue);  
                    redis.delete(keyMutex);  
                &#125;  
            &#125;  
        &#125;);  
    &#125;  
    return value;  
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol start="4">
<li>资源保护：<br>
采用 netflix 的 hystrix，可以做资源的隔离保护主线程池，如果把这个应用到缓存的构建也未尝不可。</li>
<li>四种解决方案：没有最佳只有最合适</li>
</ol>
<table><thead><tr><th>解决方案</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>简单分布式互斥锁（mutex key）</td><td>1. 思路简单 2. 保证一致性</td><td>1. 代码复杂度增大 2. 存在死锁的风险 3. 存在线程池阻塞的风险</td></tr><tr><td>“提前” 使用互斥锁</td><td>1. 保证一致性</td><td>同上</td></tr><tr><td>不过期 (本文)</td><td>1. 异步构建缓存，不会阻塞线程池</td><td>1. 不保证一致性。2. 代码复杂度增大 (每个 value 都要维护一个 timekey)。3. 占用一定的内存空间 (每个 value 都要维护一个 timekey)。</td></tr><tr><td>资源隔离组件 hystrix(本文)</td><td>1. hystrix 技术成熟，有效保证后端。2. hystrix 监控强大。</td><td>1. 部分访问存在降级策略。</td></tr></tbody></table>
<p>数据库服务器崩溃（ 2）<br>
\1. 系统平稳运行过程中<br>
\2. 数据库连接量瞬间激增<br>
\3. Redis 服务器无大量 key 过期<br>
\4. Redis 内存平稳，无波动<br>
\5. Redis 服务器 CPU 正常<br>
\6. 数据库崩溃</p>
<p>问题排查<br>
\1. Redis 中某个 key 过期，该 key 访问量巨大<br>
\2. 多个数据请求从服务器直接压到 Redis 后，均未命中<br>
\3. Redis 在短时间内发起了大量对数据库中同一数据的访问</p>
<p>问题分析<br>
 单个 key 高热数据<br>
 key 过期</p>
<p>解决方案（术）<br>
\1. 预先设定<br>
以电商为例，每个商家根据店铺等级， 指定若干款主打商品，在购物节期间， 加大此类信息 key 的过期时长<br>
注意：购物节不仅仅指当天，以及后续若干天，访问峰值呈现逐渐降低的趋势<br>
\2. 现场调整<br>
监控访问量，对自然流量激增的数据延长过期时间或设置为永久性 key<br>
\3. 后台刷新数据<br>
启动定时任务，高峰期来临之前， 刷新数据有效期， 确保不丢失<br>
\4. 二级缓存<br>
设置不同的失效时间，保障不会被同时淘汰就行<br>
\5. 加锁<br>
分布式锁，防止被击穿，但是要注意也是性能瓶颈，慎重！</p>
<p>总结<br>
缓存击穿就是单个高热数据过期的瞬间，数据访问量较大，未命中 redis 后，发起了大量对同一数据的数据库访问，导致对数据库服<br>
务器造成压力。应对策略应该在业务数据分析与预防方面进行，配合运行监控测试与即时调整策略，毕竟单个 key 的过期监控难度<br>
较高，配合雪崩处理策略即可</p>
<h3 id="缓存雪崩"><a class="header-anchor" href="#缓存雪崩">¶</a>缓存雪崩</h3>
<p>大量的 key 设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时 DB 请求量大、压力骤增，引起雪崩。</p>
<p>缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至 down 机。</p>
<p>缓存雪崩和缓存击穿不同的是， <strong>缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。</strong></p>
<p>缓存崩溃时<strong>请求会直接落到数据库上</strong>，很可能由于无法承受大量的并发请求而崩溃，此时如果只重启数据库，或因为缓存重启后没有数据，新的流量进来很快又会把数据库击倒。</p>
<p>解决方案：</p>
<ul>
<li>规避雪崩：缓存数据的<strong>过期时间设置随机</strong>，防止同一时间大量数据过期现象发生。</li>
<li>如果缓存数据库是<strong>分布式部署</strong>，将热点数据均匀分布在不同缓存数据库中。</li>
<li>设置热点数据永远不过期。</li>
<li>出现雪崩：降级 熔断</li>
<li>事前：尽量保证整个 redis 集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略。</li>
<li>事中：本地 ehcache 缓存 + hystrix 限流 &amp; 降级，避免 MySQL 崩掉</li>
<li>事后：利用 redis 持久化机制保存的数据尽快恢复缓存</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/img_convert/89ed34304c24266daa788ad41de60066.png" alt="" loading="lazy"></p>
<p>数据库服务器崩溃（ 1）<br>
\1. 系统平稳运行过程中，忽然数据库连接量激增<br>
\2. 应用服务器无法及时处理请求<br>
\3. 大量 408， 500 错误页面出现<br>
\4. 客户反复刷新页面获取数据<br>
\5. 数据库崩溃<br>
\6. 应用服务器崩溃<br>
\7. 重启应用服务器无效<br>
\8. Redis 服务器崩溃<br>
\9. Redis 集群崩溃<br>
\10. 重启数据库后再次被瞬间流量放倒</p>
<p>问题排查<br>
\1. 在一个较短的时间内，缓存中较多的 key 集中过期<br>
\2. 此周期内请求访问过期的数据， redis 未命中， redis 向数据库获取数据<br>
\3. 数据库同时接收到大量的请求无法及时处理<br>
\4. Redis 大量请求被积压，开始出现超时现象<br>
\5. 数据库流量激增，数据库崩溃<br>
\6. 重启后仍然面对缓存中无数据可用<br>
\7. Redis 服务器资源被严重占用， Redis 服务器崩溃<br>
\8. Redis 集群呈现崩塌，集群瓦解<br>
\9. 应用服务器无法及时得到数据响应请求，来自客户端的请求数量越来越多，应用服务器崩溃<br>
\10. 应用服务器， redis，数据库全部重启，效果不理想</p>
<p>问题分析<br>
 短时间范围内<br>
 大量 key 集中过期</p>
<p>解决方案（道）<br>
\1. 更多的页面静态化处理<br>
\2. 构建多级缓存架构<br>
Nginx 缓存 + redis 缓存 + ehcache 缓存<br>
\3. 检测 Mysql 严重耗时业务进行优化<br>
对数据库的瓶颈排查：例如超时查询、耗时较高事务等<br>
\4. 灾难预警机制<br>
监控 redis 服务器性能指标<br>
 CPU 占用、 CPU 使用率<br>
 内存容量<br>
 查询平均响应时间<br>
 线程数<br>
\5. 限流、降级<br>
短时间范围内牺牲一些客户体验，限制一部分请求访问，降低应用服务器压力，待业务低速运转后再逐步放开访问</p>
<p>解决方案（术）<br>
\1. LRU 与 LFU 切换<br>
\2. 数据有效期策略调整<br>
 根据业务数据有效期进行分类错峰， A 类 90 分钟， B 类 80 分钟， C 类 70 分钟<br>
 过期时间使用固定时间 + 随机值的形式，稀释集中到期的 key 的数量<br>
\3. 超热数据使用永久 key<br>
\4. 定期维护（自动 + 人工）<br>
对即将过期数据做访问量分析，确认是否延时，配合访问量统计，做热点数据的延时<br>
\5. 加锁<br>
慎用！</p>
<p>总结<br>
缓存雪崩就是瞬间过期数据量太大，导致对数据库服务器造成压力。如能够有效避免过期时间集中，可以有效解决雪崩现象的出现（约 40%），配合其他策略一起使用，并监控服务器的运行数据，根据运行记录做快速调整。</p>
<h3 id="数据一致性问题"><a class="header-anchor" href="#数据一致性问题">¶</a>数据一致性问题</h3>
<p>缓存与数据库双写时的数据一致性?</p>
<blockquote>
<p>一般情况下我们都是这样使用缓存的：先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。这种方式很明显会存在缓存和数据库的数据不一致的情况。</p>
</blockquote>
<p>你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？</p>
<p>一般来说，就是如果你的系统不是严格要求缓存 + 数据库必须一致性的话，缓存可以稍微的跟数据库偶尔有不一致的情况，最好不要做这个方案，读请求和写请求串行化，串到一个内存队列里去，这样就可以保证一定不会出现不一致的情况</p>
<p>串行化之后，就会导致系统的吞吐量会大幅度的降低，用比正常情况下多几倍的机器去支撑线上的一个请求。</p>
<p>更多内容可以查看：<a target="_blank" rel="noopener" href="https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-consistence.md">https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-consistence.md</a></p>
<p>当更新数据时，如更新某商品的库存，当前商品的库存是 100，现在要更新为 99，先更新数据库更改成 99，然后删除缓存，发现删除缓存失败了，这意味着数据库存的是 99，而缓存是 100，这导致数据库和缓存不一致。</p>
<p>解决方法：<br>
这种情况应该是<strong>先删除缓存，然后再更新数据库，</strong></p>
<ul>
<li>如果删除缓存失败，那就不要更新数据库，</li>
<li>如果说删除缓存成功，而更新数据库失败，那查询的时候只是从数据库里查了旧的数据而已，这样就能保持数据库与缓存的一致性。</li>
</ul>
<p>场景：（删完缓存改数据库时被别人又增内存了）在高并发的情况下，如果当删除完缓存的时候，这时 A 去更新数据库，但 A 还没有更新完，另外一个请求 B 来查询数据，B 发现缓存里没有，B 就去数据库里查，还是以上面商品库存为例，如果数据库中产品的库存是 100，那么查询到的库存是 100，B 然后插入缓存，插入完缓存后，原来那个更新数据库的线程把数据库更新为了 99，导致数据库与缓存不一致的情况</p>
<p>解决方法：创建队列让更新操作排队。<br>
遇到这种情况，可以用队列的去解决这个问，<strong>创建几个队列</strong>，如 20 个，根据商品的 ID 去做 hash 值，然后对队列个数取摸，当有数据更新请求时，先把它丢到队列里去，当更新完后在从队列里去除，如果在更新的过程中，遇到以上场景，先去缓存里看下有没有数据，如果没有，<strong>可以先去队列里看是否有相同商品 ID 在做更新，如果有也把查询的请求发送到队列里去，然后同步等待缓存更新完成</strong>。</p>
<p>这里有一个优化点，如果发现队列里有一个查询请求了，那么就不要放新的查询操作进去了，用一个 while（true）循环去查询缓存，循环个 200MS 左右，如果缓存里还没有则直接取数据库的旧数据，一般情况下是可以取到的。</p>
<p>在高并发下解决场景二要注意的问题：</p>
<p>（1）读请求时长阻塞</p>
<p>由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时间内返回，该解决方案最大的风险在于可能数据更新很频繁，导致队列中挤压了大量的更新操作在里面，然后读请求会发生大量的超时，最后导致大量的请求直接走数据库，像遇到这种情况，一般要做好足够的压力测试，如果压力过大，需要根据实际情况添加机器。</p>
<p>（2）请求并发量过高</p>
<p>这里还是要做好压力测试，多模拟真实场景，并发量在最高的时候 QPS 多少，扛不住就要多加机器，还有就是做好读写比例是多少</p>
<p>（3）多服务实例部署的请求路由</p>
<p>可能这个服务部署了多个实例，那么必须保证说，执行数据更新操作，以及执行缓存更新操作的请求，都通过 nginx 服务器路由到相同的服务实例上</p>
<p>（4）热点商品的路由问题，导致请求的倾斜</p>
<p>某些商品的读请求特别高，全部打到了相同的机器的相同丢列里了，可能造成某台服务器压力过大，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以更新频率不是太高的话，这个问题的影响并不是很大，但是确实有可能某些服务器的负载会高一些。</p>
<p><img src="https://img-blog.csdn.net/20170903171144693" alt="" loading="lazy"></p>
<h3 id="并发竞争-Key"><a class="header-anchor" href="#并发竞争-Key">¶</a>并发竞争 Key</h3>
<p>所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对一个 key 进行操作，但是最后执行的顺序和我们期望的顺序不同，这样也就导致了结果的不同！</p>
<p>推荐一种方案：分布式锁（zookeeper 和 redis 都可以实现分布式锁）。（如果不存在 Redis 的并发竞争 Key 问题，不要使用分布式锁，这样会影响性能）</p>
<p>基于 zookeeper 临时有序节点可以实现的分布式锁。大致思想为：每个客户端对某个方法加锁时，在 zookeeper 上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁。</p>
<p>在实践中，当然是从以可靠性为主。所以首推 Zookeeper。</p>
<p>参考：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/8bddd381de06">https://www.jianshu.com/p/8bddd381de06</a></li>
</ul>
<h3 id="性能指标监控"><a class="header-anchor" href="#性能指标监控">¶</a>性能指标监控</h3>
<p>监控指标<br>
 性能指标： Performance<br>
 内存指标： Memory<br>
 基本活动指标： Basic activity<br>
 持久性指标： Persistence<br>
 错误指标： Error</p>
<p>监控指标<br>
 性能指标： Performance</p>
<table><thead><tr><th>Name</th><th>描述</th></tr></thead><tbody><tr><td>latency</td><td>Redis 响应一个请求的时间</td></tr><tr><td>instantaneous_ops_per_sec</td><td>平均每秒处理请求次数</td></tr><tr><td>hit rate</td><td>缓存命中率（计算出来的）</td></tr></tbody></table>
<p>监控指标<br>
 内存指标： Memory</p>
<table><thead><tr><th>name</th><th>描述</th></tr></thead><tbody><tr><td>used_memory</td><td>已使用内存</td></tr><tr><td>mem_fragmentation_ratio</td><td>内存碎片率</td></tr><tr><td>evited_keys</td><td>由于最大内存限制被移除的 key 值</td></tr><tr><td>blocked_clients</td><td>由于 BLPOP,BRPOP,BRPOPLPUSH 而被阻塞的客户端</td></tr></tbody></table>
<p>监控指标<br>
 基本活动指标： Basic activity</p>
<table><thead><tr><th>Name</th><th>描述</th></tr></thead><tbody><tr><td>connected_clients</td><td>客户端连接数</td></tr><tr><td>connected_slaves</td><td>slave 数量</td></tr><tr><td>master_last_io_seconds_ago</td><td>最近一次主从交互之后的秒数</td></tr><tr><td>keyspace</td><td>数据库中的 key 值总数</td></tr></tbody></table>
<p>监控指标<br>
 持久性指标： Persistence</p>
<table><thead><tr><th>name</th><th>描述</th></tr></thead><tbody><tr><td>rdb_last_save_time</td><td>最后一次持久化保存到磁盘的时间戳</td></tr><tr><td>rdb_changes_since_last_save</td><td>自最后一次持久化以来数据库的更改次数</td></tr></tbody></table>
<p>监控指标<br>
 错误指标： Error</p>
<table><thead><tr><th>name</th><th></th></tr></thead><tbody><tr><td>rejected_connections</td><td>由于达到 maxclient 限制而被拒绝的连接数</td></tr><tr><td>keyspace_misses</td><td>key 值查找失败（没有命中）次数</td></tr><tr><td>master_link_down_since_seconds</td><td>主从断开的持续时间（秒）</td></tr></tbody></table>
<p>监控方式<br>
 工具<br>
 Cloud Insight Redis<br>
 Prometheus<br>
 Redis-stat<br>
 Redis-faina<br>
 RedisLive<br>
 zabbix<br>
 命令<br>
 benchmark<br>
 redis cli<br>
 monitor<br>
 showlog</p>
<p>benchmark</p>
<p> 命令</p>
<p>redis-benchmark [-h] [-p ] [-c ] [-n &lt;requests]&gt; [-k ]</p>
<p> 范例 1</p>
<p>redis-benchmark</p>
<p>说明： 50 个连接， 10000 次请求对应的性能<br>
 范例 2</p>
<p>redis-benchmark -c 100 -n 5000</p>
<p>说明： 100 个连接， 5000 次请求对应的性能</p>
<p>monitor</p>
<p> 命令</p>
<p>monitor</p>
<p>打印服务器调试信息</p>
<p>showlong</p>
<p> 命令</p>
<p>showlong [operator]</p>
<p> get ：获取慢查询日志<br>
 len ：获取慢查询日志条目数<br>
 reset ：重置慢查询日志<br>
 相关配置</p>
<pre class="line-numbers language-none"><code class="language-none">slowlog-log-slower-than 1000 #设置慢查询的时间下线，单位：微妙
slowlog-max-len 100 #设置慢查询命令对应的日志显示长度，单位：命令数<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h1>常见面试题</h1>
<h3 id="为啥-Redis-那么快？"><a class="header-anchor" href="#为啥-Redis-那么快？">¶</a><strong>为啥 Redis 那么快？</strong></h3>
<p><img src="https://img-blog.csdnimg.cn/img_convert/ddbb9433676fea2ff9f528d493e5312c.png" alt="" loading="lazy"></p>
<p><strong>Redis</strong> 采用的是基于内存的采用的是单进程单线程模型的 KV 数据库，由 C 语言编写，官方提供的数据是可以达到 100000 + 的 <strong>QPS（每秒内查询次数）</strong>。</p>
<ul>
<li>
<ul>
<li>完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。它的，数据存在内存中，类似于 <strong>HashMap</strong>，<strong>HashMap</strong> 的优势就是查找和操作的时间复杂度都是 O(1)；</li>
<li>数据结构简单，对数据操作也简单，<strong>Redis</strong> 中的数据结构是专门进行设计的；</li>
<li>采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 <strong>CPU</strong>，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；</li>
<li>使用多路 I/O 复用模型，非阻塞 NIO；</li>
<li>使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，<strong>Redis</strong> 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；</li>
</ul>
</li>
</ul>
<p><strong>我可以问一下啥是上下文切换么？</strong></p>
<p>线程切换时线程当前的状态，包括栈等</p>
<p><strong>那他是单线程的，我们现在服务器都是多核的，那不是很浪费？</strong><br>
是的他是单线程的，但是，我们可以通过在单机开多个 <strong>Redis 实例</strong>嘛。<br>
<strong>既然提到了单机会有瓶颈，那你们是怎么解决这个瓶颈的？</strong><br>
我们用到了集群的部署方式也就是 <strong>Redis cluster</strong>，并且是主从同步读写分离，类似 <strong>Mysql</strong> 的主从同步，<strong>Redis cluster</strong> 支撑 N 个 <strong>Redis master node</strong>，每个 <strong>master node</strong> 都可以挂载多个 <strong>slave node</strong>。<br>
这样整个 <strong>Redis</strong> 就可以横向扩容了。如果你要支撑更大数据量的缓存，那就横向扩容更多的 <strong>master</strong> 节点，每个 <strong>master</strong> 节点就能存放更多的数据了。<br>
<strong>哦？那问题就来了，他们之间是怎么进行数据交互的？以及 Redis 是怎么进行持久化的？Redis 数据都在内存中，一断电或者重启不就木有了嘛？</strong><br>
是的，持久化的话是 <strong>Redis</strong> 高可用中比较重要的一个环节，因为 <strong>Redis</strong> 数据在内存的特性，持久化必须得有，我了解到的持久化是有两种方式的。</p>
<ul>
<li>
<ul>
<li>RDB：<strong>RDB</strong> 持久化机制，是对 <strong>Redis</strong> 中的数据执行<strong>周期性</strong>的持久化。</li>
<li>AOF：<strong>AOF</strong> 机制对每条写入命令作为日志，以 <strong>append-only</strong> 的模式写入一个日志文件中，因为这个模式是只追加的方式，所以没有任何磁盘寻址的开销，所以很快，有点像 Mysql 中的 <strong>binlog</strong>。</li>
</ul>
</li>
</ul>
<p>两种方式都可以把 <strong>Redis</strong> 内存中的数据持久化到磁盘上，然后再将这些数据备份到别的地方去，<strong>RDB</strong> 更适合做<strong>冷备</strong>，<strong>AOF</strong> 更适合做<strong>热备</strong>，比如我杭州的某电商公司有这两个数据，我备份一份到我杭州的节点，再备份一个到上海的，就算发生无法避免的自然灾害，也不会两个地方都一起挂吧，这<strong>灾备</strong>也就是<strong>异地容灾</strong>，地球毁灭他没办法。<br>
<strong>tip：两种机制全部开启的时候，Redis 在重启的时候会默认使用 AOF 去重新构建数据，因为 AOF 的数据是比 RDB 更完整的。</strong><br>
<strong>那这两种机制各自优缺点是啥？</strong><br>
我先说 <strong>RDB</strong> 吧<br>
<strong>优点：</strong><br>
他会生成多个数据文件，每个数据文件分别都代表了某一时刻 <strong>Redis</strong> 里面的数据，这种方式，有没有觉得很适合做<strong>冷备</strong>，完整的数据运维设置定时任务，定时同步到远端的服务器，比如阿里的云服务，这样一旦线上挂了，你想恢复多少分钟之前的数据，就去远端拷贝一份之前的数据就好了。<br>
<strong>RDB</strong> 对 <strong>Redis</strong> 的性能影响非常小，是因为在同步数据的时候他只是 <strong>fork</strong> 了一个子进程去做持久化的，而且他在数据恢复的时候速度比 <strong>AOF</strong> 来的快。<br>
<strong>缺点：</strong><br>
<strong>RDB</strong> 都是快照文件，都是默认五分钟甚至更久的时间才会生成一次，这意味着你这次同步到下次同步这中间五分钟的数据都很可能全部丢失掉。<strong>AOF</strong> 则最多丢一秒的数据，<strong>数据完整性</strong>上高下立判。<br>
还有就是 <strong>RDB</strong> 在生成数据快照的时候，如果文件很大，客户端可能会暂停几毫秒甚至几秒，你公司在做秒杀的时候他刚好在这个时候 <strong>fork</strong> 了一个子进程去生成一个大快照，哦豁，出大问题。<br>
我们再来说说 <strong>AOF</strong><br>
<strong>优点：</strong><br>
上面提到了，<strong>RDB</strong> 五分钟一次生成快照，但是 <strong>AOF</strong> 是一秒一次去通过一个后台的线程<code>fsync</code>操作，那最多丢这一秒的数据。<br>
<strong>AOF</strong> 在对日志文件进行操作的时候是以<code>append-only</code>的方式去写的，他只是追加的方式写数据，自然就少了很多磁盘寻址的开销了，写入性能惊人，文件也不容易破损。<br>
<strong>AOF</strong> 的日志是通过一个叫<strong>非常可读</strong>的方式记录的，这样的特性就适合做<strong>灾难性数据误删除</strong>的紧急恢复了，比如公司的实习生通过 <strong>flushall</strong> 清空了所有的数据，只要这个时候后台重写还没发生，你马上拷贝一份 <strong>AOF</strong> 日志文件，把最后一条 <strong>flushall</strong> 命令删了就完事了。</p>
<p><strong>缺点：</strong><br>
一样的数据，<strong>AOF</strong> 文件比 <strong>RDB</strong> 还要大。<br>
<strong>AOF</strong> 开启后，<strong>Redis</strong> 支持写的 <strong>QPS</strong> 会比 <strong>RDB</strong> 支持写的要低，他不是每秒都要去异步刷新一次日志嘛 <strong>fsync</strong>，当然即使这样性能还是很高，我记得 <strong>ElasticSearch</strong> 也是这样的，异步刷新缓存区的数据去持久化，为啥这么做呢，不直接来一条怼一条呢，那我会告诉你这样性能可能低到没办法用的，大家可以思考下为啥哟。<br>
<strong>那两者怎么选择？</strong></p>
<p>小孩子才做选择，<strong>我全都要</strong>，你单独用 <strong>RDB</strong> 你会丢失很多数据，你单独用 <strong>AOF</strong>，你数据恢复没 <strong>RDB</strong> 来的快，真出什么时候第一时间用 <strong>RDB</strong> 恢复，然后 <strong>AOF</strong> 做数据补全，真香！冷备热备一起上，才是互联网时代一个高健壮性系统的王道。<br>
<strong>看不出来年纪轻轻有点东西的呀，对了我听你提到了高可用，Redis 还有其他保证集群高可用的方式么？</strong><br>
！！！晕 自己给自己埋个坑（其实是明早就准备好了，故意抛出这个词等他问，就怕他不问）。<br>
假装思考一会（<strong>不要太久，免得以为你真的不会</strong>），哦我想起来了，还有哨兵集群 <strong>sentinel</strong>。<br>
哨兵必须用三个实例去保证自己的健壮性的，哨兵 + 主从并<strong>不能保证数据不丢失</strong>，但是可以保证集群的<strong>高可用</strong>。<br>
为啥必须要三个实例呢？我们先看看两个哨兵会咋样。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/ba8a9e993128e00238e000032fc54ccf.png" alt="" loading="lazy"><img src="https://img-blog.csdnimg.cn/img_convert/d816539907a311be3cfcd8d43545ef38.png" alt="" loading="lazy"></p>
<p>master 宕机了 s1 和 s2 两个哨兵只要有一个认为你宕机了就切换了，并且会选举出一个哨兵去执行故障，但是这个时候也需要大多数哨兵都是运行的。<br>
那这样有啥问题呢？M1 宕机了，S1 没挂那其实是 OK 的，但是整个机器都挂了呢？哨兵就只剩下 S2 个裸屌了，没有哨兵去允许故障转移了，虽然另外一个机器上还有 R1，但是故障转移就是不执行。<br>
经典的哨兵集群是这样的：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/40c4b12429e049a0cf3357721a9672eb.png" alt="" loading="lazy"><img src="https://img-blog.csdnimg.cn/img_convert/cb9d6944b0011870af3ce96f6b3b2375.png" alt="" loading="lazy"></p>
<p>M1 所在的机器挂了，哨兵还有两个，两个人一看他不是挂了嘛，那我们就选举一个出来执行故障转移不就好了。<br>
暖男我，小的总结下哨兵组件的主要功能：</p>
<ul>
<li>
<ul>
<li>集群监控：负责监控 Redis master 和 slave 进程是否正常工作。</li>
<li>消息通知：如果某个 <strong>Redis</strong> 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。</li>
<li>故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。</li>
<li>配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。</li>
</ul>
</li>
</ul>
<p><strong>我记得你还提到了主从同步，能说一下主从之间的数据怎么同步的么？</strong><br>
面试官您的记性可真是一级棒呢，我都要忘了你还记得，我特么谢谢你，提到这个，就跟我前面提到的数据持久化的 <strong>RDB</strong> 和 <strong>AOF</strong> 有着比密切的关系了。<br>
我先说下为啥要用主从这样的架构模式，前面提到了单机 <strong>QPS</strong> 是有上限的，而且 <strong>Redis</strong> 的特性就是必须支撑读高并发的，那你一台机器又读又写，<strong>这谁顶得住啊</strong>，不当人啊！但是你让这个 master 机器去写，数据同步给别的 slave 机器，他们都拿去读，分发掉大量的请求那是不是好很多，而且扩容的时候还可以轻松实现水平扩容。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/20f4ab09d79ce8df5f551644d5c88015.png" alt="" loading="lazy"></p>
<p><strong>回归正题，他们数据怎么同步的呢？</strong><br>
你启动一台 slave 的时候，他会发送一个 <strong>psync</strong> 命令给 master ，如果是这个 slave 第一次连接到 master，他会触发一个全量复制。master 就会启动一个线程，生成 <strong>RDB</strong> 快照，还会把新的写请求都缓存在内存中，<strong>RDB</strong> 文件生成后，master 会将这个 <strong>RDB</strong> 发送给 slave 的，slave 拿到之后做的第一件事情就是写进本地的磁盘，然后加载进内存，然后 master 会把内存里面缓存的那些新命名都发给 slave。<br>
<strong>数据传输的时候断网了或者服务器挂了怎么办啊？</strong><br>
传输过程中有什么网络问题啥的，会自动重连的，并且连接之后会把缺少的数据补上的。<br>
<strong>大家需要记得的就是，RDB 快照的数据生成的时候，缓存区也必须同时开始接受新请求，不然你旧的数据过去了，你在同步期间的增量数据咋办？是吧？</strong><br>
<strong>那说了这么多你能说一下他的内存淘汰机制么，来手写一下 LRU 代码？</strong></p>
<p><em><em>手写 LRU？你是不是想直接跳起来说一句：Are U F*<em>k Kidding me？</em></em><br>
这个问题是我在蚂蚁金服三面的时候亲身被问过的问题，不知道大家有没有被怼到过这个问题。<br>
<strong>Redis</strong> 的过期策略，是有__定期删除 + 惰性删除</em> * 两种。<br>
定期好理解，默认 100s 就随机抽一些设置了过期时间的 key，去检查是否过期，过期了就删了。<br>
<strong>为啥不扫描全部设置了过期时间的 key 呢？</strong><br>
假如 Redis 里面所有的 key 都有过期时间，都扫描一遍？那太恐怖了，而且我们线上基本上也都是会设置一定的过期时间的。全扫描跟你去查数据库不带 where 条件不走索引全表扫描一样，100s 一次，Redis 累都累死了。<br>
<strong>如果一直没随机到很多 key，里面不就存在大量的无效 key 了？</strong><br>
好问题，<strong>惰性删除</strong>，见名知意，惰性嘛，我不主动删，我懒，我等你来查询了我看看你过期没，过期就删了还不给你返回，没过期该怎么样就怎么样。<br>
<strong>最后就是如果的如果，定期没删，我也没查询，那可咋整？</strong><br>
<strong>内存淘汰机制</strong>！<br>
官网上给到的内存淘汰机制是以下几个：</p>
<ul>
<li>
<ul>
<li><strong>noeviction</strong>: 返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但 DEL 和几个例外）</li>
<li><strong>allkeys-lru</strong>: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。</li>
<li><strong>volatile-lru</strong>: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键, 使得新添加的数据有空间存放。</li>
<li><strong>allkeys-random</strong>: 回收随机的键使得新添加的数据有空间存放。</li>
<li><strong>volatile-random</strong>: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。</li>
<li><strong>volatile-ttl</strong>: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键, 使得新添加的数据有空间存放。<br>
如果没有键满足回收的前提条件的话，策略 <strong>volatile-lru</strong>, <strong>volatile-random</strong> 以及 <strong>volatile-ttl</strong> 就和 noeviction 差不多了。</li>
</ul>
</li>
</ul>
<p>至于 <strong>LRU</strong> 我也简单提一下，手写实在是太长了，大家可以去 <strong>Redis 官网</strong>看看，我把<strong>近视 LUR</strong> 效果给大家看看<br>
<strong>tip：Redis 为什么不使用真实的 LRU 实现是因为这需要太多的内存。不过近似的 LRU 算法对于应用而言应该是等价的。使用真实的 LRU 算法与近似的算法可以通过下面的图像对比。</strong></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/33cad37cd39d082b649028c8c63f0b65.png" alt="" loading="lazy"></p>
<p>你可以看到三种点在图片中, 形成了三种带.</p>
<ul>
<li>
<ul>
<li>浅灰色带是已经被回收的对象。</li>
<li>灰色带是没有被回收的对象。</li>
<li>绿色带是被添加的对象。</li>
<li>在 <strong>LRU</strong> 实现的理论中，我们希望的是，在旧键中的第一半将会过期。<strong>Redis</strong> 的 <strong>LRU</strong> 算法则是概率的过期旧的键。</li>
</ul>
</li>
</ul>
<p>你可以看到，在都是五个采样的时候 Redis 3.0 比 Redis 2.8 要好，Redis2.8 中在最后一次访问之间的大多数的对象依然保留着。使用 10 个采样大小的 Redis 3.0 的近似值已经非常接近理论的性能。<br>
注意 LRU 只是个预测键将如何被访问的模型。另外，如果你的数据访问模式非常接近幂定律，大部分的访问将集中在一个键的集合中，LRU 的近似算法将处理得很好。<br>
其实在大家熟悉的 <strong>LinkedHashMap</strong> 中也实现了 Lru 算法的，实现如下：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/e65d15b933b967d56815950743081a3c.png" alt="" loading="lazy"><img src="https://img-blog.csdnimg.cn/img_convert/055f8934d9258544b71e53da48ae8804.png" alt="" loading="lazy"></p>
<p>当容量超过 100 时，开始执行 <strong>LRU</strong> 策略：将最近最少未使用的 <strong>TimeoutInfoHolder</strong> 对象 <strong>evict</strong> 掉。<br>
真实面试中会让你写 LUR 算法，你可别搞原始的那个，那真 TM 多，写不完的，你要么怼上面这个，要么怼下面这个，找一个数据结构实现下 Java 版本的 LRU 还是比较容易的，知道啥原理就好了。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/df0a5fe83ad2d52805259a39d20e75d2.png" alt="" loading="lazy"><img src="https://img-blog.csdnimg.cn/img_convert/6da8e626c348653125b565d1251afd5b.png" alt="" loading="lazy"></p>
</div><div id="reward-container"><span class="hty-icon-button button-glow" id="reward-button" title="打赏" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === &quot;none&quot;) ? &quot;block&quot; : &quot;none&quot;;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-hand-coin-line"></use></svg></span><div id="reward-comment">I'm so cute. Please give me money.</div><div id="qr" style="display:none;"><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/alipay-qrcode.jpg"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/alipay-qrcode.jpg" alt="支付宝" title="支付宝"></a><div><span style="color:#00A3EE"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-alipay-line"></use></svg></span></div></div><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/qqpay-qrcode.png"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/qqpay-qrcode.png" alt="QQ 支付" title="QQ 支付"></a><div><span style="color:#12B7F5"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-qq-line"></use></svg></span></div></div><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/wechatpay-qrcode.jpg"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/donate/wechatpay-qrcode.jpg" alt="微信支付" title="微信支付"></a><div><span style="color:#2DC100"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wechat-pay-line"></use></svg></span></div></div></div></div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>momo</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="https://ppxiaodi.gitee.io/2020/03/14/CollectionNote/java/%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E/Redis%E7%AC%94%E8%AE%B0(%E5%B0%9A%E7%A1%85%E8%B0%B7%E9%BB%91%E9%A9%AC%E6%95%B4%E5%90%88)/" title="Redis笔记(尚硅谷黑马整合)">https://ppxiaodi.gitee.io/2020/03/14/CollectionNote/java/%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E/Redis%E7%AC%94%E8%AE%B0(%E5%B0%9A%E7%A1%85%E8%B0%B7%E9%BB%91%E9%A9%AC%E6%95%B4%E5%90%88)/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a> 许可协议。</li></ul></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/2020/03/14/CollectionNote/java/%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%8A%A0%E5%BC%82%E6%AD%A5%E7%BC%96%E6%8E%92/" rel="prev" title="线程池加异步编排"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-left-s-line"></use></svg><span class="post-nav-text">线程池加异步编排</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/2020/03/14/CollectionNote/java/%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E/%E8%AE%A4%E8%AF%81%E6%9C%8D%E5%8A%A1/" rel="next" title="认证服务_验证码、社交登录、分布式 session、单点登录"><span class="post-nav-text">认证服务_验证码、社交登录、分布式 session、单点登录</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div></div><div class="hty-card" id="comment"><div class="comment-tooltip text-center"><span>要不要和我说些什么？</span><br></div></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 – 2022 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> momo</span></div><div class="powered"><span>由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v5.2.0</span><span class="footer-separator">|</span><span>主题 - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.7.0</span></div></footer><a class="hty-icon-button" id="back-to-top" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#0078E7" stroke-width="2" stroke-linecap="round"></circle></svg></a><a class="popup-trigger hty-icon-button icon-search" id="search" href="javascript:;" title="搜索"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-search-line"></use></svg></span></a><script>window.addEventListener("DOMContentLoaded", () => {
  // Handle and trigger popup window
  document.querySelector(".popup-trigger").addEventListener("click", () => {
    document.querySelector(".popup").classList.add("show");
    setTimeout(() => {
      document.querySelector(".search-input").focus();
    }, 100);
  });

  // Monitor main search box
  const onPopupClose = () => {
    document.querySelector(".popup").classList.remove("show");
  };

  document.querySelector(".popup-btn-close").addEventListener("click", () => {
    onPopupClose();
  });

  window.addEventListener("keyup", event => {
    if (event.key === "Escape") {
      onPopupClose();
    }
  });
});
</script><script src="/js/search/local-search.js" defer></script><div class="popup search-popup"><div class="search-header"><span class="popup-btn-close close-icon hty-icon-button"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-close-line"></use></svg></span></div><div class="search-input-container"><input class="search-input" id="local-search-input" type="text" placeholder="搜索..." value=""></div><div id="local-search-result"></div></div></div></body></html>